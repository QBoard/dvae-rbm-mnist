Device =  cpu
Mini sets = False
z_dim =  10
numh = 1
learning rate = 0.001
Dataset size= 60000
seed num =  57
len train_total_loader = 391
len valid_total_loader = 79
len test_total_loader = 79
Results will be saved to: /tf/agircha/DVAEh/results
Epoch[1/100], Step [10/391], Reconst Loss: 360.08188, KL Div: 4.08949, Total Loss: 364.17137
Epoch[1/100], Step [20/391], Reconst Loss: 247.45761, KL Div: 5.28874, Total Loss: 252.74635
Epoch[1/100], Step [30/391], Reconst Loss: 212.69412, KL Div: 7.82974, Total Loss: 220.52386
Epoch[1/100], Step [40/391], Reconst Loss: 198.98318, KL Div: 8.43102, Total Loss: 207.41420
Epoch[1/100], Step [50/391], Reconst Loss: 195.25040, KL Div: 8.28985, Total Loss: 203.54024
Epoch[1/100], Step [60/391], Reconst Loss: 186.10983, KL Div: 9.10414, Total Loss: 195.21397
Epoch[1/100], Step [70/391], Reconst Loss: 178.56728, KL Div: 9.01494, Total Loss: 187.58222
Epoch[1/100], Step [80/391], Reconst Loss: 174.58002, KL Div: 9.29296, Total Loss: 183.87298
Epoch[1/100], Step [90/391], Reconst Loss: 171.34209, KL Div: 9.20880, Total Loss: 180.55089
Epoch[1/100], Step [100/391], Reconst Loss: 167.76363, KL Div: 8.61098, Total Loss: 176.37460
Epoch[1/100], Step [110/391], Reconst Loss: 164.55734, KL Div: 9.02944, Total Loss: 173.58678
Epoch[1/100], Step [120/391], Reconst Loss: 162.54974, KL Div: 9.40581, Total Loss: 171.95556
Epoch[1/100], Step [130/391], Reconst Loss: 161.49753, KL Div: 8.48452, Total Loss: 169.98205
Epoch[1/100], Step [140/391], Reconst Loss: 157.24902, KL Div: 8.94248, Total Loss: 166.19150
Epoch[1/100], Step [150/391], Reconst Loss: 159.64032, KL Div: 9.16515, Total Loss: 168.80547
Epoch[1/100], Step [160/391], Reconst Loss: 159.28143, KL Div: 9.21086, Total Loss: 168.49229
Epoch[1/100], Step [170/391], Reconst Loss: 157.90884, KL Div: 8.94076, Total Loss: 166.84960
Epoch[1/100], Step [180/391], Reconst Loss: 162.90550, KL Div: 9.33457, Total Loss: 172.24007
Epoch[1/100], Step [190/391], Reconst Loss: 151.84378, KL Div: 9.30973, Total Loss: 161.15351
Epoch[1/100], Step [200/391], Reconst Loss: 156.09473, KL Div: 9.54649, Total Loss: 165.64122
Epoch[1/100], Step [210/391], Reconst Loss: 151.04463, KL Div: 9.14773, Total Loss: 160.19236
Epoch[1/100], Step [220/391], Reconst Loss: 149.04169, KL Div: 9.17751, Total Loss: 158.21919
Epoch[1/100], Step [230/391], Reconst Loss: 148.96234, KL Div: 9.50368, Total Loss: 158.46602
Epoch[1/100], Step [240/391], Reconst Loss: 148.89590, KL Div: 9.46926, Total Loss: 158.36517
Epoch[1/100], Step [250/391], Reconst Loss: 145.09761, KL Div: 9.36303, Total Loss: 154.46064
Epoch[1/100], Step [260/391], Reconst Loss: 157.02213, KL Div: 9.28469, Total Loss: 166.30681
Epoch[1/100], Step [270/391], Reconst Loss: 145.43271, KL Div: 9.34575, Total Loss: 154.77846
Epoch[1/100], Step [280/391], Reconst Loss: 149.07126, KL Div: 9.45169, Total Loss: 158.52295
Epoch[1/100], Step [290/391], Reconst Loss: 150.38475, KL Div: 9.26723, Total Loss: 159.65198
Epoch[1/100], Step [300/391], Reconst Loss: 142.64865, KL Div: 9.18821, Total Loss: 151.83686
Epoch[1/100], Step [310/391], Reconst Loss: 145.92937, KL Div: 8.89841, Total Loss: 154.82778
Epoch[1/100], Step [320/391], Reconst Loss: 148.50903, KL Div: 9.00330, Total Loss: 157.51233
Epoch[1/100], Step [330/391], Reconst Loss: 143.67555, KL Div: 9.55341, Total Loss: 153.22897
Epoch[1/100], Step [340/391], Reconst Loss: 150.50958, KL Div: 9.53620, Total Loss: 160.04579
Epoch[1/100], Step [350/391], Reconst Loss: 148.09158, KL Div: 9.26728, Total Loss: 157.35887
Epoch[1/100], Step [360/391], Reconst Loss: 144.08917, KL Div: 9.49833, Total Loss: 153.58750
Epoch[1/100], Step [370/391], Reconst Loss: 146.32449, KL Div: 9.74014, Total Loss: 156.06464
Epoch[1/100], Step [380/391], Reconst Loss: 146.32904, KL Div: 9.32831, Total Loss: 155.65735
Epoch[1/100], Step [390/391], Reconst Loss: 143.40840, KL Div: 9.25480, Total Loss: 152.66320
Epoch = 1
Training epoch time =  140.74818754196167
train total loss =  153.191923203125
valid total loss =  153.8497098388672
Total epoch time =  258.9540491104126
Saving checkpoint...
Done!
Epoch[2/100], Step [10/391], Reconst Loss: 138.96310, KL Div: 9.84740, Total Loss: 148.81051
Epoch[2/100], Step [20/391], Reconst Loss: 138.57523, KL Div: 9.57994, Total Loss: 148.15516
Epoch[2/100], Step [30/391], Reconst Loss: 140.44366, KL Div: 9.48681, Total Loss: 149.93047
Epoch[2/100], Step [40/391], Reconst Loss: 146.10896, KL Div: 9.30664, Total Loss: 155.41561
Epoch[2/100], Step [50/391], Reconst Loss: 146.61771, KL Div: 9.30067, Total Loss: 155.91838
Epoch[2/100], Step [60/391], Reconst Loss: 147.56650, KL Div: 9.74939, Total Loss: 157.31589
Epoch[2/100], Step [70/391], Reconst Loss: 140.23410, KL Div: 9.85943, Total Loss: 150.09353
Epoch[2/100], Step [80/391], Reconst Loss: 144.74474, KL Div: 9.81735, Total Loss: 154.56208
Epoch[2/100], Step [90/391], Reconst Loss: 136.81898, KL Div: 9.38700, Total Loss: 146.20598
Epoch[2/100], Step [100/391], Reconst Loss: 145.76378, KL Div: 9.71220, Total Loss: 155.47598
Epoch[2/100], Step [110/391], Reconst Loss: 145.34093, KL Div: 9.79843, Total Loss: 155.13936
Epoch[2/100], Step [120/391], Reconst Loss: 139.04066, KL Div: 9.72385, Total Loss: 148.76452
Epoch[2/100], Step [130/391], Reconst Loss: 146.06396, KL Div: 9.59324, Total Loss: 155.65720
Epoch[2/100], Step [140/391], Reconst Loss: 143.37914, KL Div: 9.66504, Total Loss: 153.04418
Epoch[2/100], Step [150/391], Reconst Loss: 145.24814, KL Div: 9.73901, Total Loss: 154.98714
Epoch[2/100], Step [160/391], Reconst Loss: 137.96866, KL Div: 9.71388, Total Loss: 147.68254
Epoch[2/100], Step [170/391], Reconst Loss: 141.26038, KL Div: 9.62224, Total Loss: 150.88261
Epoch[2/100], Step [180/391], Reconst Loss: 149.56245, KL Div: 9.66630, Total Loss: 159.22876
Epoch[2/100], Step [190/391], Reconst Loss: 143.71463, KL Div: 9.50315, Total Loss: 153.21778
Epoch[2/100], Step [200/391], Reconst Loss: 139.47804, KL Div: 9.69865, Total Loss: 149.17669
Epoch[2/100], Step [210/391], Reconst Loss: 139.17484, KL Div: 10.00295, Total Loss: 149.17779
Epoch[2/100], Step [220/391], Reconst Loss: 140.72144, KL Div: 9.55629, Total Loss: 150.27772
Epoch[2/100], Step [230/391], Reconst Loss: 139.33803, KL Div: 9.86848, Total Loss: 149.20650
Epoch[2/100], Step [240/391], Reconst Loss: 137.46623, KL Div: 9.56835, Total Loss: 147.03458
Epoch[2/100], Step [250/391], Reconst Loss: 139.19980, KL Div: 10.33183, Total Loss: 149.53163
Epoch[2/100], Step [260/391], Reconst Loss: 139.04723, KL Div: 9.54718, Total Loss: 148.59441
Epoch[2/100], Step [270/391], Reconst Loss: 142.91350, KL Div: 9.89103, Total Loss: 152.80453
Epoch[2/100], Step [280/391], Reconst Loss: 136.03806, KL Div: 9.97857, Total Loss: 146.01663
Epoch[2/100], Step [290/391], Reconst Loss: 141.19966, KL Div: 9.64840, Total Loss: 150.84806
Epoch[2/100], Step [300/391], Reconst Loss: 143.25433, KL Div: 9.68810, Total Loss: 152.94243
Epoch[2/100], Step [310/391], Reconst Loss: 132.16325, KL Div: 9.76593, Total Loss: 141.92918
Epoch[2/100], Step [320/391], Reconst Loss: 133.63832, KL Div: 10.28844, Total Loss: 143.92676
Epoch[2/100], Step [330/391], Reconst Loss: 135.26083, KL Div: 9.52213, Total Loss: 144.78297
Epoch[2/100], Step [340/391], Reconst Loss: 136.17570, KL Div: 9.75995, Total Loss: 145.93566
Epoch[2/100], Step [350/391], Reconst Loss: 135.65570, KL Div: 9.96941, Total Loss: 145.62511
Epoch[2/100], Step [360/391], Reconst Loss: 133.65190, KL Div: 9.55755, Total Loss: 143.20945
Epoch[2/100], Step [370/391], Reconst Loss: 141.24380, KL Div: 9.38570, Total Loss: 150.62951
Epoch[2/100], Step [380/391], Reconst Loss: 138.20119, KL Div: 9.47872, Total Loss: 147.67990
Epoch[2/100], Step [390/391], Reconst Loss: 132.05331, KL Div: 9.54607, Total Loss: 141.59938
Epoch = 2
Training epoch time =  140.4050371646881
train total loss =  146.2923410546875
valid total loss =  146.7768080078125
Total epoch time =  258.4401454925537
Saving checkpoint...
Done!
Epoch[3/100], Step [10/391], Reconst Loss: 135.53130, KL Div: 9.80503, Total Loss: 145.33633
Epoch[3/100], Step [20/391], Reconst Loss: 142.16507, KL Div: 10.05867, Total Loss: 152.22374
Epoch[3/100], Step [30/391], Reconst Loss: 139.83344, KL Div: 9.71213, Total Loss: 149.54557
Epoch[3/100], Step [40/391], Reconst Loss: 134.16580, KL Div: 9.91709, Total Loss: 144.08289
Epoch[3/100], Step [50/391], Reconst Loss: 138.32556, KL Div: 9.46171, Total Loss: 147.78727
Epoch[3/100], Step [60/391], Reconst Loss: 137.13034, KL Div: 10.22167, Total Loss: 147.35201
Epoch[3/100], Step [70/391], Reconst Loss: 136.74551, KL Div: 9.78050, Total Loss: 146.52601
Epoch[3/100], Step [80/391], Reconst Loss: 137.67871, KL Div: 9.58170, Total Loss: 147.26041
Epoch[3/100], Step [90/391], Reconst Loss: 138.64197, KL Div: 9.51452, Total Loss: 148.15649
Epoch[3/100], Step [100/391], Reconst Loss: 135.28523, KL Div: 9.64696, Total Loss: 144.93219
Epoch[3/100], Step [110/391], Reconst Loss: 133.18845, KL Div: 9.27028, Total Loss: 142.45873
Epoch[3/100], Step [120/391], Reconst Loss: 137.77203, KL Div: 9.50403, Total Loss: 147.27607
Epoch[3/100], Step [130/391], Reconst Loss: 139.13345, KL Div: 9.54376, Total Loss: 148.67721
Epoch[3/100], Step [140/391], Reconst Loss: 130.14975, KL Div: 9.73789, Total Loss: 139.88764
Epoch[3/100], Step [150/391], Reconst Loss: 130.16501, KL Div: 9.93145, Total Loss: 140.09646
Epoch[3/100], Step [160/391], Reconst Loss: 138.62660, KL Div: 9.99216, Total Loss: 148.61876
Epoch[3/100], Step [170/391], Reconst Loss: 133.60593, KL Div: 9.59203, Total Loss: 143.19796
Epoch[3/100], Step [180/391], Reconst Loss: 133.26363, KL Div: 10.23160, Total Loss: 143.49523
Epoch[3/100], Step [190/391], Reconst Loss: 133.54311, KL Div: 9.91191, Total Loss: 143.45501
Epoch[3/100], Step [200/391], Reconst Loss: 135.03636, KL Div: 9.45111, Total Loss: 144.48747
Epoch[3/100], Step [210/391], Reconst Loss: 137.85651, KL Div: 9.81089, Total Loss: 147.66740
Epoch[3/100], Step [220/391], Reconst Loss: 134.28131, KL Div: 9.97944, Total Loss: 144.26075
Epoch[3/100], Step [230/391], Reconst Loss: 136.86095, KL Div: 10.09325, Total Loss: 146.95419
Epoch[3/100], Step [240/391], Reconst Loss: 146.30052, KL Div: 9.66866, Total Loss: 155.96918
Epoch[3/100], Step [250/391], Reconst Loss: 134.88055, KL Div: 9.74221, Total Loss: 144.62277
Epoch[3/100], Step [260/391], Reconst Loss: 133.07422, KL Div: 10.26855, Total Loss: 143.34277
Epoch[3/100], Step [270/391], Reconst Loss: 126.37149, KL Div: 10.02286, Total Loss: 136.39435
Epoch[3/100], Step [280/391], Reconst Loss: 136.03223, KL Div: 10.02719, Total Loss: 146.05942
Epoch[3/100], Step [290/391], Reconst Loss: 133.06561, KL Div: 9.58712, Total Loss: 142.65273
Epoch[3/100], Step [300/391], Reconst Loss: 138.54991, KL Div: 9.48548, Total Loss: 148.03539
Epoch[3/100], Step [310/391], Reconst Loss: 147.68207, KL Div: 9.80512, Total Loss: 157.48719
Epoch[3/100], Step [320/391], Reconst Loss: 133.79486, KL Div: 9.68046, Total Loss: 143.47532
Epoch[3/100], Step [330/391], Reconst Loss: 131.89191, KL Div: 9.62940, Total Loss: 141.52131
Epoch[3/100], Step [340/391], Reconst Loss: 134.71599, KL Div: 9.96450, Total Loss: 144.68049
Epoch[3/100], Step [350/391], Reconst Loss: 131.46837, KL Div: 9.68663, Total Loss: 141.15500
Epoch[3/100], Step [360/391], Reconst Loss: 134.33423, KL Div: 9.97815, Total Loss: 144.31237
Epoch[3/100], Step [370/391], Reconst Loss: 131.23782, KL Div: 10.02446, Total Loss: 141.26228
Epoch[3/100], Step [380/391], Reconst Loss: 135.21758, KL Div: 9.52635, Total Loss: 144.74392
Epoch[3/100], Step [390/391], Reconst Loss: 138.39038, KL Div: 9.81276, Total Loss: 148.20314
Epoch = 3
Training epoch time =  139.06811022758484
train total loss =  142.90545775390626
valid total loss =  143.7540053222656
Total epoch time =  257.28322553634644
Saving checkpoint...
Done!
Epoch[4/100], Step [10/391], Reconst Loss: 136.82574, KL Div: 10.22814, Total Loss: 147.05388
Epoch[4/100], Step [20/391], Reconst Loss: 135.47079, KL Div: 9.70442, Total Loss: 145.17522
Epoch[4/100], Step [30/391], Reconst Loss: 131.23538, KL Div: 9.80071, Total Loss: 141.03609
Epoch[4/100], Step [40/391], Reconst Loss: 135.35825, KL Div: 9.96725, Total Loss: 145.32549
Epoch[4/100], Step [50/391], Reconst Loss: 128.73962, KL Div: 9.90560, Total Loss: 138.64522
Epoch[4/100], Step [60/391], Reconst Loss: 137.61221, KL Div: 10.01321, Total Loss: 147.62543
Epoch[4/100], Step [70/391], Reconst Loss: 132.98648, KL Div: 10.07302, Total Loss: 143.05950
Epoch[4/100], Step [80/391], Reconst Loss: 130.10712, KL Div: 9.89328, Total Loss: 140.00040
Epoch[4/100], Step [90/391], Reconst Loss: 133.01215, KL Div: 9.98423, Total Loss: 142.99638
Epoch[4/100], Step [100/391], Reconst Loss: 130.22839, KL Div: 9.93642, Total Loss: 140.16481
Epoch[4/100], Step [110/391], Reconst Loss: 137.24686, KL Div: 9.93724, Total Loss: 147.18410
Epoch[4/100], Step [120/391], Reconst Loss: 134.32639, KL Div: 9.81646, Total Loss: 144.14284
Epoch[4/100], Step [130/391], Reconst Loss: 130.67346, KL Div: 9.93658, Total Loss: 140.61005
Epoch[4/100], Step [140/391], Reconst Loss: 129.93761, KL Div: 9.88601, Total Loss: 139.82362
Epoch[4/100], Step [150/391], Reconst Loss: 135.77953, KL Div: 10.04922, Total Loss: 145.82874
Epoch[4/100], Step [160/391], Reconst Loss: 124.69513, KL Div: 10.07216, Total Loss: 134.76729
Epoch[4/100], Step [170/391], Reconst Loss: 130.87369, KL Div: 9.79016, Total Loss: 140.66384
Epoch[4/100], Step [180/391], Reconst Loss: 131.49774, KL Div: 9.56889, Total Loss: 141.06663
Epoch[4/100], Step [190/391], Reconst Loss: 125.52407, KL Div: 9.78568, Total Loss: 135.30975
Epoch[4/100], Step [200/391], Reconst Loss: 133.99300, KL Div: 9.74621, Total Loss: 143.73920
Epoch[4/100], Step [210/391], Reconst Loss: 135.92740, KL Div: 9.74913, Total Loss: 145.67653
Epoch[4/100], Step [220/391], Reconst Loss: 139.38959, KL Div: 9.86993, Total Loss: 149.25952
Epoch[4/100], Step [230/391], Reconst Loss: 125.38707, KL Div: 9.89385, Total Loss: 135.28092
Epoch[4/100], Step [240/391], Reconst Loss: 129.78186, KL Div: 10.14588, Total Loss: 139.92774
Epoch[4/100], Step [250/391], Reconst Loss: 129.89633, KL Div: 9.88000, Total Loss: 139.77633
Epoch[4/100], Step [260/391], Reconst Loss: 133.70674, KL Div: 9.75149, Total Loss: 143.45823
Epoch[4/100], Step [270/391], Reconst Loss: 125.51774, KL Div: 9.74209, Total Loss: 135.25982
Epoch[4/100], Step [280/391], Reconst Loss: 123.55783, KL Div: 9.92088, Total Loss: 133.47872
Epoch[4/100], Step [290/391], Reconst Loss: 129.68918, KL Div: 10.08014, Total Loss: 139.76932
Epoch[4/100], Step [300/391], Reconst Loss: 126.39070, KL Div: 9.91937, Total Loss: 136.31007
Epoch[4/100], Step [310/391], Reconst Loss: 132.63275, KL Div: 9.93835, Total Loss: 142.57110
Epoch[4/100], Step [320/391], Reconst Loss: 130.77629, KL Div: 9.59797, Total Loss: 140.37426
Epoch[4/100], Step [330/391], Reconst Loss: 132.72238, KL Div: 9.77173, Total Loss: 142.49411
Epoch[4/100], Step [340/391], Reconst Loss: 132.55846, KL Div: 9.95869, Total Loss: 142.51714
Epoch[4/100], Step [350/391], Reconst Loss: 132.86084, KL Div: 9.76047, Total Loss: 142.62131
Epoch[4/100], Step [360/391], Reconst Loss: 127.45372, KL Div: 9.53145, Total Loss: 136.98517
Epoch[4/100], Step [370/391], Reconst Loss: 133.38081, KL Div: 10.02176, Total Loss: 143.40257
Epoch[4/100], Step [380/391], Reconst Loss: 133.45671, KL Div: 9.82911, Total Loss: 143.28582
Epoch[4/100], Step [390/391], Reconst Loss: 128.70262, KL Div: 9.75104, Total Loss: 138.45366
Epoch = 4
Training epoch time =  139.5967400074005
train total loss =  140.5707896484375
valid total loss =  141.09334323730468
Total epoch time =  260.5500466823578
Saving checkpoint...
Done!
Epoch[5/100], Step [10/391], Reconst Loss: 131.45921, KL Div: 9.53743, Total Loss: 140.99664
Epoch[5/100], Step [20/391], Reconst Loss: 136.11923, KL Div: 9.58607, Total Loss: 145.70531
Epoch[5/100], Step [30/391], Reconst Loss: 130.04994, KL Div: 9.92076, Total Loss: 139.97071
Epoch[5/100], Step [40/391], Reconst Loss: 127.84693, KL Div: 9.51293, Total Loss: 137.35986
Epoch[5/100], Step [50/391], Reconst Loss: 137.65747, KL Div: 9.80465, Total Loss: 147.46212
Epoch[5/100], Step [60/391], Reconst Loss: 128.69014, KL Div: 9.73601, Total Loss: 138.42615
Epoch[5/100], Step [70/391], Reconst Loss: 131.23212, KL Div: 9.68268, Total Loss: 140.91479
Epoch[5/100], Step [80/391], Reconst Loss: 125.42728, KL Div: 10.22211, Total Loss: 135.64940
Epoch[5/100], Step [90/391], Reconst Loss: 134.10091, KL Div: 9.41785, Total Loss: 143.51876
Epoch[5/100], Step [100/391], Reconst Loss: 123.96553, KL Div: 9.94952, Total Loss: 133.91505
Epoch[5/100], Step [110/391], Reconst Loss: 132.09790, KL Div: 9.67930, Total Loss: 141.77720
Epoch[5/100], Step [120/391], Reconst Loss: 134.89804, KL Div: 9.88699, Total Loss: 144.78503
Epoch[5/100], Step [130/391], Reconst Loss: 126.55840, KL Div: 9.48952, Total Loss: 136.04792
Epoch[5/100], Step [140/391], Reconst Loss: 131.66325, KL Div: 9.55018, Total Loss: 141.21344
Epoch[5/100], Step [150/391], Reconst Loss: 132.88303, KL Div: 9.71065, Total Loss: 142.59368
Epoch[5/100], Step [160/391], Reconst Loss: 130.46072, KL Div: 10.04633, Total Loss: 140.50706
Epoch[5/100], Step [170/391], Reconst Loss: 130.35434, KL Div: 9.98176, Total Loss: 140.33610
Epoch[5/100], Step [180/391], Reconst Loss: 130.36362, KL Div: 9.84360, Total Loss: 140.20721
Epoch[5/100], Step [190/391], Reconst Loss: 136.35287, KL Div: 9.76655, Total Loss: 146.11943
Epoch[5/100], Step [200/391], Reconst Loss: 132.99011, KL Div: 9.70771, Total Loss: 142.69782
Epoch[5/100], Step [210/391], Reconst Loss: 134.90419, KL Div: 9.94753, Total Loss: 144.85172
Epoch[5/100], Step [220/391], Reconst Loss: 136.73337, KL Div: 9.81184, Total Loss: 146.54521
Epoch[5/100], Step [230/391], Reconst Loss: 131.26457, KL Div: 9.80272, Total Loss: 141.06729
Epoch[5/100], Step [240/391], Reconst Loss: 125.69705, KL Div: 9.93259, Total Loss: 135.62964
Epoch[5/100], Step [250/391], Reconst Loss: 136.72525, KL Div: 9.83052, Total Loss: 146.55577
Epoch[5/100], Step [260/391], Reconst Loss: 136.84369, KL Div: 9.80058, Total Loss: 146.64427
Epoch[5/100], Step [270/391], Reconst Loss: 129.94725, KL Div: 9.75147, Total Loss: 139.69872
Epoch[5/100], Step [280/391], Reconst Loss: 134.90634, KL Div: 9.57851, Total Loss: 144.48485
Epoch[5/100], Step [290/391], Reconst Loss: 129.51555, KL Div: 10.00141, Total Loss: 139.51696
Epoch[5/100], Step [300/391], Reconst Loss: 130.55991, KL Div: 9.35254, Total Loss: 139.91244
Epoch[5/100], Step [310/391], Reconst Loss: 122.87239, KL Div: 9.89749, Total Loss: 132.76988
Epoch[5/100], Step [320/391], Reconst Loss: 128.12552, KL Div: 9.85508, Total Loss: 137.98060
Epoch[5/100], Step [330/391], Reconst Loss: 124.65268, KL Div: 9.87273, Total Loss: 134.52541
Epoch[5/100], Step [340/391], Reconst Loss: 131.20920, KL Div: 9.86628, Total Loss: 141.07548
Epoch[5/100], Step [350/391], Reconst Loss: 127.46091, KL Div: 9.96274, Total Loss: 137.42364
Epoch[5/100], Step [360/391], Reconst Loss: 131.41422, KL Div: 10.06146, Total Loss: 141.47567
Epoch[5/100], Step [370/391], Reconst Loss: 127.72066, KL Div: 9.79557, Total Loss: 137.51623
Epoch[5/100], Step [380/391], Reconst Loss: 127.36629, KL Div: 9.76940, Total Loss: 137.13569
Epoch[5/100], Step [390/391], Reconst Loss: 134.10698, KL Div: 10.00738, Total Loss: 144.11435
Epoch = 5
Training epoch time =  140.47591137886047
train total loss =  140.41704755859374
valid total loss =  140.98540639648436
Total epoch time =  259.4495801925659
Saving checkpoint...
Done!
Epoch[6/100], Step [10/391], Reconst Loss: 129.70171, KL Div: 10.00299, Total Loss: 139.70469
Epoch[6/100], Step [20/391], Reconst Loss: 127.67743, KL Div: 10.10967, Total Loss: 137.78710
Epoch[6/100], Step [30/391], Reconst Loss: 127.76508, KL Div: 10.43537, Total Loss: 138.20046
Epoch[6/100], Step [40/391], Reconst Loss: 126.69931, KL Div: 10.02437, Total Loss: 136.72368
Epoch[6/100], Step [50/391], Reconst Loss: 139.74977, KL Div: 10.54855, Total Loss: 150.29832
Epoch[6/100], Step [60/391], Reconst Loss: 128.75537, KL Div: 10.43398, Total Loss: 139.18935
Epoch[6/100], Step [70/391], Reconst Loss: 127.97656, KL Div: 10.39847, Total Loss: 138.37503
Epoch[6/100], Step [80/391], Reconst Loss: 135.66452, KL Div: 10.34515, Total Loss: 146.00967
Epoch[6/100], Step [90/391], Reconst Loss: 129.22987, KL Div: 10.43351, Total Loss: 139.66339
Epoch[6/100], Step [100/391], Reconst Loss: 131.07921, KL Div: 9.94208, Total Loss: 141.02129
Epoch[6/100], Step [110/391], Reconst Loss: 128.02583, KL Div: 10.07054, Total Loss: 138.09637
Epoch[6/100], Step [120/391], Reconst Loss: 126.71317, KL Div: 10.10011, Total Loss: 136.81328
Epoch[6/100], Step [130/391], Reconst Loss: 130.45532, KL Div: 9.96299, Total Loss: 140.41832
Epoch[6/100], Step [140/391], Reconst Loss: 122.25110, KL Div: 9.56875, Total Loss: 131.81985
Epoch[6/100], Step [150/391], Reconst Loss: 127.17036, KL Div: 10.02695, Total Loss: 137.19731
Epoch[6/100], Step [160/391], Reconst Loss: 127.65231, KL Div: 10.00431, Total Loss: 137.65662
Epoch[6/100], Step [170/391], Reconst Loss: 132.80215, KL Div: 9.90025, Total Loss: 142.70240
Epoch[6/100], Step [180/391], Reconst Loss: 127.85626, KL Div: 9.95246, Total Loss: 137.80872
Epoch[6/100], Step [190/391], Reconst Loss: 132.09102, KL Div: 9.68712, Total Loss: 141.77814
Epoch[6/100], Step [200/391], Reconst Loss: 129.67215, KL Div: 9.86679, Total Loss: 139.53894
Epoch[6/100], Step [210/391], Reconst Loss: 135.12474, KL Div: 10.01552, Total Loss: 145.14026
Epoch[6/100], Step [220/391], Reconst Loss: 123.80229, KL Div: 10.25118, Total Loss: 134.05347
Epoch[6/100], Step [230/391], Reconst Loss: 127.87310, KL Div: 9.70818, Total Loss: 137.58128
Epoch[6/100], Step [240/391], Reconst Loss: 124.94981, KL Div: 10.24335, Total Loss: 135.19317
Epoch[6/100], Step [250/391], Reconst Loss: 131.75909, KL Div: 9.92808, Total Loss: 141.68717
Epoch[6/100], Step [260/391], Reconst Loss: 129.50716, KL Div: 9.97191, Total Loss: 139.47906
Epoch[6/100], Step [270/391], Reconst Loss: 128.54240, KL Div: 10.27377, Total Loss: 138.81617
Epoch[6/100], Step [280/391], Reconst Loss: 127.31326, KL Div: 9.74913, Total Loss: 137.06238
Epoch[6/100], Step [290/391], Reconst Loss: 126.14449, KL Div: 9.94795, Total Loss: 136.09244
Epoch[6/100], Step [300/391], Reconst Loss: 129.86354, KL Div: 9.94002, Total Loss: 139.80357
Epoch[6/100], Step [310/391], Reconst Loss: 132.14575, KL Div: 10.14417, Total Loss: 142.28992
Epoch[6/100], Step [320/391], Reconst Loss: 123.52385, KL Div: 10.12968, Total Loss: 133.65353
Epoch[6/100], Step [330/391], Reconst Loss: 129.09540, KL Div: 9.67662, Total Loss: 138.77202
Epoch[6/100], Step [340/391], Reconst Loss: 122.56627, KL Div: 9.60695, Total Loss: 132.17322
Epoch[6/100], Step [350/391], Reconst Loss: 128.04329, KL Div: 10.12059, Total Loss: 138.16388
Epoch[6/100], Step [360/391], Reconst Loss: 133.49057, KL Div: 9.58928, Total Loss: 143.07985
Epoch[6/100], Step [370/391], Reconst Loss: 130.12979, KL Div: 10.13939, Total Loss: 140.26919
Epoch[6/100], Step [380/391], Reconst Loss: 124.65115, KL Div: 9.97437, Total Loss: 134.62552
Epoch[6/100], Step [390/391], Reconst Loss: 121.92552, KL Div: 10.16310, Total Loss: 132.08862
Epoch = 6
Training epoch time =  139.1093361377716
train total loss =  136.72389181640625
valid total loss =  137.2275178222656
Total epoch time =  258.5959208011627
Saving checkpoint...
Done!
Epoch[7/100], Step [10/391], Reconst Loss: 126.53387, KL Div: 9.75722, Total Loss: 136.29110
Epoch[7/100], Step [20/391], Reconst Loss: 129.89622, KL Div: 9.90271, Total Loss: 139.79894
Epoch[7/100], Step [30/391], Reconst Loss: 126.04803, KL Div: 10.04980, Total Loss: 136.09783
Epoch[7/100], Step [40/391], Reconst Loss: 135.14922, KL Div: 10.08045, Total Loss: 145.22967
Epoch[7/100], Step [50/391], Reconst Loss: 123.59998, KL Div: 9.87798, Total Loss: 133.47796
Epoch[7/100], Step [60/391], Reconst Loss: 123.42499, KL Div: 10.32791, Total Loss: 133.75290
Epoch[7/100], Step [70/391], Reconst Loss: 130.53304, KL Div: 10.23401, Total Loss: 140.76705
Epoch[7/100], Step [80/391], Reconst Loss: 125.38593, KL Div: 9.89135, Total Loss: 135.27727
Epoch[7/100], Step [90/391], Reconst Loss: 130.62634, KL Div: 10.36245, Total Loss: 140.98879
Epoch[7/100], Step [100/391], Reconst Loss: 132.49625, KL Div: 9.95738, Total Loss: 142.45362
Epoch[7/100], Step [110/391], Reconst Loss: 120.51083, KL Div: 10.14382, Total Loss: 130.65465
Epoch[7/100], Step [120/391], Reconst Loss: 122.17561, KL Div: 10.02607, Total Loss: 132.20169
Epoch[7/100], Step [130/391], Reconst Loss: 134.52573, KL Div: 10.18125, Total Loss: 144.70698
Epoch[7/100], Step [140/391], Reconst Loss: 137.66087, KL Div: 9.90344, Total Loss: 147.56431
Epoch[7/100], Step [150/391], Reconst Loss: 126.12451, KL Div: 9.77390, Total Loss: 135.89841
Epoch[7/100], Step [160/391], Reconst Loss: 129.54945, KL Div: 10.13291, Total Loss: 139.68236
Epoch[7/100], Step [170/391], Reconst Loss: 123.87900, KL Div: 10.60440, Total Loss: 134.48339
Epoch[7/100], Step [180/391], Reconst Loss: 123.94703, KL Div: 9.51073, Total Loss: 133.45776
Epoch[7/100], Step [190/391], Reconst Loss: 126.14697, KL Div: 10.08265, Total Loss: 136.22961
Epoch[7/100], Step [200/391], Reconst Loss: 126.94186, KL Div: 10.11468, Total Loss: 137.05653
Epoch[7/100], Step [210/391], Reconst Loss: 133.62041, KL Div: 10.19812, Total Loss: 143.81853
Epoch[7/100], Step [220/391], Reconst Loss: 128.80829, KL Div: 10.19605, Total Loss: 139.00433
Epoch[7/100], Step [230/391], Reconst Loss: 129.77591, KL Div: 9.80607, Total Loss: 139.58198
Epoch[7/100], Step [240/391], Reconst Loss: 128.94278, KL Div: 10.29852, Total Loss: 139.24130
Epoch[7/100], Step [250/391], Reconst Loss: 128.10120, KL Div: 10.11127, Total Loss: 138.21247
Epoch[7/100], Step [260/391], Reconst Loss: 123.78465, KL Div: 10.15622, Total Loss: 133.94087
Epoch[7/100], Step [270/391], Reconst Loss: 132.55363, KL Div: 9.83939, Total Loss: 142.39303
Epoch[7/100], Step [280/391], Reconst Loss: 132.61821, KL Div: 9.81017, Total Loss: 142.42838
Epoch[7/100], Step [290/391], Reconst Loss: 125.35065, KL Div: 10.00495, Total Loss: 135.35560
Epoch[7/100], Step [300/391], Reconst Loss: 128.21611, KL Div: 10.10836, Total Loss: 138.32447
Epoch[7/100], Step [310/391], Reconst Loss: 124.52509, KL Div: 10.28257, Total Loss: 134.80766
Epoch[7/100], Step [320/391], Reconst Loss: 120.00096, KL Div: 9.77522, Total Loss: 129.77619
Epoch[7/100], Step [330/391], Reconst Loss: 122.04861, KL Div: 10.43655, Total Loss: 132.48516
Epoch[7/100], Step [340/391], Reconst Loss: 126.05094, KL Div: 10.28783, Total Loss: 136.33877
Epoch[7/100], Step [350/391], Reconst Loss: 130.76410, KL Div: 10.22341, Total Loss: 140.98751
Epoch[7/100], Step [360/391], Reconst Loss: 127.87869, KL Div: 10.22779, Total Loss: 138.10648
Epoch[7/100], Step [370/391], Reconst Loss: 124.14720, KL Div: 10.17032, Total Loss: 134.31753
Epoch[7/100], Step [380/391], Reconst Loss: 127.83704, KL Div: 9.86669, Total Loss: 137.70373
Epoch[7/100], Step [390/391], Reconst Loss: 122.78602, KL Div: 10.19061, Total Loss: 132.97663
Epoch = 7
Training epoch time =  139.52778387069702
train total loss =  136.022376953125
valid total loss =  136.69122817382814
Total epoch time =  258.1026961803436
Saving checkpoint...
Done!
Epoch[8/100], Step [10/391], Reconst Loss: 126.48527, KL Div: 10.02666, Total Loss: 136.51193
Epoch[8/100], Step [20/391], Reconst Loss: 123.18420, KL Div: 10.27960, Total Loss: 133.46380
Epoch[8/100], Step [30/391], Reconst Loss: 133.42776, KL Div: 9.88519, Total Loss: 143.31296
Epoch[8/100], Step [40/391], Reconst Loss: 127.61302, KL Div: 10.04583, Total Loss: 137.65885
Epoch[8/100], Step [50/391], Reconst Loss: 132.65942, KL Div: 10.19828, Total Loss: 142.85770
Epoch[8/100], Step [60/391], Reconst Loss: 128.52243, KL Div: 10.25797, Total Loss: 138.78040
Epoch[8/100], Step [70/391], Reconst Loss: 128.24304, KL Div: 10.16933, Total Loss: 138.41237
Epoch[8/100], Step [80/391], Reconst Loss: 125.44478, KL Div: 10.28342, Total Loss: 135.72820
Epoch[8/100], Step [90/391], Reconst Loss: 121.29987, KL Div: 9.67063, Total Loss: 130.97050
Epoch[8/100], Step [100/391], Reconst Loss: 128.04236, KL Div: 10.17837, Total Loss: 138.22073
Epoch[8/100], Step [110/391], Reconst Loss: 123.94377, KL Div: 10.12383, Total Loss: 134.06760
Epoch[8/100], Step [120/391], Reconst Loss: 123.86714, KL Div: 10.07390, Total Loss: 133.94104
Epoch[8/100], Step [130/391], Reconst Loss: 119.75255, KL Div: 10.20285, Total Loss: 129.95540
Epoch[8/100], Step [140/391], Reconst Loss: 123.19577, KL Div: 10.37293, Total Loss: 133.56870
Epoch[8/100], Step [150/391], Reconst Loss: 127.02684, KL Div: 10.26204, Total Loss: 137.28888
Epoch[8/100], Step [160/391], Reconst Loss: 126.21674, KL Div: 10.12679, Total Loss: 136.34353
Epoch[8/100], Step [170/391], Reconst Loss: 125.10847, KL Div: 10.30647, Total Loss: 135.41495
Epoch[8/100], Step [180/391], Reconst Loss: 128.22552, KL Div: 9.93465, Total Loss: 138.16017
Epoch[8/100], Step [190/391], Reconst Loss: 125.38400, KL Div: 10.52167, Total Loss: 135.90568
Epoch[8/100], Step [200/391], Reconst Loss: 126.58134, KL Div: 10.32409, Total Loss: 136.90543
Epoch[8/100], Step [210/391], Reconst Loss: 130.05754, KL Div: 10.76871, Total Loss: 140.82625
Epoch[8/100], Step [220/391], Reconst Loss: 123.28081, KL Div: 10.24186, Total Loss: 133.52266
Epoch[8/100], Step [230/391], Reconst Loss: 127.66634, KL Div: 10.04398, Total Loss: 137.71032
Epoch[8/100], Step [240/391], Reconst Loss: 126.88321, KL Div: 10.34462, Total Loss: 137.22783
Epoch[8/100], Step [250/391], Reconst Loss: 127.49017, KL Div: 10.09912, Total Loss: 137.58929
Epoch[8/100], Step [260/391], Reconst Loss: 127.90413, KL Div: 10.20410, Total Loss: 138.10823
Epoch[8/100], Step [270/391], Reconst Loss: 128.29492, KL Div: 10.16343, Total Loss: 138.45835
Epoch[8/100], Step [280/391], Reconst Loss: 126.90825, KL Div: 9.68903, Total Loss: 136.59728
Epoch[8/100], Step [290/391], Reconst Loss: 130.32916, KL Div: 10.04963, Total Loss: 140.37879
Epoch[8/100], Step [300/391], Reconst Loss: 124.36922, KL Div: 9.87041, Total Loss: 134.23964
Epoch[8/100], Step [310/391], Reconst Loss: 123.90311, KL Div: 9.94125, Total Loss: 133.84436
Epoch[8/100], Step [320/391], Reconst Loss: 122.64391, KL Div: 9.97599, Total Loss: 132.61990
Epoch[8/100], Step [330/391], Reconst Loss: 131.11212, KL Div: 10.25967, Total Loss: 141.37179
Epoch[8/100], Step [340/391], Reconst Loss: 125.59345, KL Div: 10.35396, Total Loss: 135.94741
Epoch[8/100], Step [350/391], Reconst Loss: 126.29375, KL Div: 10.35206, Total Loss: 136.64580
Epoch[8/100], Step [360/391], Reconst Loss: 118.48058, KL Div: 10.10249, Total Loss: 128.58307
Epoch[8/100], Step [370/391], Reconst Loss: 121.95606, KL Div: 10.88981, Total Loss: 132.84587
Epoch[8/100], Step [380/391], Reconst Loss: 123.24080, KL Div: 10.28512, Total Loss: 133.52592
Epoch[8/100], Step [390/391], Reconst Loss: 124.49618, KL Div: 10.16112, Total Loss: 134.65730
Epoch = 8
Training epoch time =  139.41935896873474
train total loss =  135.12786595703125
valid total loss =  135.90286157226564
Total epoch time =  257.9790885448456
Saving checkpoint...
Done!
Epoch[9/100], Step [10/391], Reconst Loss: 125.05361, KL Div: 10.17080, Total Loss: 135.22441
Epoch[9/100], Step [20/391], Reconst Loss: 122.57690, KL Div: 10.30055, Total Loss: 132.87746
Epoch[9/100], Step [30/391], Reconst Loss: 119.17622, KL Div: 9.88290, Total Loss: 129.05912
Epoch[9/100], Step [40/391], Reconst Loss: 128.73032, KL Div: 10.24331, Total Loss: 138.97363
Epoch[9/100], Step [50/391], Reconst Loss: 122.45378, KL Div: 10.45387, Total Loss: 132.90765
Epoch[9/100], Step [60/391], Reconst Loss: 121.67853, KL Div: 10.30150, Total Loss: 131.98003
Epoch[9/100], Step [70/391], Reconst Loss: 121.01572, KL Div: 10.07616, Total Loss: 131.09188
Epoch[9/100], Step [80/391], Reconst Loss: 128.53989, KL Div: 10.39566, Total Loss: 138.93554
Epoch[9/100], Step [90/391], Reconst Loss: 122.78381, KL Div: 10.14945, Total Loss: 132.93326
Epoch[9/100], Step [100/391], Reconst Loss: 129.66162, KL Div: 10.24108, Total Loss: 139.90270
Epoch[9/100], Step [110/391], Reconst Loss: 122.77214, KL Div: 10.37627, Total Loss: 133.14841
Epoch[9/100], Step [120/391], Reconst Loss: 125.35371, KL Div: 10.14039, Total Loss: 135.49410
Epoch[9/100], Step [130/391], Reconst Loss: 125.60244, KL Div: 10.29398, Total Loss: 135.89642
Epoch[9/100], Step [140/391], Reconst Loss: 126.02666, KL Div: 10.21339, Total Loss: 136.24005
Epoch[9/100], Step [150/391], Reconst Loss: 127.14258, KL Div: 10.31222, Total Loss: 137.45480
Epoch[9/100], Step [160/391], Reconst Loss: 126.35941, KL Div: 10.58021, Total Loss: 136.93961
Epoch[9/100], Step [170/391], Reconst Loss: 132.18675, KL Div: 10.30587, Total Loss: 142.49262
Epoch[9/100], Step [180/391], Reconst Loss: 123.92409, KL Div: 10.52644, Total Loss: 134.45053
Epoch[9/100], Step [190/391], Reconst Loss: 128.24904, KL Div: 10.45226, Total Loss: 138.70130
Epoch[9/100], Step [200/391], Reconst Loss: 126.95375, KL Div: 10.28106, Total Loss: 137.23481
Epoch[9/100], Step [210/391], Reconst Loss: 124.78717, KL Div: 10.77095, Total Loss: 135.55812
Epoch[9/100], Step [220/391], Reconst Loss: 124.41996, KL Div: 10.17006, Total Loss: 134.59002
Epoch[9/100], Step [230/391], Reconst Loss: 123.42870, KL Div: 10.26889, Total Loss: 133.69758
Epoch[9/100], Step [240/391], Reconst Loss: 132.57726, KL Div: 10.16694, Total Loss: 142.74420
Epoch[9/100], Step [250/391], Reconst Loss: 124.95739, KL Div: 10.47413, Total Loss: 135.43151
Epoch[9/100], Step [260/391], Reconst Loss: 130.29233, KL Div: 10.42854, Total Loss: 140.72087
Epoch[9/100], Step [270/391], Reconst Loss: 126.80342, KL Div: 10.25474, Total Loss: 137.05816
Epoch[9/100], Step [280/391], Reconst Loss: 123.47057, KL Div: 9.97384, Total Loss: 133.44441
Epoch[9/100], Step [290/391], Reconst Loss: 120.84377, KL Div: 9.76565, Total Loss: 130.60943
Epoch[9/100], Step [300/391], Reconst Loss: 128.55180, KL Div: 10.28908, Total Loss: 138.84088
Epoch[9/100], Step [310/391], Reconst Loss: 128.17159, KL Div: 10.52308, Total Loss: 138.69467
Epoch[9/100], Step [320/391], Reconst Loss: 127.63710, KL Div: 10.07847, Total Loss: 137.71557
Epoch[9/100], Step [330/391], Reconst Loss: 123.56856, KL Div: 10.39996, Total Loss: 133.96852
Epoch[9/100], Step [340/391], Reconst Loss: 124.84052, KL Div: 9.86260, Total Loss: 134.70312
Epoch[9/100], Step [350/391], Reconst Loss: 123.19724, KL Div: 10.25449, Total Loss: 133.45173
Epoch[9/100], Step [360/391], Reconst Loss: 131.53281, KL Div: 10.15879, Total Loss: 141.69160
Epoch[9/100], Step [370/391], Reconst Loss: 124.19114, KL Div: 10.01542, Total Loss: 134.20655
Epoch[9/100], Step [380/391], Reconst Loss: 119.18041, KL Div: 10.17936, Total Loss: 129.35977
Epoch[9/100], Step [390/391], Reconst Loss: 130.90599, KL Div: 10.36162, Total Loss: 141.26761
Epoch = 9
Training epoch time =  139.20171451568604
train total loss =  134.19190158203125
valid total loss =  134.85650490722657
Total epoch time =  257.39000725746155
Saving checkpoint...
Done!
Epoch[10/100], Step [10/391], Reconst Loss: 128.08542, KL Div: 10.01046, Total Loss: 138.09588
Epoch[10/100], Step [20/391], Reconst Loss: 121.05849, KL Div: 10.33338, Total Loss: 131.39188
Epoch[10/100], Step [30/391], Reconst Loss: 126.21936, KL Div: 10.16050, Total Loss: 136.37986
Epoch[10/100], Step [40/391], Reconst Loss: 120.52376, KL Div: 9.95996, Total Loss: 130.48372
Epoch[10/100], Step [50/391], Reconst Loss: 128.56938, KL Div: 9.88419, Total Loss: 138.45357
Epoch[10/100], Step [60/391], Reconst Loss: 126.36312, KL Div: 10.28593, Total Loss: 136.64905
Epoch[10/100], Step [70/391], Reconst Loss: 129.95197, KL Div: 9.94584, Total Loss: 139.89781
Epoch[10/100], Step [80/391], Reconst Loss: 129.49239, KL Div: 9.96255, Total Loss: 139.45494
Epoch[10/100], Step [90/391], Reconst Loss: 124.32632, KL Div: 10.93733, Total Loss: 135.26365
Epoch[10/100], Step [100/391], Reconst Loss: 122.49995, KL Div: 10.33048, Total Loss: 132.83044
Epoch[10/100], Step [110/391], Reconst Loss: 124.90718, KL Div: 10.54038, Total Loss: 135.44756
Epoch[10/100], Step [120/391], Reconst Loss: 125.90585, KL Div: 10.51690, Total Loss: 136.42274
Epoch[10/100], Step [130/391], Reconst Loss: 126.16069, KL Div: 10.05318, Total Loss: 136.21387
Epoch[10/100], Step [140/391], Reconst Loss: 122.46787, KL Div: 10.13825, Total Loss: 132.60613
Epoch[10/100], Step [150/391], Reconst Loss: 119.58219, KL Div: 9.99996, Total Loss: 129.58215
Epoch[10/100], Step [160/391], Reconst Loss: 131.18793, KL Div: 10.32884, Total Loss: 141.51677
Epoch[10/100], Step [170/391], Reconst Loss: 129.16133, KL Div: 10.46992, Total Loss: 139.63125
Epoch[10/100], Step [180/391], Reconst Loss: 124.58508, KL Div: 10.26284, Total Loss: 134.84793
Epoch[10/100], Step [190/391], Reconst Loss: 119.69180, KL Div: 10.26313, Total Loss: 129.95493
Epoch[10/100], Step [200/391], Reconst Loss: 123.17403, KL Div: 10.27291, Total Loss: 133.44693
Epoch[10/100], Step [210/391], Reconst Loss: 122.01729, KL Div: 10.18906, Total Loss: 132.20635
Epoch[10/100], Step [220/391], Reconst Loss: 122.26399, KL Div: 9.95705, Total Loss: 132.22104
Epoch[10/100], Step [230/391], Reconst Loss: 116.98692, KL Div: 10.00330, Total Loss: 126.99022
Epoch[10/100], Step [240/391], Reconst Loss: 127.82755, KL Div: 10.20982, Total Loss: 138.03736
Epoch[10/100], Step [250/391], Reconst Loss: 125.26299, KL Div: 10.05088, Total Loss: 135.31386
Epoch[10/100], Step [260/391], Reconst Loss: 127.85501, KL Div: 9.98788, Total Loss: 137.84290
Epoch[10/100], Step [270/391], Reconst Loss: 124.39436, KL Div: 10.16266, Total Loss: 134.55701
Epoch[10/100], Step [280/391], Reconst Loss: 130.10127, KL Div: 10.07451, Total Loss: 140.17578
Epoch[10/100], Step [290/391], Reconst Loss: 120.58015, KL Div: 9.58884, Total Loss: 130.16900
Epoch[10/100], Step [300/391], Reconst Loss: 125.03178, KL Div: 9.99356, Total Loss: 135.02535
Epoch[10/100], Step [310/391], Reconst Loss: 126.72305, KL Div: 10.29548, Total Loss: 137.01853
Epoch[10/100], Step [320/391], Reconst Loss: 121.41937, KL Div: 9.75863, Total Loss: 131.17801
Epoch[10/100], Step [330/391], Reconst Loss: 126.91936, KL Div: 9.69402, Total Loss: 136.61338
Epoch[10/100], Step [340/391], Reconst Loss: 120.04843, KL Div: 10.07312, Total Loss: 130.12156
Epoch[10/100], Step [350/391], Reconst Loss: 117.28825, KL Div: 10.14997, Total Loss: 127.43822
Epoch[10/100], Step [360/391], Reconst Loss: 122.61630, KL Div: 10.38049, Total Loss: 132.99679
Epoch[10/100], Step [370/391], Reconst Loss: 128.79121, KL Div: 10.45567, Total Loss: 139.24688
Epoch[10/100], Step [380/391], Reconst Loss: 125.96367, KL Div: 10.29339, Total Loss: 136.25706
Epoch[10/100], Step [390/391], Reconst Loss: 118.66811, KL Div: 9.99861, Total Loss: 128.66672
Epoch = 10
Training epoch time =  139.27548813819885
train total loss =  133.87730072265626
valid total loss =  134.5422764892578
Total epoch time =  257.7794315814972
Saving checkpoint...
Done!
Epoch[11/100], Step [10/391], Reconst Loss: 124.36168, KL Div: 10.52297, Total Loss: 134.88465
Epoch[11/100], Step [20/391], Reconst Loss: 119.42914, KL Div: 10.41337, Total Loss: 129.84250
Epoch[11/100], Step [30/391], Reconst Loss: 122.13567, KL Div: 10.15549, Total Loss: 132.29116
Epoch[11/100], Step [40/391], Reconst Loss: 126.69963, KL Div: 10.79626, Total Loss: 137.49589
Epoch[11/100], Step [50/391], Reconst Loss: 118.95201, KL Div: 10.02008, Total Loss: 128.97209
Epoch[11/100], Step [60/391], Reconst Loss: 124.28364, KL Div: 10.56726, Total Loss: 134.85089
Epoch[11/100], Step [70/391], Reconst Loss: 127.21308, KL Div: 10.44336, Total Loss: 137.65644
Epoch[11/100], Step [80/391], Reconst Loss: 125.41801, KL Div: 10.23863, Total Loss: 135.65664
Epoch[11/100], Step [90/391], Reconst Loss: 119.47107, KL Div: 9.81906, Total Loss: 129.29013
Epoch[11/100], Step [100/391], Reconst Loss: 123.84127, KL Div: 10.02842, Total Loss: 133.86969
Epoch[11/100], Step [110/391], Reconst Loss: 124.55965, KL Div: 10.54267, Total Loss: 135.10232
Epoch[11/100], Step [120/391], Reconst Loss: 123.66600, KL Div: 10.24082, Total Loss: 133.90682
Epoch[11/100], Step [130/391], Reconst Loss: 123.64264, KL Div: 10.35394, Total Loss: 133.99658
Epoch[11/100], Step [140/391], Reconst Loss: 117.40015, KL Div: 9.83006, Total Loss: 127.23021
Epoch[11/100], Step [150/391], Reconst Loss: 118.32948, KL Div: 10.14092, Total Loss: 128.47040
Epoch[11/100], Step [160/391], Reconst Loss: 126.29452, KL Div: 10.08359, Total Loss: 136.37810
Epoch[11/100], Step [170/391], Reconst Loss: 123.76733, KL Div: 10.34865, Total Loss: 134.11598
Epoch[11/100], Step [180/391], Reconst Loss: 127.12724, KL Div: 10.01341, Total Loss: 137.14065
Epoch[11/100], Step [190/391], Reconst Loss: 121.44177, KL Div: 9.91704, Total Loss: 131.35881
Epoch[11/100], Step [200/391], Reconst Loss: 125.46677, KL Div: 10.12549, Total Loss: 135.59226
Epoch[11/100], Step [210/391], Reconst Loss: 117.65914, KL Div: 10.41321, Total Loss: 128.07235
Epoch[11/100], Step [220/391], Reconst Loss: 124.65249, KL Div: 10.07685, Total Loss: 134.72934
Epoch[11/100], Step [230/391], Reconst Loss: 128.62744, KL Div: 9.94082, Total Loss: 138.56826
Epoch[11/100], Step [240/391], Reconst Loss: 123.76580, KL Div: 10.48743, Total Loss: 134.25323
Epoch[11/100], Step [250/391], Reconst Loss: 124.98691, KL Div: 10.52429, Total Loss: 135.51120
Epoch[11/100], Step [260/391], Reconst Loss: 121.62907, KL Div: 10.57055, Total Loss: 132.19962
Epoch[11/100], Step [270/391], Reconst Loss: 126.09174, KL Div: 10.49474, Total Loss: 136.58648
Epoch[11/100], Step [280/391], Reconst Loss: 124.05646, KL Div: 10.25368, Total Loss: 134.31014
Epoch[11/100], Step [290/391], Reconst Loss: 126.02924, KL Div: 9.83995, Total Loss: 135.86919
Epoch[11/100], Step [300/391], Reconst Loss: 119.36271, KL Div: 10.49864, Total Loss: 129.86135
Epoch[11/100], Step [310/391], Reconst Loss: 123.94533, KL Div: 10.56350, Total Loss: 134.50883
Epoch[11/100], Step [320/391], Reconst Loss: 127.28326, KL Div: 10.57645, Total Loss: 137.85972
Epoch[11/100], Step [330/391], Reconst Loss: 120.12279, KL Div: 10.46149, Total Loss: 130.58428
Epoch[11/100], Step [340/391], Reconst Loss: 125.45438, KL Div: 9.82837, Total Loss: 135.28274
Epoch[11/100], Step [350/391], Reconst Loss: 120.27887, KL Div: 10.24624, Total Loss: 130.52511
Epoch[11/100], Step [360/391], Reconst Loss: 120.62625, KL Div: 10.41022, Total Loss: 131.03647
Epoch[11/100], Step [370/391], Reconst Loss: 121.25288, KL Div: 9.97431, Total Loss: 131.22719
Epoch[11/100], Step [380/391], Reconst Loss: 130.13220, KL Div: 10.13321, Total Loss: 140.26541
Epoch[11/100], Step [390/391], Reconst Loss: 122.06393, KL Div: 10.37689, Total Loss: 132.44082
Epoch = 11
Training epoch time =  140.00675892829895
train total loss =  133.15897583984375
valid total loss =  133.90769948730468
Total epoch time =  258.17224311828613
Saving checkpoint...
Done!
Epoch[12/100], Step [10/391], Reconst Loss: 119.17558, KL Div: 10.65221, Total Loss: 129.82780
Epoch[12/100], Step [20/391], Reconst Loss: 125.56251, KL Div: 10.31555, Total Loss: 135.87806
Epoch[12/100], Step [30/391], Reconst Loss: 116.85837, KL Div: 10.31605, Total Loss: 127.17441
Epoch[12/100], Step [40/391], Reconst Loss: 125.93411, KL Div: 10.28460, Total Loss: 136.21872
Epoch[12/100], Step [50/391], Reconst Loss: 119.17702, KL Div: 10.20390, Total Loss: 129.38092
Epoch[12/100], Step [60/391], Reconst Loss: 123.92872, KL Div: 10.20924, Total Loss: 134.13796
Epoch[12/100], Step [70/391], Reconst Loss: 124.31155, KL Div: 10.38174, Total Loss: 134.69329
Epoch[12/100], Step [80/391], Reconst Loss: 118.21091, KL Div: 10.48451, Total Loss: 128.69542
Epoch[12/100], Step [90/391], Reconst Loss: 123.26788, KL Div: 10.36589, Total Loss: 133.63377
Epoch[12/100], Step [100/391], Reconst Loss: 122.26527, KL Div: 10.28328, Total Loss: 132.54856
Epoch[12/100], Step [110/391], Reconst Loss: 120.90663, KL Div: 10.21923, Total Loss: 131.12586
Epoch[12/100], Step [120/391], Reconst Loss: 122.39935, KL Div: 10.16759, Total Loss: 132.56694
Epoch[12/100], Step [130/391], Reconst Loss: 117.30353, KL Div: 10.31205, Total Loss: 127.61557
Epoch[12/100], Step [140/391], Reconst Loss: 123.29071, KL Div: 10.76078, Total Loss: 134.05149
Epoch[12/100], Step [150/391], Reconst Loss: 115.47148, KL Div: 10.49053, Total Loss: 125.96201
Epoch[12/100], Step [160/391], Reconst Loss: 122.61071, KL Div: 10.49995, Total Loss: 133.11066
Epoch[12/100], Step [170/391], Reconst Loss: 118.00093, KL Div: 10.61358, Total Loss: 128.61451
Epoch[12/100], Step [180/391], Reconst Loss: 120.52864, KL Div: 10.43081, Total Loss: 130.95945
Epoch[12/100], Step [190/391], Reconst Loss: 120.18382, KL Div: 9.68843, Total Loss: 129.87224
Epoch[12/100], Step [200/391], Reconst Loss: 119.37425, KL Div: 10.86415, Total Loss: 130.23840
Epoch[12/100], Step [210/391], Reconst Loss: 130.20471, KL Div: 10.18107, Total Loss: 140.38578
Epoch[12/100], Step [220/391], Reconst Loss: 117.15413, KL Div: 10.61176, Total Loss: 127.76588
Epoch[12/100], Step [230/391], Reconst Loss: 124.64301, KL Div: 10.36111, Total Loss: 135.00412
Epoch[12/100], Step [240/391], Reconst Loss: 122.34919, KL Div: 10.08985, Total Loss: 132.43904
Epoch[12/100], Step [250/391], Reconst Loss: 122.97385, KL Div: 10.57336, Total Loss: 133.54720
Epoch[12/100], Step [260/391], Reconst Loss: 120.53426, KL Div: 9.95832, Total Loss: 130.49259
Epoch[12/100], Step [270/391], Reconst Loss: 121.70550, KL Div: 10.48708, Total Loss: 132.19258
Epoch[12/100], Step [280/391], Reconst Loss: 125.22392, KL Div: 10.20211, Total Loss: 135.42603
Epoch[12/100], Step [290/391], Reconst Loss: 120.57353, KL Div: 10.98647, Total Loss: 131.56000
Epoch[12/100], Step [300/391], Reconst Loss: 125.30916, KL Div: 10.11987, Total Loss: 135.42903
Epoch[12/100], Step [310/391], Reconst Loss: 127.67928, KL Div: 10.66188, Total Loss: 138.34116
Epoch[12/100], Step [320/391], Reconst Loss: 123.43187, KL Div: 10.17476, Total Loss: 133.60663
Epoch[12/100], Step [330/391], Reconst Loss: 118.46438, KL Div: 10.06036, Total Loss: 128.52474
Epoch[12/100], Step [340/391], Reconst Loss: 122.61538, KL Div: 10.35176, Total Loss: 132.96714
Epoch[12/100], Step [350/391], Reconst Loss: 126.57561, KL Div: 10.53210, Total Loss: 137.10771
Epoch[12/100], Step [360/391], Reconst Loss: 123.77461, KL Div: 10.84555, Total Loss: 134.62017
Epoch[12/100], Step [370/391], Reconst Loss: 125.85466, KL Div: 10.66438, Total Loss: 136.51904
Epoch[12/100], Step [380/391], Reconst Loss: 125.38805, KL Div: 10.38444, Total Loss: 135.77248
Epoch[12/100], Step [390/391], Reconst Loss: 122.66127, KL Div: 10.74433, Total Loss: 133.40560
Epoch = 12
Training epoch time =  139.6066448688507
train total loss =  132.70886599609375
valid total loss =  133.62696145019532
Total epoch time =  257.57214522361755
Saving checkpoint...
Done!
Epoch[13/100], Step [10/391], Reconst Loss: 124.82750, KL Div: 10.09207, Total Loss: 134.91957
Epoch[13/100], Step [20/391], Reconst Loss: 120.47583, KL Div: 10.53131, Total Loss: 131.00714
Epoch[13/100], Step [30/391], Reconst Loss: 116.78815, KL Div: 10.30584, Total Loss: 127.09399
Epoch[13/100], Step [40/391], Reconst Loss: 121.88105, KL Div: 11.15756, Total Loss: 133.03861
Epoch[13/100], Step [50/391], Reconst Loss: 126.27633, KL Div: 10.23401, Total Loss: 136.51034
Epoch[13/100], Step [60/391], Reconst Loss: 123.77158, KL Div: 10.50152, Total Loss: 134.27310
Epoch[13/100], Step [70/391], Reconst Loss: 125.09511, KL Div: 10.36194, Total Loss: 135.45705
Epoch[13/100], Step [80/391], Reconst Loss: 123.23128, KL Div: 10.58199, Total Loss: 133.81327
Epoch[13/100], Step [90/391], Reconst Loss: 118.11455, KL Div: 10.69006, Total Loss: 128.80461
Epoch[13/100], Step [100/391], Reconst Loss: 120.73470, KL Div: 10.43154, Total Loss: 131.16624
Epoch[13/100], Step [110/391], Reconst Loss: 128.26460, KL Div: 9.98044, Total Loss: 138.24504
Epoch[13/100], Step [120/391], Reconst Loss: 118.92743, KL Div: 10.73974, Total Loss: 129.66717
Epoch[13/100], Step [130/391], Reconst Loss: 118.49302, KL Div: 10.61607, Total Loss: 129.10909
Epoch[13/100], Step [140/391], Reconst Loss: 122.02738, KL Div: 10.48646, Total Loss: 132.51384
Epoch[13/100], Step [150/391], Reconst Loss: 116.20085, KL Div: 10.50186, Total Loss: 126.70271
Epoch[13/100], Step [160/391], Reconst Loss: 125.49797, KL Div: 9.96752, Total Loss: 135.46549
Epoch[13/100], Step [170/391], Reconst Loss: 116.48745, KL Div: 10.46632, Total Loss: 126.95377
Epoch[13/100], Step [180/391], Reconst Loss: 124.21667, KL Div: 10.49247, Total Loss: 134.70915
Epoch[13/100], Step [190/391], Reconst Loss: 124.47536, KL Div: 10.40903, Total Loss: 134.88439
Epoch[13/100], Step [200/391], Reconst Loss: 123.86514, KL Div: 10.13047, Total Loss: 133.99560
Epoch[13/100], Step [210/391], Reconst Loss: 123.82717, KL Div: 10.68481, Total Loss: 134.51199
Epoch[13/100], Step [220/391], Reconst Loss: 117.57410, KL Div: 10.26312, Total Loss: 127.83722
Epoch[13/100], Step [230/391], Reconst Loss: 121.50522, KL Div: 10.66730, Total Loss: 132.17252
Epoch[13/100], Step [240/391], Reconst Loss: 122.47900, KL Div: 10.33771, Total Loss: 132.81671
Epoch[13/100], Step [250/391], Reconst Loss: 121.66740, KL Div: 10.76113, Total Loss: 132.42853
Epoch[13/100], Step [260/391], Reconst Loss: 120.75183, KL Div: 10.14900, Total Loss: 130.90083
Epoch[13/100], Step [270/391], Reconst Loss: 118.99605, KL Div: 10.15338, Total Loss: 129.14943
Epoch[13/100], Step [280/391], Reconst Loss: 125.19702, KL Div: 10.67679, Total Loss: 135.87381
Epoch[13/100], Step [290/391], Reconst Loss: 121.17075, KL Div: 10.56713, Total Loss: 131.73788
Epoch[13/100], Step [300/391], Reconst Loss: 125.47539, KL Div: 11.21050, Total Loss: 136.68589
Epoch[13/100], Step [310/391], Reconst Loss: 118.29943, KL Div: 10.50790, Total Loss: 128.80733
Epoch[13/100], Step [320/391], Reconst Loss: 127.49843, KL Div: 10.23979, Total Loss: 137.73822
Epoch[13/100], Step [330/391], Reconst Loss: 127.89607, KL Div: 10.56964, Total Loss: 138.46571
Epoch[13/100], Step [340/391], Reconst Loss: 128.94942, KL Div: 10.20099, Total Loss: 139.15041
Epoch[13/100], Step [350/391], Reconst Loss: 122.23360, KL Div: 10.34036, Total Loss: 132.57396
Epoch[13/100], Step [360/391], Reconst Loss: 120.15226, KL Div: 10.78674, Total Loss: 130.93900
Epoch[13/100], Step [370/391], Reconst Loss: 120.65416, KL Div: 10.63361, Total Loss: 131.28777
Epoch[13/100], Step [380/391], Reconst Loss: 123.60822, KL Div: 10.60032, Total Loss: 134.20853
Epoch[13/100], Step [390/391], Reconst Loss: 120.80040, KL Div: 10.46220, Total Loss: 131.26260
Epoch = 13
Training epoch time =  139.1443383693695
train total loss =  132.58739857421875
valid total loss =  133.42100357666015
Total epoch time =  257.48190355300903
Saving checkpoint...
Done!
Epoch[14/100], Step [10/391], Reconst Loss: 122.83514, KL Div: 10.43318, Total Loss: 133.26831
Epoch[14/100], Step [20/391], Reconst Loss: 120.36058, KL Div: 10.20969, Total Loss: 130.57027
Epoch[14/100], Step [30/391], Reconst Loss: 124.94145, KL Div: 11.10272, Total Loss: 136.04417
Epoch[14/100], Step [40/391], Reconst Loss: 120.20472, KL Div: 10.63027, Total Loss: 130.83499
Epoch[14/100], Step [50/391], Reconst Loss: 122.62079, KL Div: 10.36140, Total Loss: 132.98219
Epoch[14/100], Step [60/391], Reconst Loss: 123.22413, KL Div: 10.81020, Total Loss: 134.03432
Epoch[14/100], Step [70/391], Reconst Loss: 115.69337, KL Div: 10.57206, Total Loss: 126.26542
Epoch[14/100], Step [80/391], Reconst Loss: 121.59728, KL Div: 10.64724, Total Loss: 132.24452
Epoch[14/100], Step [90/391], Reconst Loss: 123.74536, KL Div: 10.70305, Total Loss: 134.44841
Epoch[14/100], Step [100/391], Reconst Loss: 120.63573, KL Div: 10.82638, Total Loss: 131.46212
Epoch[14/100], Step [110/391], Reconst Loss: 118.89935, KL Div: 10.48065, Total Loss: 129.38000
Epoch[14/100], Step [120/391], Reconst Loss: 127.64403, KL Div: 10.97784, Total Loss: 138.62186
Epoch[14/100], Step [130/391], Reconst Loss: 117.62582, KL Div: 10.46122, Total Loss: 128.08705
Epoch[14/100], Step [140/391], Reconst Loss: 121.49358, KL Div: 10.54704, Total Loss: 132.04061
Epoch[14/100], Step [150/391], Reconst Loss: 123.50881, KL Div: 10.24073, Total Loss: 133.74954
Epoch[14/100], Step [160/391], Reconst Loss: 122.37053, KL Div: 9.94344, Total Loss: 132.31397
Epoch[14/100], Step [170/391], Reconst Loss: 125.43800, KL Div: 10.37907, Total Loss: 135.81708
Epoch[14/100], Step [180/391], Reconst Loss: 121.32355, KL Div: 10.06410, Total Loss: 131.38765
Epoch[14/100], Step [190/391], Reconst Loss: 122.96053, KL Div: 10.67121, Total Loss: 133.63173
Epoch[14/100], Step [200/391], Reconst Loss: 127.90457, KL Div: 10.67370, Total Loss: 138.57827
Epoch[14/100], Step [210/391], Reconst Loss: 120.90781, KL Div: 10.67385, Total Loss: 131.58165
Epoch[14/100], Step [220/391], Reconst Loss: 133.25211, KL Div: 10.76881, Total Loss: 144.02092
Epoch[14/100], Step [230/391], Reconst Loss: 122.72246, KL Div: 10.79054, Total Loss: 133.51299
Epoch[14/100], Step [240/391], Reconst Loss: 122.36359, KL Div: 10.70813, Total Loss: 133.07172
Epoch[14/100], Step [250/391], Reconst Loss: 124.20821, KL Div: 10.63696, Total Loss: 134.84518
Epoch[14/100], Step [260/391], Reconst Loss: 123.78761, KL Div: 10.21700, Total Loss: 134.00462
Epoch[14/100], Step [270/391], Reconst Loss: 124.79373, KL Div: 10.52895, Total Loss: 135.32268
Epoch[14/100], Step [280/391], Reconst Loss: 133.57974, KL Div: 10.13850, Total Loss: 143.71825
Epoch[14/100], Step [290/391], Reconst Loss: 118.54297, KL Div: 10.68284, Total Loss: 129.22581
Epoch[14/100], Step [300/391], Reconst Loss: 123.69506, KL Div: 10.27776, Total Loss: 133.97282
Epoch[14/100], Step [310/391], Reconst Loss: 128.27789, KL Div: 10.39166, Total Loss: 138.66956
Epoch[14/100], Step [320/391], Reconst Loss: 115.83914, KL Div: 10.48466, Total Loss: 126.32381
Epoch[14/100], Step [330/391], Reconst Loss: 120.88651, KL Div: 10.88866, Total Loss: 131.77518
Epoch[14/100], Step [340/391], Reconst Loss: 122.22129, KL Div: 10.22115, Total Loss: 132.44244
Epoch[14/100], Step [350/391], Reconst Loss: 122.49995, KL Div: 10.48354, Total Loss: 132.98350
Epoch[14/100], Step [360/391], Reconst Loss: 129.59915, KL Div: 10.92201, Total Loss: 140.52117
Epoch[14/100], Step [370/391], Reconst Loss: 123.46223, KL Div: 10.41560, Total Loss: 133.87783
Epoch[14/100], Step [380/391], Reconst Loss: 118.64307, KL Div: 10.57837, Total Loss: 129.22145
Epoch[14/100], Step [390/391], Reconst Loss: 125.02591, KL Div: 10.11367, Total Loss: 135.13958
Epoch = 14
Training epoch time =  139.04277968406677
train total loss =  132.7244571875
valid total loss =  133.3893895751953
Total epoch time =  257.2233633995056
Saving checkpoint...
Done!
Epoch[15/100], Step [10/391], Reconst Loss: 123.61403, KL Div: 10.08877, Total Loss: 133.70280
Epoch[15/100], Step [20/391], Reconst Loss: 123.78346, KL Div: 10.79833, Total Loss: 134.58179
Epoch[15/100], Step [30/391], Reconst Loss: 125.40903, KL Div: 10.09700, Total Loss: 135.50603
Epoch[15/100], Step [40/391], Reconst Loss: 122.42004, KL Div: 10.75455, Total Loss: 133.17459
Epoch[15/100], Step [50/391], Reconst Loss: 123.18234, KL Div: 10.29097, Total Loss: 133.47332
Epoch[15/100], Step [60/391], Reconst Loss: 124.67835, KL Div: 10.29167, Total Loss: 134.97002
Epoch[15/100], Step [70/391], Reconst Loss: 131.82542, KL Div: 10.74374, Total Loss: 142.56917
Epoch[15/100], Step [80/391], Reconst Loss: 119.47884, KL Div: 10.81707, Total Loss: 130.29592
Epoch[15/100], Step [90/391], Reconst Loss: 123.82543, KL Div: 10.31344, Total Loss: 134.13887
Epoch[15/100], Step [100/391], Reconst Loss: 121.52455, KL Div: 11.26234, Total Loss: 132.78689
Epoch[15/100], Step [110/391], Reconst Loss: 123.02340, KL Div: 10.48847, Total Loss: 133.51187
Epoch[15/100], Step [120/391], Reconst Loss: 126.04604, KL Div: 10.61257, Total Loss: 136.65861
Epoch[15/100], Step [130/391], Reconst Loss: 121.44707, KL Div: 10.55571, Total Loss: 132.00277
Epoch[15/100], Step [140/391], Reconst Loss: 124.48555, KL Div: 10.81540, Total Loss: 135.30095
Epoch[15/100], Step [150/391], Reconst Loss: 123.18724, KL Div: 10.42984, Total Loss: 133.61708
Epoch[15/100], Step [160/391], Reconst Loss: 126.70654, KL Div: 10.39604, Total Loss: 137.10257
Epoch[15/100], Step [170/391], Reconst Loss: 120.80446, KL Div: 10.55302, Total Loss: 131.35748
Epoch[15/100], Step [180/391], Reconst Loss: 127.44157, KL Div: 10.50257, Total Loss: 137.94415
Epoch[15/100], Step [190/391], Reconst Loss: 122.46619, KL Div: 10.73390, Total Loss: 133.20010
Epoch[15/100], Step [200/391], Reconst Loss: 121.45900, KL Div: 10.49242, Total Loss: 131.95142
Epoch[15/100], Step [210/391], Reconst Loss: 117.62054, KL Div: 10.37374, Total Loss: 127.99428
Epoch[15/100], Step [220/391], Reconst Loss: 125.05067, KL Div: 10.68521, Total Loss: 135.73588
Epoch[15/100], Step [230/391], Reconst Loss: 124.01467, KL Div: 10.45452, Total Loss: 134.46919
Epoch[15/100], Step [240/391], Reconst Loss: 121.26966, KL Div: 10.44660, Total Loss: 131.71626
Epoch[15/100], Step [250/391], Reconst Loss: 120.39494, KL Div: 10.02867, Total Loss: 130.42361
Epoch[15/100], Step [260/391], Reconst Loss: 123.85700, KL Div: 10.79188, Total Loss: 134.64888
Epoch[15/100], Step [270/391], Reconst Loss: 117.22956, KL Div: 10.47224, Total Loss: 127.70180
Epoch[15/100], Step [280/391], Reconst Loss: 118.67780, KL Div: 10.38419, Total Loss: 129.06199
Epoch[15/100], Step [290/391], Reconst Loss: 122.51708, KL Div: 10.57524, Total Loss: 133.09232
Epoch[15/100], Step [300/391], Reconst Loss: 121.32869, KL Div: 10.45115, Total Loss: 131.77984
Epoch[15/100], Step [310/391], Reconst Loss: 119.19364, KL Div: 9.95791, Total Loss: 129.15155
Epoch[15/100], Step [320/391], Reconst Loss: 123.84518, KL Div: 10.76387, Total Loss: 134.60904
Epoch[15/100], Step [330/391], Reconst Loss: 121.26830, KL Div: 10.14294, Total Loss: 131.41124
Epoch[15/100], Step [340/391], Reconst Loss: 122.35640, KL Div: 10.42611, Total Loss: 132.78251
Epoch[15/100], Step [350/391], Reconst Loss: 127.22987, KL Div: 10.35458, Total Loss: 137.58444
Epoch[15/100], Step [360/391], Reconst Loss: 116.95714, KL Div: 10.45864, Total Loss: 127.41578
Epoch[15/100], Step [370/391], Reconst Loss: 119.94255, KL Div: 10.41705, Total Loss: 130.35960
Epoch[15/100], Step [380/391], Reconst Loss: 119.55428, KL Div: 10.57446, Total Loss: 130.12873
Epoch[15/100], Step [390/391], Reconst Loss: 122.98788, KL Div: 10.78216, Total Loss: 133.77004
Epoch = 15
Training epoch time =  139.47350788116455
train total loss =  131.76627330078125
valid total loss =  132.6336900878906
Total epoch time =  257.8713881969452
Saving checkpoint...
Done!
Epoch[16/100], Step [10/391], Reconst Loss: 122.00366, KL Div: 10.09027, Total Loss: 132.09393
Epoch[16/100], Step [20/391], Reconst Loss: 125.57510, KL Div: 9.91818, Total Loss: 135.49327
Epoch[16/100], Step [30/391], Reconst Loss: 117.08014, KL Div: 10.79033, Total Loss: 127.87047
Epoch[16/100], Step [40/391], Reconst Loss: 117.18178, KL Div: 10.34526, Total Loss: 127.52703
Epoch[16/100], Step [50/391], Reconst Loss: 125.52079, KL Div: 10.34852, Total Loss: 135.86931
Epoch[16/100], Step [60/391], Reconst Loss: 126.25049, KL Div: 10.65659, Total Loss: 136.90708
Epoch[16/100], Step [70/391], Reconst Loss: 116.37200, KL Div: 10.52525, Total Loss: 126.89725
Epoch[16/100], Step [80/391], Reconst Loss: 125.09942, KL Div: 10.59219, Total Loss: 135.69161
Epoch[16/100], Step [90/391], Reconst Loss: 120.09803, KL Div: 10.41679, Total Loss: 130.51482
Epoch[16/100], Step [100/391], Reconst Loss: 124.17747, KL Div: 10.39786, Total Loss: 134.57533
Epoch[16/100], Step [110/391], Reconst Loss: 120.86549, KL Div: 10.42742, Total Loss: 131.29291
Epoch[16/100], Step [120/391], Reconst Loss: 124.15405, KL Div: 10.97235, Total Loss: 135.12640
Epoch[16/100], Step [130/391], Reconst Loss: 122.32378, KL Div: 10.53118, Total Loss: 132.85496
Epoch[16/100], Step [140/391], Reconst Loss: 122.13864, KL Div: 10.41140, Total Loss: 132.55004
Epoch[16/100], Step [150/391], Reconst Loss: 124.28293, KL Div: 10.41636, Total Loss: 134.69929
Epoch[16/100], Step [160/391], Reconst Loss: 128.05467, KL Div: 10.83751, Total Loss: 138.89218
Epoch[16/100], Step [170/391], Reconst Loss: 120.59225, KL Div: 10.61320, Total Loss: 131.20544
Epoch[16/100], Step [180/391], Reconst Loss: 122.11852, KL Div: 10.63019, Total Loss: 132.74870
Epoch[16/100], Step [190/391], Reconst Loss: 125.06203, KL Div: 10.32181, Total Loss: 135.38384
Epoch[16/100], Step [200/391], Reconst Loss: 120.67940, KL Div: 10.71434, Total Loss: 131.39374
Epoch[16/100], Step [210/391], Reconst Loss: 122.44310, KL Div: 11.07063, Total Loss: 133.51373
Epoch[16/100], Step [220/391], Reconst Loss: 120.22979, KL Div: 10.51132, Total Loss: 130.74111
Epoch[16/100], Step [230/391], Reconst Loss: 116.40331, KL Div: 10.46078, Total Loss: 126.86408
Epoch[16/100], Step [240/391], Reconst Loss: 121.91090, KL Div: 10.56041, Total Loss: 132.47131
Epoch[16/100], Step [250/391], Reconst Loss: 119.26749, KL Div: 10.41061, Total Loss: 129.67810
Epoch[16/100], Step [260/391], Reconst Loss: 129.98572, KL Div: 10.65298, Total Loss: 140.63870
Epoch[16/100], Step [270/391], Reconst Loss: 124.57314, KL Div: 10.63498, Total Loss: 135.20813
Epoch[16/100], Step [280/391], Reconst Loss: 119.94759, KL Div: 10.77210, Total Loss: 130.71969
Epoch[16/100], Step [290/391], Reconst Loss: 121.41808, KL Div: 11.02195, Total Loss: 132.44003
Epoch[16/100], Step [300/391], Reconst Loss: 120.08389, KL Div: 10.56385, Total Loss: 130.64774
Epoch[16/100], Step [310/391], Reconst Loss: 117.27303, KL Div: 10.51054, Total Loss: 127.78357
Epoch[16/100], Step [320/391], Reconst Loss: 119.23523, KL Div: 10.81970, Total Loss: 130.05493
Epoch[16/100], Step [330/391], Reconst Loss: 126.25656, KL Div: 10.51998, Total Loss: 136.77654
Epoch[16/100], Step [340/391], Reconst Loss: 122.76471, KL Div: 11.10772, Total Loss: 133.87243
Epoch[16/100], Step [350/391], Reconst Loss: 125.75349, KL Div: 10.51159, Total Loss: 136.26509
Epoch[16/100], Step [360/391], Reconst Loss: 122.17215, KL Div: 10.46384, Total Loss: 132.63599
Epoch[16/100], Step [370/391], Reconst Loss: 120.29095, KL Div: 10.99842, Total Loss: 131.28938
Epoch[16/100], Step [380/391], Reconst Loss: 125.29624, KL Div: 10.54807, Total Loss: 135.84431
Epoch[16/100], Step [390/391], Reconst Loss: 122.42573, KL Div: 10.79565, Total Loss: 133.22137
Epoch = 16
Training epoch time =  138.95509696006775
train total loss =  131.210543984375
valid total loss =  131.94051713867188
Total epoch time =  257.0152726173401
Saving checkpoint...
Done!
Epoch[17/100], Step [10/391], Reconst Loss: 118.96687, KL Div: 10.44251, Total Loss: 129.40939
Epoch[17/100], Step [20/391], Reconst Loss: 123.39455, KL Div: 11.12351, Total Loss: 134.51805
Epoch[17/100], Step [30/391], Reconst Loss: 118.86774, KL Div: 10.59765, Total Loss: 129.46539
Epoch[17/100], Step [40/391], Reconst Loss: 126.18597, KL Div: 10.67770, Total Loss: 136.86367
Epoch[17/100], Step [50/391], Reconst Loss: 123.52155, KL Div: 9.86289, Total Loss: 133.38444
Epoch[17/100], Step [60/391], Reconst Loss: 121.75117, KL Div: 10.54346, Total Loss: 132.29464
Epoch[17/100], Step [70/391], Reconst Loss: 122.73870, KL Div: 10.65709, Total Loss: 133.39579
Epoch[17/100], Step [80/391], Reconst Loss: 120.90646, KL Div: 10.52670, Total Loss: 131.43317
Epoch[17/100], Step [90/391], Reconst Loss: 119.48035, KL Div: 10.66889, Total Loss: 130.14924
Epoch[17/100], Step [100/391], Reconst Loss: 122.74336, KL Div: 10.39340, Total Loss: 133.13676
Epoch[17/100], Step [110/391], Reconst Loss: 119.85106, KL Div: 10.91590, Total Loss: 130.76696
Epoch[17/100], Step [120/391], Reconst Loss: 124.12840, KL Div: 10.53610, Total Loss: 134.66449
Epoch[17/100], Step [130/391], Reconst Loss: 124.45605, KL Div: 10.83366, Total Loss: 135.28971
Epoch[17/100], Step [140/391], Reconst Loss: 121.83956, KL Div: 10.82527, Total Loss: 132.66483
Epoch[17/100], Step [150/391], Reconst Loss: 124.09566, KL Div: 10.80954, Total Loss: 134.90519
Epoch[17/100], Step [160/391], Reconst Loss: 123.56471, KL Div: 10.55523, Total Loss: 134.11995
Epoch[17/100], Step [170/391], Reconst Loss: 124.64200, KL Div: 10.54548, Total Loss: 135.18748
Epoch[17/100], Step [180/391], Reconst Loss: 117.43872, KL Div: 10.65516, Total Loss: 128.09388
Epoch[17/100], Step [190/391], Reconst Loss: 121.54813, KL Div: 10.89517, Total Loss: 132.44329
Epoch[17/100], Step [200/391], Reconst Loss: 121.44188, KL Div: 10.40524, Total Loss: 131.84712
Epoch[17/100], Step [210/391], Reconst Loss: 124.11067, KL Div: 10.87549, Total Loss: 134.98617
Epoch[17/100], Step [220/391], Reconst Loss: 121.74025, KL Div: 10.92575, Total Loss: 132.66600
Epoch[17/100], Step [230/391], Reconst Loss: 120.35457, KL Div: 10.52896, Total Loss: 130.88353
Epoch[17/100], Step [240/391], Reconst Loss: 124.49104, KL Div: 10.59898, Total Loss: 135.09003
Epoch[17/100], Step [250/391], Reconst Loss: 122.53142, KL Div: 10.54971, Total Loss: 133.08113
Epoch[17/100], Step [260/391], Reconst Loss: 122.58789, KL Div: 10.33317, Total Loss: 132.92106
Epoch[17/100], Step [270/391], Reconst Loss: 125.66302, KL Div: 10.62360, Total Loss: 136.28662
Epoch[17/100], Step [280/391], Reconst Loss: 122.83154, KL Div: 10.59236, Total Loss: 133.42390
Epoch[17/100], Step [290/391], Reconst Loss: 125.11678, KL Div: 11.11378, Total Loss: 136.23056
Epoch[17/100], Step [300/391], Reconst Loss: 121.47180, KL Div: 10.75176, Total Loss: 132.22356
Epoch[17/100], Step [310/391], Reconst Loss: 114.90645, KL Div: 10.86102, Total Loss: 125.76747
Epoch[17/100], Step [320/391], Reconst Loss: 122.55975, KL Div: 10.62316, Total Loss: 133.18291
Epoch[17/100], Step [330/391], Reconst Loss: 121.59455, KL Div: 10.65357, Total Loss: 132.24813
Epoch[17/100], Step [340/391], Reconst Loss: 126.24399, KL Div: 10.31998, Total Loss: 136.56397
Epoch[17/100], Step [350/391], Reconst Loss: 124.12160, KL Div: 11.18787, Total Loss: 135.30947
Epoch[17/100], Step [360/391], Reconst Loss: 124.57777, KL Div: 10.55500, Total Loss: 135.13277
Epoch[17/100], Step [370/391], Reconst Loss: 121.39692, KL Div: 10.77887, Total Loss: 132.17579
Epoch[17/100], Step [380/391], Reconst Loss: 122.78971, KL Div: 10.92474, Total Loss: 133.71445
Epoch[17/100], Step [390/391], Reconst Loss: 113.71199, KL Div: 10.58228, Total Loss: 124.29427
Epoch = 17
Training epoch time =  139.35718488693237
train total loss =  131.15427107421874
valid total loss =  132.17415864257813
Total epoch time =  257.90012526512146
Saving checkpoint...
Done!
Epoch[18/100], Step [10/391], Reconst Loss: 123.65823, KL Div: 10.71031, Total Loss: 134.36855
Epoch[18/100], Step [20/391], Reconst Loss: 118.91602, KL Div: 11.02583, Total Loss: 129.94185
Epoch[18/100], Step [30/391], Reconst Loss: 120.51251, KL Div: 10.12138, Total Loss: 130.63389
Epoch[18/100], Step [40/391], Reconst Loss: 121.85059, KL Div: 10.20943, Total Loss: 132.06002
Epoch[18/100], Step [50/391], Reconst Loss: 130.88385, KL Div: 11.13460, Total Loss: 142.01845
Epoch[18/100], Step [60/391], Reconst Loss: 121.43253, KL Div: 10.77071, Total Loss: 132.20324
Epoch[18/100], Step [70/391], Reconst Loss: 125.11366, KL Div: 10.63944, Total Loss: 135.75310
Epoch[18/100], Step [80/391], Reconst Loss: 121.30692, KL Div: 10.98731, Total Loss: 132.29423
Epoch[18/100], Step [90/391], Reconst Loss: 124.09638, KL Div: 10.41773, Total Loss: 134.51411
Epoch[18/100], Step [100/391], Reconst Loss: 122.89491, KL Div: 10.81713, Total Loss: 133.71205
Epoch[18/100], Step [110/391], Reconst Loss: 127.30171, KL Div: 10.71674, Total Loss: 138.01845
Epoch[18/100], Step [120/391], Reconst Loss: 122.92943, KL Div: 10.59840, Total Loss: 133.52783
Epoch[18/100], Step [130/391], Reconst Loss: 126.83693, KL Div: 10.24133, Total Loss: 137.07826
Epoch[18/100], Step [140/391], Reconst Loss: 115.54115, KL Div: 11.01331, Total Loss: 126.55446
Epoch[18/100], Step [150/391], Reconst Loss: 115.87426, KL Div: 10.88371, Total Loss: 126.75797
Epoch[18/100], Step [160/391], Reconst Loss: 120.52592, KL Div: 10.55506, Total Loss: 131.08098
Epoch[18/100], Step [170/391], Reconst Loss: 119.72745, KL Div: 10.92133, Total Loss: 130.64878
Epoch[18/100], Step [180/391], Reconst Loss: 124.36410, KL Div: 10.68413, Total Loss: 135.04823
Epoch[18/100], Step [190/391], Reconst Loss: 122.48305, KL Div: 10.67763, Total Loss: 133.16068
Epoch[18/100], Step [200/391], Reconst Loss: 120.13457, KL Div: 10.68569, Total Loss: 130.82026
Epoch[18/100], Step [210/391], Reconst Loss: 124.32759, KL Div: 10.77224, Total Loss: 135.09983
Epoch[18/100], Step [220/391], Reconst Loss: 123.43382, KL Div: 10.84976, Total Loss: 134.28358
Epoch[18/100], Step [230/391], Reconst Loss: 124.28255, KL Div: 11.00374, Total Loss: 135.28629
Epoch[18/100], Step [240/391], Reconst Loss: 123.11257, KL Div: 10.41884, Total Loss: 133.53141
Epoch[18/100], Step [250/391], Reconst Loss: 124.32565, KL Div: 10.74726, Total Loss: 135.07291
Epoch[18/100], Step [260/391], Reconst Loss: 117.70286, KL Div: 10.44229, Total Loss: 128.14515
Epoch[18/100], Step [270/391], Reconst Loss: 121.38157, KL Div: 11.19034, Total Loss: 132.57191
Epoch[18/100], Step [280/391], Reconst Loss: 118.58379, KL Div: 10.97746, Total Loss: 129.56124
Epoch[18/100], Step [290/391], Reconst Loss: 122.91640, KL Div: 10.79168, Total Loss: 133.70808
Epoch[18/100], Step [300/391], Reconst Loss: 115.06205, KL Div: 10.86954, Total Loss: 125.93159
Epoch[18/100], Step [310/391], Reconst Loss: 122.42849, KL Div: 10.67067, Total Loss: 133.09916
Epoch[18/100], Step [320/391], Reconst Loss: 123.60866, KL Div: 10.91687, Total Loss: 134.52553
Epoch[18/100], Step [330/391], Reconst Loss: 125.12525, KL Div: 10.79720, Total Loss: 135.92245
Epoch[18/100], Step [340/391], Reconst Loss: 118.57883, KL Div: 11.30786, Total Loss: 129.88668
Epoch[18/100], Step [350/391], Reconst Loss: 120.20160, KL Div: 10.70193, Total Loss: 130.90353
Epoch[18/100], Step [360/391], Reconst Loss: 128.69644, KL Div: 10.98720, Total Loss: 139.68364
Epoch[18/100], Step [370/391], Reconst Loss: 128.36292, KL Div: 10.63810, Total Loss: 139.00102
Epoch[18/100], Step [380/391], Reconst Loss: 117.68807, KL Div: 11.11080, Total Loss: 128.79887
Epoch[18/100], Step [390/391], Reconst Loss: 119.27338, KL Div: 11.23610, Total Loss: 130.50948
Epoch = 18
Training epoch time =  139.19488525390625
train total loss =  131.202853515625
valid total loss =  132.18247060546875
Total epoch time =  257.2456316947937
Saving checkpoint...
Done!
Epoch[19/100], Step [10/391], Reconst Loss: 123.66705, KL Div: 10.85697, Total Loss: 134.52402
Epoch[19/100], Step [20/391], Reconst Loss: 129.50818, KL Div: 10.84570, Total Loss: 140.35388
Epoch[19/100], Step [30/391], Reconst Loss: 119.00359, KL Div: 10.53459, Total Loss: 129.53818
Epoch[19/100], Step [40/391], Reconst Loss: 118.22406, KL Div: 10.54402, Total Loss: 128.76808
Epoch[19/100], Step [50/391], Reconst Loss: 115.03835, KL Div: 10.67653, Total Loss: 125.71488
Epoch[19/100], Step [60/391], Reconst Loss: 120.74834, KL Div: 11.15570, Total Loss: 131.90404
Epoch[19/100], Step [70/391], Reconst Loss: 117.56895, KL Div: 10.47879, Total Loss: 128.04774
Epoch[19/100], Step [80/391], Reconst Loss: 122.19720, KL Div: 11.44069, Total Loss: 133.63789
Epoch[19/100], Step [90/391], Reconst Loss: 116.47948, KL Div: 10.98151, Total Loss: 127.46098
Epoch[19/100], Step [100/391], Reconst Loss: 125.10983, KL Div: 10.61220, Total Loss: 135.72204
Epoch[19/100], Step [110/391], Reconst Loss: 123.77859, KL Div: 10.93921, Total Loss: 134.71780
Epoch[19/100], Step [120/391], Reconst Loss: 120.87041, KL Div: 11.00400, Total Loss: 131.87442
Epoch[19/100], Step [130/391], Reconst Loss: 124.89864, KL Div: 11.06472, Total Loss: 135.96336
Epoch[19/100], Step [140/391], Reconst Loss: 122.02374, KL Div: 10.69542, Total Loss: 132.71916
Epoch[19/100], Step [150/391], Reconst Loss: 118.79367, KL Div: 10.82054, Total Loss: 129.61421
Epoch[19/100], Step [160/391], Reconst Loss: 120.98630, KL Div: 11.24733, Total Loss: 132.23363
Epoch[19/100], Step [170/391], Reconst Loss: 118.70633, KL Div: 11.15820, Total Loss: 129.86453
Epoch[19/100], Step [180/391], Reconst Loss: 122.38037, KL Div: 10.90097, Total Loss: 133.28134
Epoch[19/100], Step [190/391], Reconst Loss: 123.14783, KL Div: 10.97175, Total Loss: 134.11958
Epoch[19/100], Step [200/391], Reconst Loss: 120.52126, KL Div: 11.11062, Total Loss: 131.63188
Epoch[19/100], Step [210/391], Reconst Loss: 119.51066, KL Div: 10.89742, Total Loss: 130.40808
Epoch[19/100], Step [220/391], Reconst Loss: 118.04293, KL Div: 11.01290, Total Loss: 129.05583
Epoch[19/100], Step [230/391], Reconst Loss: 120.04424, KL Div: 10.71289, Total Loss: 130.75713
Epoch[19/100], Step [240/391], Reconst Loss: 124.06052, KL Div: 11.12316, Total Loss: 135.18368
Epoch[19/100], Step [250/391], Reconst Loss: 121.16331, KL Div: 10.65909, Total Loss: 131.82240
Epoch[19/100], Step [260/391], Reconst Loss: 121.33685, KL Div: 10.78341, Total Loss: 132.12027
Epoch[19/100], Step [270/391], Reconst Loss: 127.56917, KL Div: 10.78419, Total Loss: 138.35336
Epoch[19/100], Step [280/391], Reconst Loss: 120.23123, KL Div: 11.03717, Total Loss: 131.26840
Epoch[19/100], Step [290/391], Reconst Loss: 118.40825, KL Div: 10.78947, Total Loss: 129.19772
Epoch[19/100], Step [300/391], Reconst Loss: 120.35405, KL Div: 11.12595, Total Loss: 131.48000
Epoch[19/100], Step [310/391], Reconst Loss: 122.13805, KL Div: 10.56068, Total Loss: 132.69873
Epoch[19/100], Step [320/391], Reconst Loss: 118.38406, KL Div: 10.34121, Total Loss: 128.72527
Epoch[19/100], Step [330/391], Reconst Loss: 115.78383, KL Div: 11.17705, Total Loss: 126.96088
Epoch[19/100], Step [340/391], Reconst Loss: 120.32678, KL Div: 10.59974, Total Loss: 130.92652
Epoch[19/100], Step [350/391], Reconst Loss: 122.05038, KL Div: 10.74193, Total Loss: 132.79232
Epoch[19/100], Step [360/391], Reconst Loss: 119.44331, KL Div: 10.87340, Total Loss: 130.31671
Epoch[19/100], Step [370/391], Reconst Loss: 124.90274, KL Div: 11.02094, Total Loss: 135.92368
Epoch[19/100], Step [380/391], Reconst Loss: 123.18604, KL Div: 10.86289, Total Loss: 134.04893
Epoch[19/100], Step [390/391], Reconst Loss: 123.90756, KL Div: 10.46048, Total Loss: 134.36804
Epoch = 19
Training epoch time =  139.1496787071228
train total loss =  130.65407943359375
valid total loss =  131.4632712158203
Total epoch time =  257.4770784378052
Saving checkpoint...
Done!
Epoch[20/100], Step [10/391], Reconst Loss: 127.25271, KL Div: 10.90056, Total Loss: 138.15327
Epoch[20/100], Step [20/391], Reconst Loss: 121.42896, KL Div: 10.43056, Total Loss: 131.85952
Epoch[20/100], Step [30/391], Reconst Loss: 119.54247, KL Div: 10.77999, Total Loss: 130.32245
Epoch[20/100], Step [40/391], Reconst Loss: 127.48407, KL Div: 10.86740, Total Loss: 138.35147
Epoch[20/100], Step [50/391], Reconst Loss: 123.19405, KL Div: 11.35518, Total Loss: 134.54923
Epoch[20/100], Step [60/391], Reconst Loss: 119.98280, KL Div: 10.61697, Total Loss: 130.59977
Epoch[20/100], Step [70/391], Reconst Loss: 115.61414, KL Div: 10.63065, Total Loss: 126.24479
Epoch[20/100], Step [80/391], Reconst Loss: 125.33331, KL Div: 10.46359, Total Loss: 135.79690
Epoch[20/100], Step [90/391], Reconst Loss: 126.78043, KL Div: 10.59952, Total Loss: 137.37995
Epoch[20/100], Step [100/391], Reconst Loss: 113.99879, KL Div: 10.36800, Total Loss: 124.36679
Epoch[20/100], Step [110/391], Reconst Loss: 116.22038, KL Div: 11.03717, Total Loss: 127.25756
Epoch[20/100], Step [120/391], Reconst Loss: 118.65479, KL Div: 10.76212, Total Loss: 129.41691
Epoch[20/100], Step [130/391], Reconst Loss: 121.32336, KL Div: 10.70401, Total Loss: 132.02738
Epoch[20/100], Step [140/391], Reconst Loss: 121.19876, KL Div: 10.08994, Total Loss: 131.28870
Epoch[20/100], Step [150/391], Reconst Loss: 121.97356, KL Div: 11.08643, Total Loss: 133.05999
Epoch[20/100], Step [160/391], Reconst Loss: 124.90001, KL Div: 10.91014, Total Loss: 135.81015
Epoch[20/100], Step [170/391], Reconst Loss: 114.54822, KL Div: 10.65841, Total Loss: 125.20662
Epoch[20/100], Step [180/391], Reconst Loss: 122.58165, KL Div: 10.72470, Total Loss: 133.30635
Epoch[20/100], Step [190/391], Reconst Loss: 119.01637, KL Div: 10.44891, Total Loss: 129.46528
Epoch[20/100], Step [200/391], Reconst Loss: 119.15417, KL Div: 10.62425, Total Loss: 129.77842
Epoch[20/100], Step [210/391], Reconst Loss: 119.81619, KL Div: 10.49264, Total Loss: 130.30883
Epoch[20/100], Step [220/391], Reconst Loss: 121.12751, KL Div: 10.45047, Total Loss: 131.57798
Epoch[20/100], Step [230/391], Reconst Loss: 119.70288, KL Div: 10.95432, Total Loss: 130.65720
Epoch[20/100], Step [240/391], Reconst Loss: 124.81945, KL Div: 10.77161, Total Loss: 135.59106
Epoch[20/100], Step [250/391], Reconst Loss: 124.29460, KL Div: 10.69765, Total Loss: 134.99225
Epoch[20/100], Step [260/391], Reconst Loss: 122.22842, KL Div: 11.14271, Total Loss: 133.37114
Epoch[20/100], Step [270/391], Reconst Loss: 123.10549, KL Div: 10.71287, Total Loss: 133.81836
Epoch[20/100], Step [280/391], Reconst Loss: 115.00261, KL Div: 10.02297, Total Loss: 125.02557
Epoch[20/100], Step [290/391], Reconst Loss: 115.58269, KL Div: 10.32836, Total Loss: 125.91104
Epoch[20/100], Step [300/391], Reconst Loss: 125.51294, KL Div: 10.99244, Total Loss: 136.50538
Epoch[20/100], Step [310/391], Reconst Loss: 123.49336, KL Div: 10.66659, Total Loss: 134.15996
Epoch[20/100], Step [320/391], Reconst Loss: 123.54407, KL Div: 11.19029, Total Loss: 134.73436
Epoch[20/100], Step [330/391], Reconst Loss: 119.95935, KL Div: 10.72472, Total Loss: 130.68407
Epoch[20/100], Step [340/391], Reconst Loss: 126.08365, KL Div: 10.79988, Total Loss: 136.88353
Epoch[20/100], Step [350/391], Reconst Loss: 120.76419, KL Div: 10.88147, Total Loss: 131.64566
Epoch[20/100], Step [360/391], Reconst Loss: 112.48991, KL Div: 11.11115, Total Loss: 123.60107
Epoch[20/100], Step [370/391], Reconst Loss: 123.88914, KL Div: 10.98902, Total Loss: 134.87817
Epoch[20/100], Step [380/391], Reconst Loss: 120.97194, KL Div: 11.32290, Total Loss: 132.29484
Epoch[20/100], Step [390/391], Reconst Loss: 118.66927, KL Div: 10.68566, Total Loss: 129.35493
Epoch = 20
Training epoch time =  139.4070463180542
train total loss =  130.507701015625
valid total loss =  131.37788041992187
Total epoch time =  257.7281460762024
Saving checkpoint...
Done!
Epoch[21/100], Step [10/391], Reconst Loss: 120.47537, KL Div: 11.05758, Total Loss: 131.53295
Epoch[21/100], Step [20/391], Reconst Loss: 128.03418, KL Div: 11.26908, Total Loss: 139.30326
Epoch[21/100], Step [30/391], Reconst Loss: 117.98038, KL Div: 10.65313, Total Loss: 128.63351
Epoch[21/100], Step [40/391], Reconst Loss: 119.08786, KL Div: 11.02292, Total Loss: 130.11078
Epoch[21/100], Step [50/391], Reconst Loss: 121.92833, KL Div: 10.72444, Total Loss: 132.65277
Epoch[21/100], Step [60/391], Reconst Loss: 121.85903, KL Div: 10.80783, Total Loss: 132.66687
Epoch[21/100], Step [70/391], Reconst Loss: 118.27785, KL Div: 10.84559, Total Loss: 129.12343
Epoch[21/100], Step [80/391], Reconst Loss: 120.18733, KL Div: 10.66459, Total Loss: 130.85192
Epoch[21/100], Step [90/391], Reconst Loss: 124.80570, KL Div: 11.18169, Total Loss: 135.98739
Epoch[21/100], Step [100/391], Reconst Loss: 122.00805, KL Div: 10.81117, Total Loss: 132.81922
Epoch[21/100], Step [110/391], Reconst Loss: 117.14581, KL Div: 11.00452, Total Loss: 128.15033
Epoch[21/100], Step [120/391], Reconst Loss: 120.80524, KL Div: 11.19646, Total Loss: 132.00169
Epoch[21/100], Step [130/391], Reconst Loss: 115.11578, KL Div: 10.50819, Total Loss: 125.62397
Epoch[21/100], Step [140/391], Reconst Loss: 121.52516, KL Div: 10.48821, Total Loss: 132.01337
Epoch[21/100], Step [150/391], Reconst Loss: 122.06750, KL Div: 10.75051, Total Loss: 132.81801
Epoch[21/100], Step [160/391], Reconst Loss: 116.91048, KL Div: 10.87246, Total Loss: 127.78295
Epoch[21/100], Step [170/391], Reconst Loss: 113.42208, KL Div: 10.94879, Total Loss: 124.37087
Epoch[21/100], Step [180/391], Reconst Loss: 122.03769, KL Div: 11.17070, Total Loss: 133.20839
Epoch[21/100], Step [190/391], Reconst Loss: 120.73056, KL Div: 10.73748, Total Loss: 131.46804
Epoch[21/100], Step [200/391], Reconst Loss: 117.74862, KL Div: 10.43340, Total Loss: 128.18202
Epoch[21/100], Step [210/391], Reconst Loss: 121.12303, KL Div: 10.55437, Total Loss: 131.67741
Epoch[21/100], Step [220/391], Reconst Loss: 124.60145, KL Div: 11.14505, Total Loss: 135.74650
Epoch[21/100], Step [230/391], Reconst Loss: 117.78053, KL Div: 10.68213, Total Loss: 128.46267
Epoch[21/100], Step [240/391], Reconst Loss: 123.02391, KL Div: 10.76397, Total Loss: 133.78788
Epoch[21/100], Step [250/391], Reconst Loss: 123.41114, KL Div: 10.80244, Total Loss: 134.21358
Epoch[21/100], Step [260/391], Reconst Loss: 124.14108, KL Div: 10.45958, Total Loss: 134.60065
Epoch[21/100], Step [270/391], Reconst Loss: 121.65614, KL Div: 10.45592, Total Loss: 132.11206
Epoch[21/100], Step [280/391], Reconst Loss: 121.51967, KL Div: 10.83644, Total Loss: 132.35610
Epoch[21/100], Step [290/391], Reconst Loss: 120.06532, KL Div: 10.67460, Total Loss: 130.73992
Epoch[21/100], Step [300/391], Reconst Loss: 121.16488, KL Div: 10.87028, Total Loss: 132.03516
Epoch[21/100], Step [310/391], Reconst Loss: 118.84100, KL Div: 11.10946, Total Loss: 129.95046
Epoch[21/100], Step [320/391], Reconst Loss: 113.58299, KL Div: 10.65336, Total Loss: 124.23636
Epoch[21/100], Step [330/391], Reconst Loss: 124.69639, KL Div: 10.89322, Total Loss: 135.58961
Epoch[21/100], Step [340/391], Reconst Loss: 119.91106, KL Div: 11.11729, Total Loss: 131.02835
Epoch[21/100], Step [350/391], Reconst Loss: 123.25046, KL Div: 10.87594, Total Loss: 134.12640
Epoch[21/100], Step [360/391], Reconst Loss: 113.02332, KL Div: 10.54393, Total Loss: 123.56724
Epoch[21/100], Step [370/391], Reconst Loss: 114.91484, KL Div: 11.60536, Total Loss: 126.52021
Epoch[21/100], Step [380/391], Reconst Loss: 120.07776, KL Div: 10.87043, Total Loss: 130.94819
Epoch[21/100], Step [390/391], Reconst Loss: 114.72301, KL Div: 10.33839, Total Loss: 125.06140
Epoch = 21
Training epoch time =  139.0854365825653
train total loss =  130.22418654296874
valid total loss =  131.06241115722656
Total epoch time =  257.2337963581085
Saving checkpoint...
Done!
Epoch[22/100], Step [10/391], Reconst Loss: 114.45861, KL Div: 10.39246, Total Loss: 124.85107
Epoch[22/100], Step [20/391], Reconst Loss: 120.00915, KL Div: 10.80408, Total Loss: 130.81323
Epoch[22/100], Step [30/391], Reconst Loss: 120.72827, KL Div: 11.26738, Total Loss: 131.99565
Epoch[22/100], Step [40/391], Reconst Loss: 119.93999, KL Div: 10.83630, Total Loss: 130.77629
Epoch[22/100], Step [50/391], Reconst Loss: 123.75725, KL Div: 11.34888, Total Loss: 135.10613
Epoch[22/100], Step [60/391], Reconst Loss: 121.46306, KL Div: 10.65238, Total Loss: 132.11544
Epoch[22/100], Step [70/391], Reconst Loss: 115.51131, KL Div: 11.24866, Total Loss: 126.75997
Epoch[22/100], Step [80/391], Reconst Loss: 118.97316, KL Div: 11.10430, Total Loss: 130.07746
Epoch[22/100], Step [90/391], Reconst Loss: 119.75920, KL Div: 11.18279, Total Loss: 130.94199
Epoch[22/100], Step [100/391], Reconst Loss: 116.31518, KL Div: 10.70473, Total Loss: 127.01991
Epoch[22/100], Step [110/391], Reconst Loss: 118.73175, KL Div: 11.11849, Total Loss: 129.85024
Epoch[22/100], Step [120/391], Reconst Loss: 123.91814, KL Div: 11.22468, Total Loss: 135.14282
Epoch[22/100], Step [130/391], Reconst Loss: 120.85487, KL Div: 10.67009, Total Loss: 131.52496
Epoch[22/100], Step [140/391], Reconst Loss: 116.99284, KL Div: 10.99673, Total Loss: 127.98958
Epoch[22/100], Step [150/391], Reconst Loss: 115.68450, KL Div: 11.18156, Total Loss: 126.86606
Epoch[22/100], Step [160/391], Reconst Loss: 114.79139, KL Div: 11.17215, Total Loss: 125.96354
Epoch[22/100], Step [170/391], Reconst Loss: 123.69501, KL Div: 10.96145, Total Loss: 134.65646
Epoch[22/100], Step [180/391], Reconst Loss: 116.52725, KL Div: 10.63750, Total Loss: 127.16475
Epoch[22/100], Step [190/391], Reconst Loss: 115.74765, KL Div: 11.03206, Total Loss: 126.77971
Epoch[22/100], Step [200/391], Reconst Loss: 117.91370, KL Div: 10.44828, Total Loss: 128.36199
Epoch[22/100], Step [210/391], Reconst Loss: 120.12839, KL Div: 10.75706, Total Loss: 130.88545
Epoch[22/100], Step [220/391], Reconst Loss: 117.04459, KL Div: 10.65779, Total Loss: 127.70238
Epoch[22/100], Step [230/391], Reconst Loss: 120.64510, KL Div: 10.94096, Total Loss: 131.58605
Epoch[22/100], Step [240/391], Reconst Loss: 118.75887, KL Div: 11.20084, Total Loss: 129.95970
Epoch[22/100], Step [250/391], Reconst Loss: 118.92429, KL Div: 10.75562, Total Loss: 129.67992
Epoch[22/100], Step [260/391], Reconst Loss: 111.75479, KL Div: 10.60780, Total Loss: 122.36259
Epoch[22/100], Step [270/391], Reconst Loss: 121.00073, KL Div: 11.26440, Total Loss: 132.26513
Epoch[22/100], Step [280/391], Reconst Loss: 120.91296, KL Div: 10.95357, Total Loss: 131.86653
Epoch[22/100], Step [290/391], Reconst Loss: 124.25062, KL Div: 10.78117, Total Loss: 135.03179
Epoch[22/100], Step [300/391], Reconst Loss: 123.58755, KL Div: 11.08707, Total Loss: 134.67462
Epoch[22/100], Step [310/391], Reconst Loss: 121.01459, KL Div: 10.94995, Total Loss: 131.96454
Epoch[22/100], Step [320/391], Reconst Loss: 120.18725, KL Div: 10.50909, Total Loss: 130.69634
Epoch[22/100], Step [330/391], Reconst Loss: 121.96037, KL Div: 11.43367, Total Loss: 133.39404
Epoch[22/100], Step [340/391], Reconst Loss: 123.09158, KL Div: 11.19684, Total Loss: 134.28843
Epoch[22/100], Step [350/391], Reconst Loss: 118.78186, KL Div: 10.85210, Total Loss: 129.63396
Epoch[22/100], Step [360/391], Reconst Loss: 115.61986, KL Div: 10.85657, Total Loss: 126.47643
Epoch[22/100], Step [370/391], Reconst Loss: 120.41257, KL Div: 11.05045, Total Loss: 131.46303
Epoch[22/100], Step [380/391], Reconst Loss: 121.89106, KL Div: 11.44958, Total Loss: 133.34064
Epoch[22/100], Step [390/391], Reconst Loss: 121.62457, KL Div: 11.05102, Total Loss: 132.67559
Epoch = 22
Training epoch time =  139.0935480594635
train total loss =  129.9874926953125
valid total loss =  131.05555275878908
Total epoch time =  257.29815220832825
Saving checkpoint...
Done!
Epoch[23/100], Step [10/391], Reconst Loss: 114.25963, KL Div: 10.65415, Total Loss: 124.91378
Epoch[23/100], Step [20/391], Reconst Loss: 121.26834, KL Div: 10.99523, Total Loss: 132.26357
Epoch[23/100], Step [30/391], Reconst Loss: 116.56776, KL Div: 10.76063, Total Loss: 127.32839
Epoch[23/100], Step [40/391], Reconst Loss: 114.44468, KL Div: 10.99170, Total Loss: 125.43637
Epoch[23/100], Step [50/391], Reconst Loss: 119.36574, KL Div: 10.89124, Total Loss: 130.25698
Epoch[23/100], Step [60/391], Reconst Loss: 125.66029, KL Div: 11.07078, Total Loss: 136.73107
Epoch[23/100], Step [70/391], Reconst Loss: 126.40226, KL Div: 10.97222, Total Loss: 137.37448
Epoch[23/100], Step [80/391], Reconst Loss: 119.23985, KL Div: 11.22467, Total Loss: 130.46452
Epoch[23/100], Step [90/391], Reconst Loss: 120.43655, KL Div: 10.77896, Total Loss: 131.21551
Epoch[23/100], Step [100/391], Reconst Loss: 118.15031, KL Div: 10.80523, Total Loss: 128.95555
Epoch[23/100], Step [110/391], Reconst Loss: 116.10374, KL Div: 10.64913, Total Loss: 126.75288
Epoch[23/100], Step [120/391], Reconst Loss: 123.17649, KL Div: 11.11636, Total Loss: 134.29285
Epoch[23/100], Step [130/391], Reconst Loss: 121.48332, KL Div: 11.18620, Total Loss: 132.66952
Epoch[23/100], Step [140/391], Reconst Loss: 119.76803, KL Div: 11.08178, Total Loss: 130.84981
Epoch[23/100], Step [150/391], Reconst Loss: 116.73647, KL Div: 10.71464, Total Loss: 127.45111
Epoch[23/100], Step [160/391], Reconst Loss: 118.98313, KL Div: 10.63522, Total Loss: 129.61835
Epoch[23/100], Step [170/391], Reconst Loss: 121.46873, KL Div: 10.65024, Total Loss: 132.11898
Epoch[23/100], Step [180/391], Reconst Loss: 116.03784, KL Div: 11.07505, Total Loss: 127.11289
Epoch[23/100], Step [190/391], Reconst Loss: 120.20445, KL Div: 10.92567, Total Loss: 131.13012
Epoch[23/100], Step [200/391], Reconst Loss: 118.98270, KL Div: 11.23984, Total Loss: 130.22254
Epoch[23/100], Step [210/391], Reconst Loss: 121.14986, KL Div: 10.77180, Total Loss: 131.92166
Epoch[23/100], Step [220/391], Reconst Loss: 121.62454, KL Div: 10.74187, Total Loss: 132.36642
Epoch[23/100], Step [230/391], Reconst Loss: 123.60433, KL Div: 11.13029, Total Loss: 134.73462
Epoch[23/100], Step [240/391], Reconst Loss: 118.59885, KL Div: 10.94724, Total Loss: 129.54609
Epoch[23/100], Step [250/391], Reconst Loss: 117.57516, KL Div: 10.83405, Total Loss: 128.40921
Epoch[23/100], Step [260/391], Reconst Loss: 115.52930, KL Div: 10.51553, Total Loss: 126.04484
Epoch[23/100], Step [270/391], Reconst Loss: 116.29213, KL Div: 10.76916, Total Loss: 127.06129
Epoch[23/100], Step [280/391], Reconst Loss: 122.99189, KL Div: 10.57207, Total Loss: 133.56396
Epoch[23/100], Step [290/391], Reconst Loss: 120.11485, KL Div: 11.17102, Total Loss: 131.28587
Epoch[23/100], Step [300/391], Reconst Loss: 117.77912, KL Div: 10.95018, Total Loss: 128.72930
Epoch[23/100], Step [310/391], Reconst Loss: 117.40494, KL Div: 10.96246, Total Loss: 128.36740
Epoch[23/100], Step [320/391], Reconst Loss: 124.76411, KL Div: 10.82737, Total Loss: 135.59147
Epoch[23/100], Step [330/391], Reconst Loss: 118.24487, KL Div: 10.81734, Total Loss: 129.06222
Epoch[23/100], Step [340/391], Reconst Loss: 121.41123, KL Div: 11.22554, Total Loss: 132.63677
Epoch[23/100], Step [350/391], Reconst Loss: 118.15300, KL Div: 11.17712, Total Loss: 129.33012
Epoch[23/100], Step [360/391], Reconst Loss: 118.08464, KL Div: 11.03171, Total Loss: 129.11635
Epoch[23/100], Step [370/391], Reconst Loss: 116.57813, KL Div: 10.71428, Total Loss: 127.29241
Epoch[23/100], Step [380/391], Reconst Loss: 122.23441, KL Div: 11.37810, Total Loss: 133.61251
Epoch[23/100], Step [390/391], Reconst Loss: 120.17968, KL Div: 11.07600, Total Loss: 131.25568
Epoch = 23
Training epoch time =  139.26827836036682
train total loss =  129.7052047265625
valid total loss =  130.63397172851563
Total epoch time =  257.28082489967346
Saving checkpoint...
Done!
Epoch[24/100], Step [10/391], Reconst Loss: 117.40549, KL Div: 10.68328, Total Loss: 128.08877
Epoch[24/100], Step [20/391], Reconst Loss: 116.24138, KL Div: 10.88697, Total Loss: 127.12835
Epoch[24/100], Step [30/391], Reconst Loss: 117.19000, KL Div: 10.85717, Total Loss: 128.04718
Epoch[24/100], Step [40/391], Reconst Loss: 122.45753, KL Div: 11.01535, Total Loss: 133.47288
Epoch[24/100], Step [50/391], Reconst Loss: 117.23392, KL Div: 11.10145, Total Loss: 128.33536
Epoch[24/100], Step [60/391], Reconst Loss: 117.51537, KL Div: 10.59393, Total Loss: 128.10930
Epoch[24/100], Step [70/391], Reconst Loss: 124.25368, KL Div: 10.77036, Total Loss: 135.02403
Epoch[24/100], Step [80/391], Reconst Loss: 118.39735, KL Div: 10.63975, Total Loss: 129.03711
Epoch[24/100], Step [90/391], Reconst Loss: 119.99922, KL Div: 10.88956, Total Loss: 130.88878
Epoch[24/100], Step [100/391], Reconst Loss: 118.65636, KL Div: 10.77917, Total Loss: 129.43552
Epoch[24/100], Step [110/391], Reconst Loss: 119.54137, KL Div: 10.79715, Total Loss: 130.33852
Epoch[24/100], Step [120/391], Reconst Loss: 125.07185, KL Div: 10.47224, Total Loss: 135.54410
Epoch[24/100], Step [130/391], Reconst Loss: 113.77824, KL Div: 10.76756, Total Loss: 124.54580
Epoch[24/100], Step [140/391], Reconst Loss: 116.11040, KL Div: 10.91162, Total Loss: 127.02202
Epoch[24/100], Step [150/391], Reconst Loss: 125.25589, KL Div: 11.05010, Total Loss: 136.30599
Epoch[24/100], Step [160/391], Reconst Loss: 116.76979, KL Div: 10.89259, Total Loss: 127.66238
Epoch[24/100], Step [170/391], Reconst Loss: 120.04502, KL Div: 11.19559, Total Loss: 131.24061
Epoch[24/100], Step [180/391], Reconst Loss: 115.39907, KL Div: 11.14641, Total Loss: 126.54548
Epoch[24/100], Step [190/391], Reconst Loss: 121.06444, KL Div: 11.19287, Total Loss: 132.25731
Epoch[24/100], Step [200/391], Reconst Loss: 119.04773, KL Div: 11.27485, Total Loss: 130.32258
Epoch[24/100], Step [210/391], Reconst Loss: 119.44624, KL Div: 11.09016, Total Loss: 130.53640
Epoch[24/100], Step [220/391], Reconst Loss: 119.11520, KL Div: 11.28441, Total Loss: 130.39961
Epoch[24/100], Step [230/391], Reconst Loss: 117.91092, KL Div: 11.06911, Total Loss: 128.98003
Epoch[24/100], Step [240/391], Reconst Loss: 114.97127, KL Div: 10.65645, Total Loss: 125.62772
Epoch[24/100], Step [250/391], Reconst Loss: 121.91019, KL Div: 11.33306, Total Loss: 133.24325
Epoch[24/100], Step [260/391], Reconst Loss: 121.11983, KL Div: 11.05283, Total Loss: 132.17266
Epoch[24/100], Step [270/391], Reconst Loss: 120.41278, KL Div: 10.85741, Total Loss: 131.27019
Epoch[24/100], Step [280/391], Reconst Loss: 121.52831, KL Div: 11.08060, Total Loss: 132.60891
Epoch[24/100], Step [290/391], Reconst Loss: 118.22153, KL Div: 11.04527, Total Loss: 129.26679
Epoch[24/100], Step [300/391], Reconst Loss: 120.81516, KL Div: 11.17354, Total Loss: 131.98870
Epoch[24/100], Step [310/391], Reconst Loss: 123.62432, KL Div: 10.95571, Total Loss: 134.58003
Epoch[24/100], Step [320/391], Reconst Loss: 114.88525, KL Div: 10.68520, Total Loss: 125.57045
Epoch[24/100], Step [330/391], Reconst Loss: 117.62950, KL Div: 10.62134, Total Loss: 128.25084
Epoch[24/100], Step [340/391], Reconst Loss: 114.43823, KL Div: 10.64036, Total Loss: 125.07859
Epoch[24/100], Step [350/391], Reconst Loss: 115.14226, KL Div: 10.37798, Total Loss: 125.52024
Epoch[24/100], Step [360/391], Reconst Loss: 116.79333, KL Div: 10.61666, Total Loss: 127.40999
Epoch[24/100], Step [370/391], Reconst Loss: 119.02399, KL Div: 11.21262, Total Loss: 130.23660
Epoch[24/100], Step [380/391], Reconst Loss: 116.38401, KL Div: 10.54385, Total Loss: 126.92787
Epoch[24/100], Step [390/391], Reconst Loss: 118.16690, KL Div: 10.87526, Total Loss: 129.04216
Epoch = 24
Training epoch time =  139.13345217704773
train total loss =  129.59409990234374
valid total loss =  130.57247938232422
Total epoch time =  257.5921108722687
Saving checkpoint...
Done!
Epoch[25/100], Step [10/391], Reconst Loss: 122.55676, KL Div: 11.73448, Total Loss: 134.29125
Epoch[25/100], Step [20/391], Reconst Loss: 118.81512, KL Div: 10.59408, Total Loss: 129.40920
Epoch[25/100], Step [30/391], Reconst Loss: 120.69531, KL Div: 11.05267, Total Loss: 131.74798
Epoch[25/100], Step [40/391], Reconst Loss: 118.72872, KL Div: 11.21436, Total Loss: 129.94308
Epoch[25/100], Step [50/391], Reconst Loss: 120.97520, KL Div: 11.06366, Total Loss: 132.03886
Epoch[25/100], Step [60/391], Reconst Loss: 122.72530, KL Div: 11.09412, Total Loss: 133.81942
Epoch[25/100], Step [70/391], Reconst Loss: 125.32649, KL Div: 11.23267, Total Loss: 136.55916
Epoch[25/100], Step [80/391], Reconst Loss: 120.17799, KL Div: 10.99970, Total Loss: 131.17769
Epoch[25/100], Step [90/391], Reconst Loss: 122.12268, KL Div: 11.14578, Total Loss: 133.26846
Epoch[25/100], Step [100/391], Reconst Loss: 124.59456, KL Div: 10.72044, Total Loss: 135.31499
Epoch[25/100], Step [110/391], Reconst Loss: 117.83323, KL Div: 10.99498, Total Loss: 128.82821
Epoch[25/100], Step [120/391], Reconst Loss: 117.53854, KL Div: 10.92714, Total Loss: 128.46569
Epoch[25/100], Step [130/391], Reconst Loss: 124.39334, KL Div: 10.72762, Total Loss: 135.12096
Epoch[25/100], Step [140/391], Reconst Loss: 121.76880, KL Div: 10.91975, Total Loss: 132.68855
Epoch[25/100], Step [150/391], Reconst Loss: 121.62946, KL Div: 10.89951, Total Loss: 132.52896
Epoch[25/100], Step [160/391], Reconst Loss: 119.17276, KL Div: 10.51731, Total Loss: 129.69007
Epoch[25/100], Step [170/391], Reconst Loss: 118.36507, KL Div: 11.10738, Total Loss: 129.47245
Epoch[25/100], Step [180/391], Reconst Loss: 114.35270, KL Div: 11.09066, Total Loss: 125.44335
Epoch[25/100], Step [190/391], Reconst Loss: 115.39091, KL Div: 10.64248, Total Loss: 126.03339
Epoch[25/100], Step [200/391], Reconst Loss: 121.99954, KL Div: 11.14104, Total Loss: 133.14058
Epoch[25/100], Step [210/391], Reconst Loss: 122.18250, KL Div: 11.18270, Total Loss: 133.36520
Epoch[25/100], Step [220/391], Reconst Loss: 116.86315, KL Div: 11.02926, Total Loss: 127.89241
Epoch[25/100], Step [230/391], Reconst Loss: 116.10178, KL Div: 10.94963, Total Loss: 127.05140
Epoch[25/100], Step [240/391], Reconst Loss: 119.95955, KL Div: 11.16990, Total Loss: 131.12945
Epoch[25/100], Step [250/391], Reconst Loss: 115.40552, KL Div: 11.04270, Total Loss: 126.44822
Epoch[25/100], Step [260/391], Reconst Loss: 121.99133, KL Div: 11.33807, Total Loss: 133.32940
Epoch[25/100], Step [270/391], Reconst Loss: 124.82869, KL Div: 10.90999, Total Loss: 135.73868
Epoch[25/100], Step [280/391], Reconst Loss: 122.47194, KL Div: 11.12975, Total Loss: 133.60169
Epoch[25/100], Step [290/391], Reconst Loss: 118.32724, KL Div: 10.95645, Total Loss: 129.28369
Epoch[25/100], Step [300/391], Reconst Loss: 124.76247, KL Div: 11.13716, Total Loss: 135.89963
Epoch[25/100], Step [310/391], Reconst Loss: 115.73941, KL Div: 10.91722, Total Loss: 126.65663
Epoch[25/100], Step [320/391], Reconst Loss: 115.75962, KL Div: 10.99284, Total Loss: 126.75246
Epoch[25/100], Step [330/391], Reconst Loss: 127.08617, KL Div: 11.01218, Total Loss: 138.09836
Epoch[25/100], Step [340/391], Reconst Loss: 114.99743, KL Div: 10.89627, Total Loss: 125.89370
Epoch[25/100], Step [350/391], Reconst Loss: 117.69512, KL Div: 10.98396, Total Loss: 128.67908
Epoch[25/100], Step [360/391], Reconst Loss: 115.68172, KL Div: 11.36430, Total Loss: 127.04602
Epoch[25/100], Step [370/391], Reconst Loss: 121.19160, KL Div: 11.46859, Total Loss: 132.66018
Epoch[25/100], Step [380/391], Reconst Loss: 113.42001, KL Div: 10.79301, Total Loss: 124.21302
Epoch[25/100], Step [390/391], Reconst Loss: 121.04168, KL Div: 11.37485, Total Loss: 132.41653
Epoch = 25
Training epoch time =  139.57001876831055
train total loss =  129.01903390625
valid total loss =  130.1574487915039
Total epoch time =  258.03537011146545
Saving checkpoint...
Done!
Epoch[26/100], Step [10/391], Reconst Loss: 121.02759, KL Div: 10.58161, Total Loss: 131.60920
Epoch[26/100], Step [20/391], Reconst Loss: 126.92274, KL Div: 10.74494, Total Loss: 137.66767
Epoch[26/100], Step [30/391], Reconst Loss: 124.60664, KL Div: 10.88954, Total Loss: 135.49618
Epoch[26/100], Step [40/391], Reconst Loss: 116.47985, KL Div: 10.48548, Total Loss: 126.96534
Epoch[26/100], Step [50/391], Reconst Loss: 116.73853, KL Div: 10.68203, Total Loss: 127.42056
Epoch[26/100], Step [60/391], Reconst Loss: 119.27213, KL Div: 10.93393, Total Loss: 130.20607
Epoch[26/100], Step [70/391], Reconst Loss: 117.11591, KL Div: 10.63531, Total Loss: 127.75121
Epoch[26/100], Step [80/391], Reconst Loss: 122.02074, KL Div: 10.95426, Total Loss: 132.97500
Epoch[26/100], Step [90/391], Reconst Loss: 121.39661, KL Div: 10.99817, Total Loss: 132.39478
Epoch[26/100], Step [100/391], Reconst Loss: 117.02599, KL Div: 10.56353, Total Loss: 127.58952
Epoch[26/100], Step [110/391], Reconst Loss: 125.74461, KL Div: 10.54000, Total Loss: 136.28461
Epoch[26/100], Step [120/391], Reconst Loss: 120.88111, KL Div: 10.81547, Total Loss: 131.69658
Epoch[26/100], Step [130/391], Reconst Loss: 121.74042, KL Div: 10.79099, Total Loss: 132.53141
Epoch[26/100], Step [140/391], Reconst Loss: 120.48574, KL Div: 10.84272, Total Loss: 131.32847
Epoch[26/100], Step [150/391], Reconst Loss: 119.90757, KL Div: 10.66298, Total Loss: 130.57055
Epoch[26/100], Step [160/391], Reconst Loss: 117.67841, KL Div: 11.00494, Total Loss: 128.68335
Epoch[26/100], Step [170/391], Reconst Loss: 116.82171, KL Div: 10.75536, Total Loss: 127.57707
Epoch[26/100], Step [180/391], Reconst Loss: 121.45605, KL Div: 10.35181, Total Loss: 131.80787
Epoch[26/100], Step [190/391], Reconst Loss: 120.51452, KL Div: 11.10012, Total Loss: 131.61464
Epoch[26/100], Step [200/391], Reconst Loss: 115.25693, KL Div: 10.58010, Total Loss: 125.83702
Epoch[26/100], Step [210/391], Reconst Loss: 120.88182, KL Div: 10.68185, Total Loss: 131.56367
Epoch[26/100], Step [220/391], Reconst Loss: 120.64747, KL Div: 10.52354, Total Loss: 131.17101
Epoch[26/100], Step [230/391], Reconst Loss: 123.14330, KL Div: 10.80123, Total Loss: 133.94453
Epoch[26/100], Step [240/391], Reconst Loss: 122.04670, KL Div: 10.66551, Total Loss: 132.71221
Epoch[26/100], Step [250/391], Reconst Loss: 113.53284, KL Div: 10.51828, Total Loss: 124.05112
Epoch[26/100], Step [260/391], Reconst Loss: 118.99987, KL Div: 10.94016, Total Loss: 129.94003
Epoch[26/100], Step [270/391], Reconst Loss: 116.91585, KL Div: 10.86322, Total Loss: 127.77907
Epoch[26/100], Step [280/391], Reconst Loss: 118.39687, KL Div: 10.82697, Total Loss: 129.22384
Epoch[26/100], Step [290/391], Reconst Loss: 121.26249, KL Div: 10.87992, Total Loss: 132.14241
Epoch[26/100], Step [300/391], Reconst Loss: 118.46745, KL Div: 10.99067, Total Loss: 129.45812
Epoch[26/100], Step [310/391], Reconst Loss: 118.35036, KL Div: 10.39699, Total Loss: 128.74735
Epoch[26/100], Step [320/391], Reconst Loss: 119.03619, KL Div: 10.73007, Total Loss: 129.76626
Epoch[26/100], Step [330/391], Reconst Loss: 111.91160, KL Div: 10.85005, Total Loss: 122.76165
Epoch[26/100], Step [340/391], Reconst Loss: 120.08401, KL Div: 10.42170, Total Loss: 130.50571
Epoch[26/100], Step [350/391], Reconst Loss: 115.13054, KL Div: 10.93848, Total Loss: 126.06901
Epoch[26/100], Step [360/391], Reconst Loss: 114.58016, KL Div: 10.97357, Total Loss: 125.55373
Epoch[26/100], Step [370/391], Reconst Loss: 124.00780, KL Div: 10.81978, Total Loss: 134.82758
Epoch[26/100], Step [380/391], Reconst Loss: 123.57777, KL Div: 10.95151, Total Loss: 134.52928
Epoch[26/100], Step [390/391], Reconst Loss: 118.79488, KL Div: 10.66576, Total Loss: 129.46065
Epoch = 26
Training epoch time =  139.23801255226135
train total loss =  129.4295896875
valid total loss =  130.43714361572265
Total epoch time =  257.33847856521606
Saving checkpoint...
Done!
Epoch[27/100], Step [10/391], Reconst Loss: 120.17378, KL Div: 10.94519, Total Loss: 131.11898
Epoch[27/100], Step [20/391], Reconst Loss: 118.13406, KL Div: 11.18335, Total Loss: 129.31741
Epoch[27/100], Step [30/391], Reconst Loss: 121.24519, KL Div: 10.78465, Total Loss: 132.02985
Epoch[27/100], Step [40/391], Reconst Loss: 115.79491, KL Div: 10.64518, Total Loss: 126.44008
Epoch[27/100], Step [50/391], Reconst Loss: 120.97350, KL Div: 10.51304, Total Loss: 131.48654
Epoch[27/100], Step [60/391], Reconst Loss: 118.76111, KL Div: 10.93229, Total Loss: 129.69340
Epoch[27/100], Step [70/391], Reconst Loss: 117.40516, KL Div: 10.59821, Total Loss: 128.00337
Epoch[27/100], Step [80/391], Reconst Loss: 123.31811, KL Div: 11.28341, Total Loss: 134.60152
Epoch[27/100], Step [90/391], Reconst Loss: 120.92718, KL Div: 11.05412, Total Loss: 131.98130
Epoch[27/100], Step [100/391], Reconst Loss: 117.69320, KL Div: 10.80959, Total Loss: 128.50279
Epoch[27/100], Step [110/391], Reconst Loss: 115.61158, KL Div: 11.12685, Total Loss: 126.73843
Epoch[27/100], Step [120/391], Reconst Loss: 118.27634, KL Div: 10.62936, Total Loss: 128.90569
Epoch[27/100], Step [130/391], Reconst Loss: 119.93489, KL Div: 10.86173, Total Loss: 130.79662
Epoch[27/100], Step [140/391], Reconst Loss: 118.86929, KL Div: 10.71519, Total Loss: 129.58447
Epoch[27/100], Step [150/391], Reconst Loss: 113.72564, KL Div: 11.11183, Total Loss: 124.83747
Epoch[27/100], Step [160/391], Reconst Loss: 119.19713, KL Div: 10.93661, Total Loss: 130.13373
Epoch[27/100], Step [170/391], Reconst Loss: 118.90685, KL Div: 10.95999, Total Loss: 129.86685
Epoch[27/100], Step [180/391], Reconst Loss: 119.33346, KL Div: 10.98554, Total Loss: 130.31900
Epoch[27/100], Step [190/391], Reconst Loss: 115.88589, KL Div: 10.94772, Total Loss: 126.83362
Epoch[27/100], Step [200/391], Reconst Loss: 118.79471, KL Div: 10.76085, Total Loss: 129.55556
Epoch[27/100], Step [210/391], Reconst Loss: 115.25275, KL Div: 10.55745, Total Loss: 125.81020
Epoch[27/100], Step [220/391], Reconst Loss: 124.17396, KL Div: 10.30744, Total Loss: 134.48140
Epoch[27/100], Step [230/391], Reconst Loss: 120.85091, KL Div: 11.04343, Total Loss: 131.89434
Epoch[27/100], Step [240/391], Reconst Loss: 118.69139, KL Div: 10.74591, Total Loss: 129.43731
Epoch[27/100], Step [250/391], Reconst Loss: 117.53202, KL Div: 10.53785, Total Loss: 128.06987
Epoch[27/100], Step [260/391], Reconst Loss: 120.53235, KL Div: 10.47595, Total Loss: 131.00830
Epoch[27/100], Step [270/391], Reconst Loss: 120.95350, KL Div: 11.21602, Total Loss: 132.16952
Epoch[27/100], Step [280/391], Reconst Loss: 122.24297, KL Div: 11.19196, Total Loss: 133.43492
Epoch[27/100], Step [290/391], Reconst Loss: 118.34476, KL Div: 11.42072, Total Loss: 129.76549
Epoch[27/100], Step [300/391], Reconst Loss: 120.23398, KL Div: 10.64894, Total Loss: 130.88292
Epoch[27/100], Step [310/391], Reconst Loss: 117.79808, KL Div: 10.80941, Total Loss: 128.60749
Epoch[27/100], Step [320/391], Reconst Loss: 124.09613, KL Div: 10.55025, Total Loss: 134.64638
Epoch[27/100], Step [330/391], Reconst Loss: 115.59098, KL Div: 10.86373, Total Loss: 126.45471
Epoch[27/100], Step [340/391], Reconst Loss: 126.70463, KL Div: 10.76283, Total Loss: 137.46745
Epoch[27/100], Step [350/391], Reconst Loss: 123.44458, KL Div: 11.47007, Total Loss: 134.91465
Epoch[27/100], Step [360/391], Reconst Loss: 124.99767, KL Div: 10.72131, Total Loss: 135.71898
Epoch[27/100], Step [370/391], Reconst Loss: 115.71047, KL Div: 10.79796, Total Loss: 126.50844
Epoch[27/100], Step [380/391], Reconst Loss: 115.71672, KL Div: 10.64097, Total Loss: 126.35769
Epoch[27/100], Step [390/391], Reconst Loss: 116.40656, KL Div: 10.64617, Total Loss: 127.05273
Epoch = 27
Training epoch time =  139.28111147880554
train total loss =  129.14584189453126
valid total loss =  130.0895487548828
Total epoch time =  257.67074394226074
Saving checkpoint...
Done!
Epoch[28/100], Step [10/391], Reconst Loss: 119.45117, KL Div: 10.81051, Total Loss: 130.26168
Epoch[28/100], Step [20/391], Reconst Loss: 117.42229, KL Div: 10.97408, Total Loss: 128.39638
Epoch[28/100], Step [30/391], Reconst Loss: 109.94411, KL Div: 11.19871, Total Loss: 121.14282
Epoch[28/100], Step [40/391], Reconst Loss: 118.11461, KL Div: 11.29903, Total Loss: 129.41364
Epoch[28/100], Step [50/391], Reconst Loss: 121.55808, KL Div: 11.42725, Total Loss: 132.98533
Epoch[28/100], Step [60/391], Reconst Loss: 120.24550, KL Div: 11.11765, Total Loss: 131.36315
Epoch[28/100], Step [70/391], Reconst Loss: 123.08339, KL Div: 10.74173, Total Loss: 133.82512
Epoch[28/100], Step [80/391], Reconst Loss: 115.24273, KL Div: 10.75722, Total Loss: 125.99995
Epoch[28/100], Step [90/391], Reconst Loss: 114.83580, KL Div: 11.15237, Total Loss: 125.98817
Epoch[28/100], Step [100/391], Reconst Loss: 118.14221, KL Div: 10.73461, Total Loss: 128.87682
Epoch[28/100], Step [110/391], Reconst Loss: 122.06416, KL Div: 11.47964, Total Loss: 133.54380
Epoch[28/100], Step [120/391], Reconst Loss: 118.29202, KL Div: 11.17676, Total Loss: 129.46877
Epoch[28/100], Step [130/391], Reconst Loss: 123.18987, KL Div: 11.40216, Total Loss: 134.59204
Epoch[28/100], Step [140/391], Reconst Loss: 119.77898, KL Div: 11.09619, Total Loss: 130.87517
Epoch[28/100], Step [150/391], Reconst Loss: 113.62770, KL Div: 11.09653, Total Loss: 124.72424
Epoch[28/100], Step [160/391], Reconst Loss: 120.92680, KL Div: 11.14150, Total Loss: 132.06829
Epoch[28/100], Step [170/391], Reconst Loss: 125.97228, KL Div: 10.86913, Total Loss: 136.84142
Epoch[28/100], Step [180/391], Reconst Loss: 120.83015, KL Div: 10.34315, Total Loss: 131.17331
Epoch[28/100], Step [190/391], Reconst Loss: 126.89909, KL Div: 11.10598, Total Loss: 138.00507
Epoch[28/100], Step [200/391], Reconst Loss: 123.83562, KL Div: 10.69625, Total Loss: 134.53186
Epoch[28/100], Step [210/391], Reconst Loss: 119.18930, KL Div: 10.61253, Total Loss: 129.80183
Epoch[28/100], Step [220/391], Reconst Loss: 117.92152, KL Div: 11.18463, Total Loss: 129.10616
Epoch[28/100], Step [230/391], Reconst Loss: 120.31284, KL Div: 11.08463, Total Loss: 131.39747
Epoch[28/100], Step [240/391], Reconst Loss: 113.77019, KL Div: 10.71744, Total Loss: 124.48763
Epoch[28/100], Step [250/391], Reconst Loss: 119.22452, KL Div: 10.81375, Total Loss: 130.03827
Epoch[28/100], Step [260/391], Reconst Loss: 125.57011, KL Div: 11.25678, Total Loss: 136.82690
Epoch[28/100], Step [270/391], Reconst Loss: 122.78820, KL Div: 11.20248, Total Loss: 133.99068
Epoch[28/100], Step [280/391], Reconst Loss: 122.97922, KL Div: 10.90744, Total Loss: 133.88665
Epoch[28/100], Step [290/391], Reconst Loss: 114.72715, KL Div: 11.02734, Total Loss: 125.75449
Epoch[28/100], Step [300/391], Reconst Loss: 118.13490, KL Div: 10.83961, Total Loss: 128.97452
Epoch[28/100], Step [310/391], Reconst Loss: 121.72278, KL Div: 10.88713, Total Loss: 132.60991
Epoch[28/100], Step [320/391], Reconst Loss: 117.33386, KL Div: 10.77700, Total Loss: 128.11086
Epoch[28/100], Step [330/391], Reconst Loss: 117.05300, KL Div: 10.68417, Total Loss: 127.73717
Epoch[28/100], Step [340/391], Reconst Loss: 110.58675, KL Div: 11.15708, Total Loss: 121.74382
Epoch[28/100], Step [350/391], Reconst Loss: 119.78736, KL Div: 11.42019, Total Loss: 131.20755
Epoch[28/100], Step [360/391], Reconst Loss: 118.80736, KL Div: 11.00957, Total Loss: 129.81693
Epoch[28/100], Step [370/391], Reconst Loss: 123.15234, KL Div: 10.80573, Total Loss: 133.95807
Epoch[28/100], Step [380/391], Reconst Loss: 119.21852, KL Div: 11.02597, Total Loss: 130.24449
Epoch[28/100], Step [390/391], Reconst Loss: 127.28169, KL Div: 10.95479, Total Loss: 138.23648
Epoch = 28
Training epoch time =  138.86360692977905
train total loss =  129.31013646484374
valid total loss =  130.38922421875
Total epoch time =  257.3460683822632
Saving checkpoint...
Done!
Epoch[29/100], Step [10/391], Reconst Loss: 120.19292, KL Div: 11.33222, Total Loss: 131.52514
Epoch[29/100], Step [20/391], Reconst Loss: 117.70360, KL Div: 11.40722, Total Loss: 129.11081
Epoch[29/100], Step [30/391], Reconst Loss: 123.87562, KL Div: 11.53866, Total Loss: 135.41428
Epoch[29/100], Step [40/391], Reconst Loss: 123.14213, KL Div: 11.17998, Total Loss: 134.32211
Epoch[29/100], Step [50/391], Reconst Loss: 118.40600, KL Div: 10.48876, Total Loss: 128.89475
Epoch[29/100], Step [60/391], Reconst Loss: 119.52299, KL Div: 11.12362, Total Loss: 130.64662
Epoch[29/100], Step [70/391], Reconst Loss: 122.29079, KL Div: 10.96587, Total Loss: 133.25666
Epoch[29/100], Step [80/391], Reconst Loss: 120.51782, KL Div: 11.14824, Total Loss: 131.66606
Epoch[29/100], Step [90/391], Reconst Loss: 114.08586, KL Div: 10.97466, Total Loss: 125.06052
Epoch[29/100], Step [100/391], Reconst Loss: 119.83229, KL Div: 11.25656, Total Loss: 131.08885
Epoch[29/100], Step [110/391], Reconst Loss: 117.44869, KL Div: 11.12458, Total Loss: 128.57327
Epoch[29/100], Step [120/391], Reconst Loss: 118.95549, KL Div: 11.60652, Total Loss: 130.56201
Epoch[29/100], Step [130/391], Reconst Loss: 119.11050, KL Div: 10.86451, Total Loss: 129.97501
Epoch[29/100], Step [140/391], Reconst Loss: 118.07515, KL Div: 10.65667, Total Loss: 128.73182
Epoch[29/100], Step [150/391], Reconst Loss: 120.62643, KL Div: 11.30588, Total Loss: 131.93232
Epoch[29/100], Step [160/391], Reconst Loss: 119.57191, KL Div: 10.76264, Total Loss: 130.33456
Epoch[29/100], Step [170/391], Reconst Loss: 117.09904, KL Div: 10.50988, Total Loss: 127.60891
Epoch[29/100], Step [180/391], Reconst Loss: 118.54362, KL Div: 10.98530, Total Loss: 129.52892
Epoch[29/100], Step [190/391], Reconst Loss: 112.62058, KL Div: 10.88197, Total Loss: 123.50255
Epoch[29/100], Step [200/391], Reconst Loss: 116.23439, KL Div: 11.15050, Total Loss: 127.38489
Epoch[29/100], Step [210/391], Reconst Loss: 118.76025, KL Div: 10.58317, Total Loss: 129.34343
Epoch[29/100], Step [220/391], Reconst Loss: 120.18156, KL Div: 10.74506, Total Loss: 130.92662
Epoch[29/100], Step [230/391], Reconst Loss: 118.50175, KL Div: 11.15724, Total Loss: 129.65899
Epoch[29/100], Step [240/391], Reconst Loss: 119.46481, KL Div: 11.23963, Total Loss: 130.70444
Epoch[29/100], Step [250/391], Reconst Loss: 116.65664, KL Div: 11.31171, Total Loss: 127.96835
Epoch[29/100], Step [260/391], Reconst Loss: 123.32948, KL Div: 11.04367, Total Loss: 134.37315
Epoch[29/100], Step [270/391], Reconst Loss: 115.83060, KL Div: 11.07271, Total Loss: 126.90331
Epoch[29/100], Step [280/391], Reconst Loss: 117.46324, KL Div: 10.83101, Total Loss: 128.29425
Epoch[29/100], Step [290/391], Reconst Loss: 125.05127, KL Div: 11.23308, Total Loss: 136.28435
Epoch[29/100], Step [300/391], Reconst Loss: 120.66369, KL Div: 11.00664, Total Loss: 131.67033
Epoch[29/100], Step [310/391], Reconst Loss: 122.28535, KL Div: 10.70748, Total Loss: 132.99283
Epoch[29/100], Step [320/391], Reconst Loss: 115.88717, KL Div: 10.67588, Total Loss: 126.56305
Epoch[29/100], Step [330/391], Reconst Loss: 114.08955, KL Div: 11.29321, Total Loss: 125.38276
Epoch[29/100], Step [340/391], Reconst Loss: 115.29609, KL Div: 10.98811, Total Loss: 126.28420
Epoch[29/100], Step [350/391], Reconst Loss: 115.18254, KL Div: 10.97482, Total Loss: 126.15736
Epoch[29/100], Step [360/391], Reconst Loss: 114.49979, KL Div: 10.80508, Total Loss: 125.30487
Epoch[29/100], Step [370/391], Reconst Loss: 120.59039, KL Div: 10.86863, Total Loss: 131.45902
Epoch[29/100], Step [380/391], Reconst Loss: 112.93294, KL Div: 11.57139, Total Loss: 124.50432
Epoch[29/100], Step [390/391], Reconst Loss: 120.14257, KL Div: 10.41038, Total Loss: 130.55295
Epoch = 29
Training epoch time =  139.27287936210632
train total loss =  128.5676775390625
valid total loss =  129.50625595703124
Total epoch time =  257.60437655448914
Saving checkpoint...
Done!
Epoch[30/100], Step [10/391], Reconst Loss: 115.19128, KL Div: 10.73520, Total Loss: 125.92648
Epoch[30/100], Step [20/391], Reconst Loss: 112.93956, KL Div: 10.93741, Total Loss: 123.87697
Epoch[30/100], Step [30/391], Reconst Loss: 118.41783, KL Div: 10.43503, Total Loss: 128.85286
Epoch[30/100], Step [40/391], Reconst Loss: 118.27943, KL Div: 11.07711, Total Loss: 129.35654
Epoch[30/100], Step [50/391], Reconst Loss: 121.54959, KL Div: 10.89960, Total Loss: 132.44919
Epoch[30/100], Step [60/391], Reconst Loss: 118.63293, KL Div: 10.88310, Total Loss: 129.51603
Epoch[30/100], Step [70/391], Reconst Loss: 121.57537, KL Div: 10.66729, Total Loss: 132.24266
Epoch[30/100], Step [80/391], Reconst Loss: 122.00078, KL Div: 11.02520, Total Loss: 133.02598
Epoch[30/100], Step [90/391], Reconst Loss: 122.69373, KL Div: 10.79522, Total Loss: 133.48895
Epoch[30/100], Step [100/391], Reconst Loss: 117.91494, KL Div: 11.00855, Total Loss: 128.92349
Epoch[30/100], Step [110/391], Reconst Loss: 121.23944, KL Div: 10.98566, Total Loss: 132.22510
Epoch[30/100], Step [120/391], Reconst Loss: 116.98113, KL Div: 11.11118, Total Loss: 128.09231
Epoch[30/100], Step [130/391], Reconst Loss: 118.78849, KL Div: 10.82179, Total Loss: 129.61028
Epoch[30/100], Step [140/391], Reconst Loss: 127.05121, KL Div: 11.06933, Total Loss: 138.12053
Epoch[30/100], Step [150/391], Reconst Loss: 115.61060, KL Div: 11.36763, Total Loss: 126.97823
Epoch[30/100], Step [160/391], Reconst Loss: 122.93218, KL Div: 11.10035, Total Loss: 134.03253
Epoch[30/100], Step [170/391], Reconst Loss: 120.24924, KL Div: 11.33605, Total Loss: 131.58529
Epoch[30/100], Step [180/391], Reconst Loss: 115.02127, KL Div: 10.99133, Total Loss: 126.01260
Epoch[30/100], Step [190/391], Reconst Loss: 116.48444, KL Div: 10.97191, Total Loss: 127.45636
Epoch[30/100], Step [200/391], Reconst Loss: 117.84729, KL Div: 11.29370, Total Loss: 129.14099
Epoch[30/100], Step [210/391], Reconst Loss: 124.96005, KL Div: 11.29748, Total Loss: 136.25753
Epoch[30/100], Step [220/391], Reconst Loss: 122.00380, KL Div: 10.94942, Total Loss: 132.95322
Epoch[30/100], Step [230/391], Reconst Loss: 114.90709, KL Div: 10.81863, Total Loss: 125.72572
Epoch[30/100], Step [240/391], Reconst Loss: 114.03131, KL Div: 10.71197, Total Loss: 124.74328
Epoch[30/100], Step [250/391], Reconst Loss: 114.01718, KL Div: 10.90031, Total Loss: 124.91749
Epoch[30/100], Step [260/391], Reconst Loss: 118.63242, KL Div: 11.28649, Total Loss: 129.91891
Epoch[30/100], Step [270/391], Reconst Loss: 123.09048, KL Div: 10.73992, Total Loss: 133.83040
Epoch[30/100], Step [280/391], Reconst Loss: 118.36271, KL Div: 11.33440, Total Loss: 129.69711
Epoch[30/100], Step [290/391], Reconst Loss: 118.42493, KL Div: 11.33068, Total Loss: 129.75561
Epoch[30/100], Step [300/391], Reconst Loss: 114.96481, KL Div: 11.17456, Total Loss: 126.13937
Epoch[30/100], Step [310/391], Reconst Loss: 116.55629, KL Div: 10.89450, Total Loss: 127.45079
Epoch[30/100], Step [320/391], Reconst Loss: 115.57303, KL Div: 10.92119, Total Loss: 126.49422
Epoch[30/100], Step [330/391], Reconst Loss: 115.64329, KL Div: 11.10346, Total Loss: 126.74675
Epoch[30/100], Step [340/391], Reconst Loss: 117.44396, KL Div: 10.85917, Total Loss: 128.30313
Epoch[30/100], Step [350/391], Reconst Loss: 110.26076, KL Div: 11.18305, Total Loss: 121.44381
Epoch[30/100], Step [360/391], Reconst Loss: 117.53266, KL Div: 10.72698, Total Loss: 128.25964
Epoch[30/100], Step [370/391], Reconst Loss: 115.97771, KL Div: 10.87063, Total Loss: 126.84834
Epoch[30/100], Step [380/391], Reconst Loss: 118.02669, KL Div: 11.01491, Total Loss: 129.04160
Epoch[30/100], Step [390/391], Reconst Loss: 124.08875, KL Div: 10.79503, Total Loss: 134.88377
Epoch = 30
Training epoch time =  139.45469188690186
train total loss =  129.216209296875
valid total loss =  130.32120109863283
Total epoch time =  257.51749181747437
Saving checkpoint...
Done!
Epoch[31/100], Step [10/391], Reconst Loss: 124.93887, KL Div: 10.89692, Total Loss: 135.83578
Epoch[31/100], Step [20/391], Reconst Loss: 113.78244, KL Div: 10.86712, Total Loss: 124.64956
Epoch[31/100], Step [30/391], Reconst Loss: 117.24665, KL Div: 10.83372, Total Loss: 128.08037
Epoch[31/100], Step [40/391], Reconst Loss: 116.15492, KL Div: 10.69868, Total Loss: 126.85360
Epoch[31/100], Step [50/391], Reconst Loss: 126.96270, KL Div: 11.34133, Total Loss: 138.30403
Epoch[31/100], Step [60/391], Reconst Loss: 116.77976, KL Div: 11.35114, Total Loss: 128.13091
Epoch[31/100], Step [70/391], Reconst Loss: 115.04630, KL Div: 11.08713, Total Loss: 126.13342
Epoch[31/100], Step [80/391], Reconst Loss: 116.99115, KL Div: 10.86252, Total Loss: 127.85367
Epoch[31/100], Step [90/391], Reconst Loss: 118.42276, KL Div: 11.12755, Total Loss: 129.55031
Epoch[31/100], Step [100/391], Reconst Loss: 118.22932, KL Div: 10.94358, Total Loss: 129.17290
Epoch[31/100], Step [110/391], Reconst Loss: 114.92818, KL Div: 11.38905, Total Loss: 126.31723
Epoch[31/100], Step [120/391], Reconst Loss: 116.08490, KL Div: 10.96027, Total Loss: 127.04517
Epoch[31/100], Step [130/391], Reconst Loss: 123.79597, KL Div: 11.32654, Total Loss: 135.12251
Epoch[31/100], Step [140/391], Reconst Loss: 120.19688, KL Div: 11.15661, Total Loss: 131.35349
Epoch[31/100], Step [150/391], Reconst Loss: 120.12699, KL Div: 11.01378, Total Loss: 131.14077
Epoch[31/100], Step [160/391], Reconst Loss: 125.77892, KL Div: 11.13240, Total Loss: 136.91132
Epoch[31/100], Step [170/391], Reconst Loss: 118.39403, KL Div: 10.70355, Total Loss: 129.09758
Epoch[31/100], Step [180/391], Reconst Loss: 125.81331, KL Div: 11.40162, Total Loss: 137.21493
Epoch[31/100], Step [190/391], Reconst Loss: 116.88403, KL Div: 10.58103, Total Loss: 127.46506
Epoch[31/100], Step [200/391], Reconst Loss: 119.03795, KL Div: 10.99716, Total Loss: 130.03511
Epoch[31/100], Step [210/391], Reconst Loss: 120.66862, KL Div: 10.86968, Total Loss: 131.53830
Epoch[31/100], Step [220/391], Reconst Loss: 117.73781, KL Div: 11.65258, Total Loss: 129.39039
Epoch[31/100], Step [230/391], Reconst Loss: 122.78159, KL Div: 10.71409, Total Loss: 133.49568
Epoch[31/100], Step [240/391], Reconst Loss: 115.70571, KL Div: 11.13605, Total Loss: 126.84176
Epoch[31/100], Step [250/391], Reconst Loss: 122.36964, KL Div: 10.96911, Total Loss: 133.33875
Epoch[31/100], Step [260/391], Reconst Loss: 120.70220, KL Div: 10.85173, Total Loss: 131.55394
Epoch[31/100], Step [270/391], Reconst Loss: 121.14240, KL Div: 10.85033, Total Loss: 131.99274
Epoch[31/100], Step [280/391], Reconst Loss: 121.63739, KL Div: 11.30505, Total Loss: 132.94244
Epoch[31/100], Step [290/391], Reconst Loss: 118.30311, KL Div: 11.40431, Total Loss: 129.70742
Epoch[31/100], Step [300/391], Reconst Loss: 112.95495, KL Div: 11.27441, Total Loss: 124.22936
Epoch[31/100], Step [310/391], Reconst Loss: 123.81997, KL Div: 11.10963, Total Loss: 134.92960
Epoch[31/100], Step [320/391], Reconst Loss: 120.47069, KL Div: 11.17264, Total Loss: 131.64333
Epoch[31/100], Step [330/391], Reconst Loss: 115.54465, KL Div: 11.47497, Total Loss: 127.01962
Epoch[31/100], Step [340/391], Reconst Loss: 117.13291, KL Div: 11.30187, Total Loss: 128.43478
Epoch[31/100], Step [350/391], Reconst Loss: 121.48456, KL Div: 11.15511, Total Loss: 132.63967
Epoch[31/100], Step [360/391], Reconst Loss: 115.21021, KL Div: 11.39854, Total Loss: 126.60874
Epoch[31/100], Step [370/391], Reconst Loss: 113.48889, KL Div: 11.19428, Total Loss: 124.68317
Epoch[31/100], Step [380/391], Reconst Loss: 117.52579, KL Div: 10.96307, Total Loss: 128.48887
Epoch[31/100], Step [390/391], Reconst Loss: 116.70364, KL Div: 10.83880, Total Loss: 127.54244
Epoch = 31
Training epoch time =  139.7327024936676
train total loss =  128.3470096875
valid total loss =  129.49544372558594
Total epoch time =  257.7773337364197
Saving checkpoint...
Done!
Epoch[32/100], Step [10/391], Reconst Loss: 119.90856, KL Div: 11.01442, Total Loss: 130.92298
Epoch[32/100], Step [20/391], Reconst Loss: 118.15013, KL Div: 11.24827, Total Loss: 129.39840
Epoch[32/100], Step [30/391], Reconst Loss: 117.24385, KL Div: 11.19890, Total Loss: 128.44275
Epoch[32/100], Step [40/391], Reconst Loss: 113.84782, KL Div: 11.75795, Total Loss: 125.60577
Epoch[32/100], Step [50/391], Reconst Loss: 115.82307, KL Div: 11.45291, Total Loss: 127.27598
Epoch[32/100], Step [60/391], Reconst Loss: 122.07555, KL Div: 11.40381, Total Loss: 133.47936
Epoch[32/100], Step [70/391], Reconst Loss: 123.68172, KL Div: 11.15116, Total Loss: 134.83288
Epoch[32/100], Step [80/391], Reconst Loss: 115.74170, KL Div: 11.30910, Total Loss: 127.05080
Epoch[32/100], Step [90/391], Reconst Loss: 116.46344, KL Div: 10.88658, Total Loss: 127.35002
Epoch[32/100], Step [100/391], Reconst Loss: 120.70226, KL Div: 11.14000, Total Loss: 131.84226
Epoch[32/100], Step [110/391], Reconst Loss: 114.83466, KL Div: 11.07178, Total Loss: 125.90644
Epoch[32/100], Step [120/391], Reconst Loss: 120.61773, KL Div: 10.94997, Total Loss: 131.56770
Epoch[32/100], Step [130/391], Reconst Loss: 117.90749, KL Div: 10.73181, Total Loss: 128.63930
Epoch[32/100], Step [140/391], Reconst Loss: 113.93759, KL Div: 11.38202, Total Loss: 125.31962
Epoch[32/100], Step [150/391], Reconst Loss: 116.40149, KL Div: 10.77733, Total Loss: 127.17882
Epoch[32/100], Step [160/391], Reconst Loss: 122.27058, KL Div: 11.33980, Total Loss: 133.61038
Epoch[32/100], Step [170/391], Reconst Loss: 119.12382, KL Div: 11.12110, Total Loss: 130.24492
Epoch[32/100], Step [180/391], Reconst Loss: 115.69274, KL Div: 10.91762, Total Loss: 126.61036
Epoch[32/100], Step [190/391], Reconst Loss: 121.10534, KL Div: 11.72357, Total Loss: 132.82891
Epoch[32/100], Step [200/391], Reconst Loss: 114.63305, KL Div: 11.25290, Total Loss: 125.88595
Epoch[32/100], Step [210/391], Reconst Loss: 114.51520, KL Div: 11.15212, Total Loss: 125.66732
Epoch[32/100], Step [220/391], Reconst Loss: 117.89685, KL Div: 11.19316, Total Loss: 129.09001
Epoch[32/100], Step [230/391], Reconst Loss: 108.86533, KL Div: 11.17250, Total Loss: 120.03784
Epoch[32/100], Step [240/391], Reconst Loss: 122.25361, KL Div: 11.56163, Total Loss: 133.81524
Epoch[32/100], Step [250/391], Reconst Loss: 111.79341, KL Div: 11.57279, Total Loss: 123.36620
Epoch[32/100], Step [260/391], Reconst Loss: 113.49368, KL Div: 11.40767, Total Loss: 124.90135
Epoch[32/100], Step [270/391], Reconst Loss: 117.59815, KL Div: 11.02009, Total Loss: 128.61825
Epoch[32/100], Step [280/391], Reconst Loss: 121.34288, KL Div: 10.98033, Total Loss: 132.32321
Epoch[32/100], Step [290/391], Reconst Loss: 122.25574, KL Div: 10.94664, Total Loss: 133.20238
Epoch[32/100], Step [300/391], Reconst Loss: 116.47693, KL Div: 11.16334, Total Loss: 127.64027
Epoch[32/100], Step [310/391], Reconst Loss: 114.00818, KL Div: 11.19803, Total Loss: 125.20621
Epoch[32/100], Step [320/391], Reconst Loss: 121.69905, KL Div: 11.26029, Total Loss: 132.95934
Epoch[32/100], Step [330/391], Reconst Loss: 119.52853, KL Div: 11.05527, Total Loss: 130.58379
Epoch[32/100], Step [340/391], Reconst Loss: 119.09352, KL Div: 10.86916, Total Loss: 129.96268
Epoch[32/100], Step [350/391], Reconst Loss: 117.94204, KL Div: 10.63331, Total Loss: 128.57535
Epoch[32/100], Step [360/391], Reconst Loss: 114.94102, KL Div: 11.36531, Total Loss: 126.30634
Epoch[32/100], Step [370/391], Reconst Loss: 118.62104, KL Div: 11.05205, Total Loss: 129.67309
Epoch[32/100], Step [380/391], Reconst Loss: 113.40137, KL Div: 10.80851, Total Loss: 124.20988
Epoch[32/100], Step [390/391], Reconst Loss: 123.60812, KL Div: 11.01189, Total Loss: 134.62001
Epoch = 32
Training epoch time =  139.13660502433777
train total loss =  128.8508433203125
valid total loss =  130.0780758544922
Total epoch time =  257.2619409561157
Saving checkpoint...
Done!
Epoch[33/100], Step [10/391], Reconst Loss: 112.77659, KL Div: 11.40289, Total Loss: 124.17948
Epoch[33/100], Step [20/391], Reconst Loss: 120.21879, KL Div: 11.41044, Total Loss: 131.62923
Epoch[33/100], Step [30/391], Reconst Loss: 113.79578, KL Div: 11.12605, Total Loss: 124.92183
Epoch[33/100], Step [40/391], Reconst Loss: 118.67925, KL Div: 11.12645, Total Loss: 129.80570
Epoch[33/100], Step [50/391], Reconst Loss: 123.18823, KL Div: 10.89586, Total Loss: 134.08409
Epoch[33/100], Step [60/391], Reconst Loss: 117.98645, KL Div: 10.90398, Total Loss: 128.89043
Epoch[33/100], Step [70/391], Reconst Loss: 121.07488, KL Div: 10.96561, Total Loss: 132.04049
Epoch[33/100], Step [80/391], Reconst Loss: 123.65058, KL Div: 11.36269, Total Loss: 135.01327
Epoch[33/100], Step [90/391], Reconst Loss: 116.22672, KL Div: 11.41842, Total Loss: 127.64514
Epoch[33/100], Step [100/391], Reconst Loss: 114.50903, KL Div: 11.09853, Total Loss: 125.60757
Epoch[33/100], Step [110/391], Reconst Loss: 118.34830, KL Div: 10.80527, Total Loss: 129.15357
Epoch[33/100], Step [120/391], Reconst Loss: 122.85046, KL Div: 10.95694, Total Loss: 133.80740
Epoch[33/100], Step [130/391], Reconst Loss: 121.35944, KL Div: 10.85403, Total Loss: 132.21347
Epoch[33/100], Step [140/391], Reconst Loss: 117.20963, KL Div: 11.34038, Total Loss: 128.55001
Epoch[33/100], Step [150/391], Reconst Loss: 116.35287, KL Div: 11.12272, Total Loss: 127.47560
Epoch[33/100], Step [160/391], Reconst Loss: 116.42847, KL Div: 11.59906, Total Loss: 128.02753
Epoch[33/100], Step [170/391], Reconst Loss: 116.16798, KL Div: 10.74872, Total Loss: 126.91670
Epoch[33/100], Step [180/391], Reconst Loss: 121.10585, KL Div: 11.00344, Total Loss: 132.10929
Epoch[33/100], Step [190/391], Reconst Loss: 122.14110, KL Div: 10.82868, Total Loss: 132.96978
Epoch[33/100], Step [200/391], Reconst Loss: 117.41085, KL Div: 11.63596, Total Loss: 129.04681
Epoch[33/100], Step [210/391], Reconst Loss: 119.48978, KL Div: 11.32900, Total Loss: 130.81878
Epoch[33/100], Step [220/391], Reconst Loss: 122.19753, KL Div: 11.50756, Total Loss: 133.70508
Epoch[33/100], Step [230/391], Reconst Loss: 119.89497, KL Div: 11.33720, Total Loss: 131.23217
Epoch[33/100], Step [240/391], Reconst Loss: 114.64029, KL Div: 11.15980, Total Loss: 125.80009
Epoch[33/100], Step [250/391], Reconst Loss: 119.19825, KL Div: 11.32725, Total Loss: 130.52550
Epoch[33/100], Step [260/391], Reconst Loss: 123.23482, KL Div: 11.33314, Total Loss: 134.56796
Epoch[33/100], Step [270/391], Reconst Loss: 116.54858, KL Div: 11.54820, Total Loss: 128.09677
Epoch[33/100], Step [280/391], Reconst Loss: 121.35686, KL Div: 11.42203, Total Loss: 132.77889
Epoch[33/100], Step [290/391], Reconst Loss: 118.49873, KL Div: 10.54124, Total Loss: 129.03998
Epoch[33/100], Step [300/391], Reconst Loss: 113.83054, KL Div: 11.45995, Total Loss: 125.29049
Epoch[33/100], Step [310/391], Reconst Loss: 122.12728, KL Div: 11.25225, Total Loss: 133.37953
Epoch[33/100], Step [320/391], Reconst Loss: 116.54950, KL Div: 11.16320, Total Loss: 127.71270
Epoch[33/100], Step [330/391], Reconst Loss: 120.61679, KL Div: 11.07940, Total Loss: 131.69619
Epoch[33/100], Step [340/391], Reconst Loss: 116.53007, KL Div: 10.86851, Total Loss: 127.39857
Epoch[33/100], Step [350/391], Reconst Loss: 113.34671, KL Div: 11.12362, Total Loss: 124.47033
Epoch[33/100], Step [360/391], Reconst Loss: 119.88091, KL Div: 11.21275, Total Loss: 131.09366
Epoch[33/100], Step [370/391], Reconst Loss: 108.98848, KL Div: 11.28295, Total Loss: 120.27143
Epoch[33/100], Step [380/391], Reconst Loss: 116.49411, KL Div: 10.67606, Total Loss: 127.17017
Epoch[33/100], Step [390/391], Reconst Loss: 120.52280, KL Div: 10.96287, Total Loss: 131.48567
Epoch = 33
Training epoch time =  139.10677313804626
train total loss =  128.78603533203125
valid total loss =  129.96903996582031
Total epoch time =  257.5544731616974
Saving checkpoint...
Done!
Epoch[34/100], Step [10/391], Reconst Loss: 122.52531, KL Div: 11.40427, Total Loss: 133.92958
Epoch[34/100], Step [20/391], Reconst Loss: 118.86323, KL Div: 11.72529, Total Loss: 130.58852
Epoch[34/100], Step [30/391], Reconst Loss: 117.22414, KL Div: 11.44797, Total Loss: 128.67211
Epoch[34/100], Step [40/391], Reconst Loss: 119.83643, KL Div: 11.08051, Total Loss: 130.91693
Epoch[34/100], Step [50/391], Reconst Loss: 119.27127, KL Div: 11.16390, Total Loss: 130.43517
Epoch[34/100], Step [60/391], Reconst Loss: 118.82201, KL Div: 11.26699, Total Loss: 130.08900
Epoch[34/100], Step [70/391], Reconst Loss: 118.12097, KL Div: 11.67179, Total Loss: 129.79276
Epoch[34/100], Step [80/391], Reconst Loss: 118.07846, KL Div: 11.51188, Total Loss: 129.59034
Epoch[34/100], Step [90/391], Reconst Loss: 124.59911, KL Div: 11.54546, Total Loss: 136.14457
Epoch[34/100], Step [100/391], Reconst Loss: 123.26032, KL Div: 11.64424, Total Loss: 134.90456
Epoch[34/100], Step [110/391], Reconst Loss: 119.54478, KL Div: 11.54967, Total Loss: 131.09445
Epoch[34/100], Step [120/391], Reconst Loss: 113.82752, KL Div: 11.03218, Total Loss: 124.85970
Epoch[34/100], Step [130/391], Reconst Loss: 116.74651, KL Div: 11.07324, Total Loss: 127.81975
Epoch[34/100], Step [140/391], Reconst Loss: 118.16936, KL Div: 11.28423, Total Loss: 129.45358
Epoch[34/100], Step [150/391], Reconst Loss: 116.93425, KL Div: 11.52874, Total Loss: 128.46299
Epoch[34/100], Step [160/391], Reconst Loss: 115.86362, KL Div: 11.28214, Total Loss: 127.14576
Epoch[34/100], Step [170/391], Reconst Loss: 120.54633, KL Div: 10.58954, Total Loss: 131.13587
Epoch[34/100], Step [180/391], Reconst Loss: 122.36510, KL Div: 10.78629, Total Loss: 133.15139
Epoch[34/100], Step [190/391], Reconst Loss: 117.53799, KL Div: 11.24084, Total Loss: 128.77883
Epoch[34/100], Step [200/391], Reconst Loss: 119.93655, KL Div: 11.01467, Total Loss: 130.95122
Epoch[34/100], Step [210/391], Reconst Loss: 121.35568, KL Div: 11.23442, Total Loss: 132.59010
Epoch[34/100], Step [220/391], Reconst Loss: 121.97886, KL Div: 10.78015, Total Loss: 132.75900
Epoch[34/100], Step [230/391], Reconst Loss: 120.26404, KL Div: 11.48604, Total Loss: 131.75008
Epoch[34/100], Step [240/391], Reconst Loss: 124.29050, KL Div: 11.20608, Total Loss: 135.49658
Epoch[34/100], Step [250/391], Reconst Loss: 120.85881, KL Div: 11.25646, Total Loss: 132.11527
Epoch[34/100], Step [260/391], Reconst Loss: 118.53082, KL Div: 11.86945, Total Loss: 130.40026
Epoch[34/100], Step [270/391], Reconst Loss: 117.95686, KL Div: 10.67763, Total Loss: 128.63450
Epoch[34/100], Step [280/391], Reconst Loss: 122.84972, KL Div: 11.38965, Total Loss: 134.23936
Epoch[34/100], Step [290/391], Reconst Loss: 117.25421, KL Div: 11.15183, Total Loss: 128.40604
Epoch[34/100], Step [300/391], Reconst Loss: 119.10752, KL Div: 11.37879, Total Loss: 130.48632
Epoch[34/100], Step [310/391], Reconst Loss: 117.16795, KL Div: 11.00083, Total Loss: 128.16879
Epoch[34/100], Step [320/391], Reconst Loss: 124.63976, KL Div: 11.23248, Total Loss: 135.87223
Epoch[34/100], Step [330/391], Reconst Loss: 118.66443, KL Div: 11.31332, Total Loss: 129.97775
Epoch[34/100], Step [340/391], Reconst Loss: 112.15590, KL Div: 11.08737, Total Loss: 123.24327
Epoch[34/100], Step [350/391], Reconst Loss: 120.09270, KL Div: 10.83763, Total Loss: 130.93034
Epoch[34/100], Step [360/391], Reconst Loss: 119.41987, KL Div: 11.10802, Total Loss: 130.52789
Epoch[34/100], Step [370/391], Reconst Loss: 115.11773, KL Div: 11.30778, Total Loss: 126.42551
Epoch[34/100], Step [380/391], Reconst Loss: 117.64488, KL Div: 10.83465, Total Loss: 128.47953
Epoch[34/100], Step [390/391], Reconst Loss: 116.26092, KL Div: 11.34738, Total Loss: 127.60830
Epoch = 34
Training epoch time =  139.4186990261078
train total loss =  128.45131095703124
valid total loss =  129.54038278808594
Total epoch time =  257.89479398727417
Saving checkpoint...
Done!
Epoch[35/100], Step [10/391], Reconst Loss: 121.88148, KL Div: 11.25959, Total Loss: 133.14108
Epoch[35/100], Step [20/391], Reconst Loss: 112.00645, KL Div: 11.60670, Total Loss: 123.61315
Epoch[35/100], Step [30/391], Reconst Loss: 121.09137, KL Div: 11.63297, Total Loss: 132.72434
Epoch[35/100], Step [40/391], Reconst Loss: 118.55953, KL Div: 11.19685, Total Loss: 129.75638
Epoch[35/100], Step [50/391], Reconst Loss: 113.15227, KL Div: 11.41519, Total Loss: 124.56746
Epoch[35/100], Step [60/391], Reconst Loss: 120.96866, KL Div: 11.03877, Total Loss: 132.00743
Epoch[35/100], Step [70/391], Reconst Loss: 115.52512, KL Div: 11.29629, Total Loss: 126.82140
Epoch[35/100], Step [80/391], Reconst Loss: 119.59248, KL Div: 11.58595, Total Loss: 131.17843
Epoch[35/100], Step [90/391], Reconst Loss: 121.12363, KL Div: 11.51153, Total Loss: 132.63516
Epoch[35/100], Step [100/391], Reconst Loss: 116.59744, KL Div: 11.34278, Total Loss: 127.94022
Epoch[35/100], Step [110/391], Reconst Loss: 112.76144, KL Div: 11.21232, Total Loss: 123.97376
Epoch[35/100], Step [120/391], Reconst Loss: 118.31058, KL Div: 11.19926, Total Loss: 129.50984
Epoch[35/100], Step [130/391], Reconst Loss: 117.59389, KL Div: 11.33953, Total Loss: 128.93342
Epoch[35/100], Step [140/391], Reconst Loss: 117.63061, KL Div: 11.43284, Total Loss: 129.06345
Epoch[35/100], Step [150/391], Reconst Loss: 119.12699, KL Div: 11.28454, Total Loss: 130.41153
Epoch[35/100], Step [160/391], Reconst Loss: 123.47226, KL Div: 11.69276, Total Loss: 135.16502
Epoch[35/100], Step [170/391], Reconst Loss: 117.73504, KL Div: 11.21964, Total Loss: 128.95468
Epoch[35/100], Step [180/391], Reconst Loss: 115.06676, KL Div: 11.33411, Total Loss: 126.40087
Epoch[35/100], Step [190/391], Reconst Loss: 113.02385, KL Div: 11.05933, Total Loss: 124.08318
Epoch[35/100], Step [200/391], Reconst Loss: 116.22308, KL Div: 11.13926, Total Loss: 127.36234
Epoch[35/100], Step [210/391], Reconst Loss: 115.56267, KL Div: 11.48079, Total Loss: 127.04346
Epoch[35/100], Step [220/391], Reconst Loss: 111.87688, KL Div: 11.69460, Total Loss: 123.57148
Epoch[35/100], Step [230/391], Reconst Loss: 116.01591, KL Div: 11.75944, Total Loss: 127.77536
Epoch[35/100], Step [240/391], Reconst Loss: 120.20797, KL Div: 11.39030, Total Loss: 131.59827
Epoch[35/100], Step [250/391], Reconst Loss: 113.70332, KL Div: 10.98315, Total Loss: 124.68647
Epoch[35/100], Step [260/391], Reconst Loss: 116.42388, KL Div: 11.24463, Total Loss: 127.66851
Epoch[35/100], Step [270/391], Reconst Loss: 117.72827, KL Div: 10.95063, Total Loss: 128.67891
Epoch[35/100], Step [280/391], Reconst Loss: 127.82436, KL Div: 11.24096, Total Loss: 139.06532
Epoch[35/100], Step [290/391], Reconst Loss: 120.08469, KL Div: 11.39115, Total Loss: 131.47585
Epoch[35/100], Step [300/391], Reconst Loss: 120.49261, KL Div: 11.16245, Total Loss: 131.65506
Epoch[35/100], Step [310/391], Reconst Loss: 113.83694, KL Div: 11.18412, Total Loss: 125.02105
Epoch[35/100], Step [320/391], Reconst Loss: 118.76205, KL Div: 11.46795, Total Loss: 130.23000
Epoch[35/100], Step [330/391], Reconst Loss: 116.42039, KL Div: 11.35618, Total Loss: 127.77657
Epoch[35/100], Step [340/391], Reconst Loss: 117.39936, KL Div: 10.80966, Total Loss: 128.20902
Epoch[35/100], Step [350/391], Reconst Loss: 110.88293, KL Div: 11.25337, Total Loss: 122.13631
Epoch[35/100], Step [360/391], Reconst Loss: 123.97070, KL Div: 11.57639, Total Loss: 135.54709
Epoch[35/100], Step [370/391], Reconst Loss: 119.74082, KL Div: 11.37070, Total Loss: 131.11152
Epoch[35/100], Step [380/391], Reconst Loss: 114.96450, KL Div: 11.27543, Total Loss: 126.23993
Epoch[35/100], Step [390/391], Reconst Loss: 114.97126, KL Div: 11.14207, Total Loss: 126.11333
Epoch = 35
Training epoch time =  139.36854076385498
train total loss =  128.27391873046875
valid total loss =  129.2596248779297
Total epoch time =  257.92441296577454
Saving checkpoint...
Done!
Epoch[36/100], Step [10/391], Reconst Loss: 124.34927, KL Div: 11.14602, Total Loss: 135.49528
Epoch[36/100], Step [20/391], Reconst Loss: 112.70435, KL Div: 11.39919, Total Loss: 124.10354
Epoch[36/100], Step [30/391], Reconst Loss: 112.42599, KL Div: 10.93122, Total Loss: 123.35721
Epoch[36/100], Step [40/391], Reconst Loss: 111.99745, KL Div: 11.60016, Total Loss: 123.59762
Epoch[36/100], Step [50/391], Reconst Loss: 125.25850, KL Div: 10.98209, Total Loss: 136.24059
Epoch[36/100], Step [60/391], Reconst Loss: 115.49033, KL Div: 11.22386, Total Loss: 126.71419
Epoch[36/100], Step [70/391], Reconst Loss: 113.09271, KL Div: 11.32432, Total Loss: 124.41703
Epoch[36/100], Step [80/391], Reconst Loss: 120.90293, KL Div: 11.30696, Total Loss: 132.20989
Epoch[36/100], Step [90/391], Reconst Loss: 117.40672, KL Div: 11.23276, Total Loss: 128.63948
Epoch[36/100], Step [100/391], Reconst Loss: 114.32099, KL Div: 11.47045, Total Loss: 125.79145
Epoch[36/100], Step [110/391], Reconst Loss: 118.59832, KL Div: 11.48903, Total Loss: 130.08735
Epoch[36/100], Step [120/391], Reconst Loss: 115.39047, KL Div: 11.22324, Total Loss: 126.61371
Epoch[36/100], Step [130/391], Reconst Loss: 114.98637, KL Div: 11.55401, Total Loss: 126.54038
Epoch[36/100], Step [140/391], Reconst Loss: 115.03721, KL Div: 11.31322, Total Loss: 126.35043
Epoch[36/100], Step [150/391], Reconst Loss: 119.26526, KL Div: 11.33641, Total Loss: 130.60167
Epoch[36/100], Step [160/391], Reconst Loss: 117.19852, KL Div: 11.25234, Total Loss: 128.45086
Epoch[36/100], Step [170/391], Reconst Loss: 110.26872, KL Div: 11.35791, Total Loss: 121.62663
Epoch[36/100], Step [180/391], Reconst Loss: 116.19621, KL Div: 11.23672, Total Loss: 127.43292
Epoch[36/100], Step [190/391], Reconst Loss: 120.95842, KL Div: 11.38186, Total Loss: 132.34028
Epoch[36/100], Step [200/391], Reconst Loss: 113.33668, KL Div: 10.91412, Total Loss: 124.25080
Epoch[36/100], Step [210/391], Reconst Loss: 114.92627, KL Div: 11.52001, Total Loss: 126.44628
Epoch[36/100], Step [220/391], Reconst Loss: 119.73751, KL Div: 10.97462, Total Loss: 130.71213
Epoch[36/100], Step [230/391], Reconst Loss: 118.82867, KL Div: 11.27642, Total Loss: 130.10509
Epoch[36/100], Step [240/391], Reconst Loss: 114.82862, KL Div: 11.19522, Total Loss: 126.02384
Epoch[36/100], Step [250/391], Reconst Loss: 120.42450, KL Div: 11.33362, Total Loss: 131.75811
Epoch[36/100], Step [260/391], Reconst Loss: 113.46082, KL Div: 11.43028, Total Loss: 124.89110
Epoch[36/100], Step [270/391], Reconst Loss: 123.97247, KL Div: 11.73935, Total Loss: 135.71183
Epoch[36/100], Step [280/391], Reconst Loss: 116.01163, KL Div: 11.44241, Total Loss: 127.45404
Epoch[36/100], Step [290/391], Reconst Loss: 116.16108, KL Div: 11.11665, Total Loss: 127.27773
Epoch[36/100], Step [300/391], Reconst Loss: 119.09026, KL Div: 11.55330, Total Loss: 130.64355
Epoch[36/100], Step [310/391], Reconst Loss: 114.84533, KL Div: 11.40140, Total Loss: 126.24673
Epoch[36/100], Step [320/391], Reconst Loss: 115.71444, KL Div: 11.35406, Total Loss: 127.06850
Epoch[36/100], Step [330/391], Reconst Loss: 114.39091, KL Div: 11.29764, Total Loss: 125.68855
Epoch[36/100], Step [340/391], Reconst Loss: 115.74132, KL Div: 11.21560, Total Loss: 126.95692
Epoch[36/100], Step [350/391], Reconst Loss: 114.89398, KL Div: 11.10388, Total Loss: 125.99787
Epoch[36/100], Step [360/391], Reconst Loss: 117.94544, KL Div: 11.42754, Total Loss: 129.37298
Epoch[36/100], Step [370/391], Reconst Loss: 127.90951, KL Div: 11.06303, Total Loss: 138.97254
Epoch[36/100], Step [380/391], Reconst Loss: 119.60342, KL Div: 11.48267, Total Loss: 131.08609
Epoch[36/100], Step [390/391], Reconst Loss: 116.00970, KL Div: 11.29015, Total Loss: 127.29985
Epoch = 36
Training epoch time =  139.21023559570312
train total loss =  127.43836603515625
valid total loss =  128.29108365478515
Total epoch time =  257.5736083984375
Saving checkpoint...
Done!
Epoch[37/100], Step [10/391], Reconst Loss: 117.86053, KL Div: 11.60245, Total Loss: 129.46299
Epoch[37/100], Step [20/391], Reconst Loss: 119.21680, KL Div: 10.89583, Total Loss: 130.11264
Epoch[37/100], Step [30/391], Reconst Loss: 122.83218, KL Div: 11.64551, Total Loss: 134.47769
Epoch[37/100], Step [40/391], Reconst Loss: 108.52179, KL Div: 10.93815, Total Loss: 119.45994
Epoch[37/100], Step [50/391], Reconst Loss: 120.12424, KL Div: 11.10293, Total Loss: 131.22717
Epoch[37/100], Step [60/391], Reconst Loss: 126.47678, KL Div: 10.72052, Total Loss: 137.19730
Epoch[37/100], Step [70/391], Reconst Loss: 119.33339, KL Div: 11.35468, Total Loss: 130.68807
Epoch[37/100], Step [80/391], Reconst Loss: 117.32063, KL Div: 11.29101, Total Loss: 128.61165
Epoch[37/100], Step [90/391], Reconst Loss: 117.96094, KL Div: 11.48800, Total Loss: 129.44894
Epoch[37/100], Step [100/391], Reconst Loss: 107.09334, KL Div: 11.38062, Total Loss: 118.47395
Epoch[37/100], Step [110/391], Reconst Loss: 117.94623, KL Div: 11.58479, Total Loss: 129.53102
Epoch[37/100], Step [120/391], Reconst Loss: 123.09866, KL Div: 11.42882, Total Loss: 134.52748
Epoch[37/100], Step [130/391], Reconst Loss: 121.94223, KL Div: 11.30745, Total Loss: 133.24968
Epoch[37/100], Step [140/391], Reconst Loss: 116.05132, KL Div: 11.12775, Total Loss: 127.17907
Epoch[37/100], Step [150/391], Reconst Loss: 116.22821, KL Div: 11.13146, Total Loss: 127.35967
Epoch[37/100], Step [160/391], Reconst Loss: 119.65889, KL Div: 11.41378, Total Loss: 131.07267
Epoch[37/100], Step [170/391], Reconst Loss: 118.47086, KL Div: 10.38239, Total Loss: 128.85326
Epoch[37/100], Step [180/391], Reconst Loss: 119.75830, KL Div: 11.38586, Total Loss: 131.14416
Epoch[37/100], Step [190/391], Reconst Loss: 113.54514, KL Div: 11.25143, Total Loss: 124.79656
Epoch[37/100], Step [200/391], Reconst Loss: 120.12774, KL Div: 11.01473, Total Loss: 131.14247
Epoch[37/100], Step [210/391], Reconst Loss: 121.52783, KL Div: 11.47812, Total Loss: 133.00595
Epoch[37/100], Step [220/391], Reconst Loss: 120.39943, KL Div: 11.16828, Total Loss: 131.56771
Epoch[37/100], Step [230/391], Reconst Loss: 111.95964, KL Div: 11.11008, Total Loss: 123.06973
Epoch[37/100], Step [240/391], Reconst Loss: 116.26167, KL Div: 10.97309, Total Loss: 127.23477
Epoch[37/100], Step [250/391], Reconst Loss: 117.41280, KL Div: 11.17296, Total Loss: 128.58575
Epoch[37/100], Step [260/391], Reconst Loss: 113.71849, KL Div: 11.44688, Total Loss: 125.16537
Epoch[37/100], Step [270/391], Reconst Loss: 114.35463, KL Div: 11.08855, Total Loss: 125.44317
Epoch[37/100], Step [280/391], Reconst Loss: 118.49171, KL Div: 11.23921, Total Loss: 129.73092
Epoch[37/100], Step [290/391], Reconst Loss: 114.61036, KL Div: 11.29324, Total Loss: 125.90360
Epoch[37/100], Step [300/391], Reconst Loss: 118.14288, KL Div: 10.88461, Total Loss: 129.02749
Epoch[37/100], Step [310/391], Reconst Loss: 116.55845, KL Div: 11.05446, Total Loss: 127.61291
Epoch[37/100], Step [320/391], Reconst Loss: 120.46321, KL Div: 11.09192, Total Loss: 131.55513
Epoch[37/100], Step [330/391], Reconst Loss: 119.05170, KL Div: 11.32981, Total Loss: 130.38151
Epoch[37/100], Step [340/391], Reconst Loss: 111.62265, KL Div: 11.77074, Total Loss: 123.39339
Epoch[37/100], Step [350/391], Reconst Loss: 111.16260, KL Div: 11.26185, Total Loss: 122.42444
Epoch[37/100], Step [360/391], Reconst Loss: 121.89302, KL Div: 11.61580, Total Loss: 133.50882
Epoch[37/100], Step [370/391], Reconst Loss: 120.19695, KL Div: 11.03435, Total Loss: 131.23130
Epoch[37/100], Step [380/391], Reconst Loss: 113.16704, KL Div: 11.59246, Total Loss: 124.75950
Epoch[37/100], Step [390/391], Reconst Loss: 121.20220, KL Div: 11.47889, Total Loss: 132.68109
Epoch = 37
Training epoch time =  139.9792070388794
train total loss =  127.7923255859375
valid total loss =  128.96864846191406
Total epoch time =  258.86500120162964
Saving checkpoint...
Done!
Epoch[38/100], Step [10/391], Reconst Loss: 114.11793, KL Div: 11.27529, Total Loss: 125.39322
Epoch[38/100], Step [20/391], Reconst Loss: 120.16602, KL Div: 11.41773, Total Loss: 131.58375
Epoch[38/100], Step [30/391], Reconst Loss: 122.82365, KL Div: 11.19411, Total Loss: 134.01775
Epoch[38/100], Step [40/391], Reconst Loss: 120.46602, KL Div: 11.14923, Total Loss: 131.61525
Epoch[38/100], Step [50/391], Reconst Loss: 119.17404, KL Div: 10.97720, Total Loss: 130.15124
Epoch[38/100], Step [60/391], Reconst Loss: 112.81497, KL Div: 11.29109, Total Loss: 124.10606
Epoch[38/100], Step [70/391], Reconst Loss: 123.61321, KL Div: 10.96479, Total Loss: 134.57800
Epoch[38/100], Step [80/391], Reconst Loss: 117.10938, KL Div: 11.30959, Total Loss: 128.41898
Epoch[38/100], Step [90/391], Reconst Loss: 115.46716, KL Div: 11.45068, Total Loss: 126.91784
Epoch[38/100], Step [100/391], Reconst Loss: 114.79698, KL Div: 11.32345, Total Loss: 126.12043
Epoch[38/100], Step [110/391], Reconst Loss: 121.55264, KL Div: 10.95582, Total Loss: 132.50846
Epoch[38/100], Step [120/391], Reconst Loss: 116.65164, KL Div: 11.23533, Total Loss: 127.88697
Epoch[38/100], Step [130/391], Reconst Loss: 113.81587, KL Div: 11.38685, Total Loss: 125.20272
Epoch[38/100], Step [140/391], Reconst Loss: 121.07304, KL Div: 11.07583, Total Loss: 132.14887
Epoch[38/100], Step [150/391], Reconst Loss: 113.29480, KL Div: 11.12436, Total Loss: 124.41916
Epoch[38/100], Step [160/391], Reconst Loss: 120.14785, KL Div: 11.32867, Total Loss: 131.47652
Epoch[38/100], Step [170/391], Reconst Loss: 109.99570, KL Div: 10.85065, Total Loss: 120.84635
Epoch[38/100], Step [180/391], Reconst Loss: 117.47948, KL Div: 11.19612, Total Loss: 128.67560
Epoch[38/100], Step [190/391], Reconst Loss: 116.40077, KL Div: 10.95448, Total Loss: 127.35525
Epoch[38/100], Step [200/391], Reconst Loss: 117.41640, KL Div: 11.32578, Total Loss: 128.74218
Epoch[38/100], Step [210/391], Reconst Loss: 115.79764, KL Div: 11.18365, Total Loss: 126.98129
Epoch[38/100], Step [220/391], Reconst Loss: 122.71783, KL Div: 11.08040, Total Loss: 133.79823
Epoch[38/100], Step [230/391], Reconst Loss: 119.41584, KL Div: 11.16632, Total Loss: 130.58216
Epoch[38/100], Step [240/391], Reconst Loss: 118.54361, KL Div: 11.19505, Total Loss: 129.73866
Epoch[38/100], Step [250/391], Reconst Loss: 115.76961, KL Div: 10.93267, Total Loss: 126.70228
Epoch[38/100], Step [260/391], Reconst Loss: 116.22043, KL Div: 10.72743, Total Loss: 126.94786
Epoch[38/100], Step [270/391], Reconst Loss: 118.64435, KL Div: 10.92435, Total Loss: 129.56870
Epoch[38/100], Step [280/391], Reconst Loss: 118.31907, KL Div: 10.61606, Total Loss: 128.93513
Epoch[38/100], Step [290/391], Reconst Loss: 119.48659, KL Div: 11.21689, Total Loss: 130.70348
Epoch[38/100], Step [300/391], Reconst Loss: 114.83754, KL Div: 11.30564, Total Loss: 126.14318
Epoch[38/100], Step [310/391], Reconst Loss: 114.63023, KL Div: 11.16088, Total Loss: 125.79112
Epoch[38/100], Step [320/391], Reconst Loss: 112.99432, KL Div: 10.85018, Total Loss: 123.84450
Epoch[38/100], Step [330/391], Reconst Loss: 117.60410, KL Div: 11.28269, Total Loss: 128.88679
Epoch[38/100], Step [340/391], Reconst Loss: 116.24860, KL Div: 11.36763, Total Loss: 127.61623
Epoch[38/100], Step [350/391], Reconst Loss: 119.86955, KL Div: 11.35487, Total Loss: 131.22443
Epoch[38/100], Step [360/391], Reconst Loss: 118.87523, KL Div: 11.58698, Total Loss: 130.46221
Epoch[38/100], Step [370/391], Reconst Loss: 113.89304, KL Div: 10.56469, Total Loss: 124.45773
Epoch[38/100], Step [380/391], Reconst Loss: 112.49509, KL Div: 10.85329, Total Loss: 123.34839
Epoch[38/100], Step [390/391], Reconst Loss: 113.66728, KL Div: 11.19434, Total Loss: 124.86162
Epoch = 38
Training epoch time =  141.31680965423584
train total loss =  127.68348490234375
valid total loss =  128.69302426757812
Total epoch time =  259.61098074913025
Saving checkpoint...
Done!
Epoch[39/100], Step [10/391], Reconst Loss: 116.43162, KL Div: 11.18487, Total Loss: 127.61649
Epoch[39/100], Step [20/391], Reconst Loss: 111.93098, KL Div: 10.94506, Total Loss: 122.87604
Epoch[39/100], Step [30/391], Reconst Loss: 115.28493, KL Div: 11.29030, Total Loss: 126.57523
Epoch[39/100], Step [40/391], Reconst Loss: 115.53837, KL Div: 11.50587, Total Loss: 127.04424
Epoch[39/100], Step [50/391], Reconst Loss: 121.45605, KL Div: 10.96576, Total Loss: 132.42180
Epoch[39/100], Step [60/391], Reconst Loss: 121.64973, KL Div: 10.96882, Total Loss: 132.61856
Epoch[39/100], Step [70/391], Reconst Loss: 115.08974, KL Div: 10.75139, Total Loss: 125.84113
Epoch[39/100], Step [80/391], Reconst Loss: 113.64412, KL Div: 10.86106, Total Loss: 124.50518
Epoch[39/100], Step [90/391], Reconst Loss: 116.99832, KL Div: 11.28494, Total Loss: 128.28326
Epoch[39/100], Step [100/391], Reconst Loss: 122.49079, KL Div: 11.43521, Total Loss: 133.92600
Epoch[39/100], Step [110/391], Reconst Loss: 121.92611, KL Div: 11.43844, Total Loss: 133.36455
Epoch[39/100], Step [120/391], Reconst Loss: 114.47932, KL Div: 11.18173, Total Loss: 125.66106
Epoch[39/100], Step [130/391], Reconst Loss: 115.23326, KL Div: 11.20651, Total Loss: 126.43977
Epoch[39/100], Step [140/391], Reconst Loss: 119.36886, KL Div: 11.20404, Total Loss: 130.57290
Epoch[39/100], Step [150/391], Reconst Loss: 114.57289, KL Div: 10.70810, Total Loss: 125.28099
Epoch[39/100], Step [160/391], Reconst Loss: 120.73487, KL Div: 11.19093, Total Loss: 131.92580
Epoch[39/100], Step [170/391], Reconst Loss: 112.72480, KL Div: 10.94999, Total Loss: 123.67479
Epoch[39/100], Step [180/391], Reconst Loss: 120.69540, KL Div: 11.37935, Total Loss: 132.07474
Epoch[39/100], Step [190/391], Reconst Loss: 114.24213, KL Div: 11.19740, Total Loss: 125.43952
Epoch[39/100], Step [200/391], Reconst Loss: 112.58394, KL Div: 10.71189, Total Loss: 123.29583
Epoch[39/100], Step [210/391], Reconst Loss: 119.73837, KL Div: 11.20349, Total Loss: 130.94186
Epoch[39/100], Step [220/391], Reconst Loss: 112.77319, KL Div: 10.87763, Total Loss: 123.65081
Epoch[39/100], Step [230/391], Reconst Loss: 118.03240, KL Div: 11.07996, Total Loss: 129.11236
Epoch[39/100], Step [240/391], Reconst Loss: 121.01556, KL Div: 11.02561, Total Loss: 132.04116
Epoch[39/100], Step [250/391], Reconst Loss: 120.02989, KL Div: 11.09890, Total Loss: 131.12879
Epoch[39/100], Step [260/391], Reconst Loss: 113.81659, KL Div: 11.01257, Total Loss: 124.82916
Epoch[39/100], Step [270/391], Reconst Loss: 119.64664, KL Div: 11.45867, Total Loss: 131.10530
Epoch[39/100], Step [280/391], Reconst Loss: 111.80612, KL Div: 11.21859, Total Loss: 123.02471
Epoch[39/100], Step [290/391], Reconst Loss: 117.00629, KL Div: 10.86752, Total Loss: 127.87381
Epoch[39/100], Step [300/391], Reconst Loss: 119.92892, KL Div: 11.25731, Total Loss: 131.18623
Epoch[39/100], Step [310/391], Reconst Loss: 117.59344, KL Div: 11.05229, Total Loss: 128.64573
Epoch[39/100], Step [320/391], Reconst Loss: 120.20737, KL Div: 11.11822, Total Loss: 131.32560
Epoch[39/100], Step [330/391], Reconst Loss: 119.10652, KL Div: 11.34159, Total Loss: 130.44811
Epoch[39/100], Step [340/391], Reconst Loss: 118.19868, KL Div: 11.06809, Total Loss: 129.26677
Epoch[39/100], Step [350/391], Reconst Loss: 116.36718, KL Div: 11.33084, Total Loss: 127.69802
Epoch[39/100], Step [360/391], Reconst Loss: 112.33990, KL Div: 10.93563, Total Loss: 123.27553
Epoch[39/100], Step [370/391], Reconst Loss: 119.09396, KL Div: 11.22182, Total Loss: 130.31577
Epoch[39/100], Step [380/391], Reconst Loss: 120.47768, KL Div: 10.87681, Total Loss: 131.35448
Epoch[39/100], Step [390/391], Reconst Loss: 115.98634, KL Div: 10.99988, Total Loss: 126.98623
Epoch = 39
Training epoch time =  139.4297592639923
train total loss =  127.55803263671875
valid total loss =  128.61263415527344
Total epoch time =  258.08851408958435
Saving checkpoint...
Done!
Epoch[40/100], Step [10/391], Reconst Loss: 116.06652, KL Div: 11.34712, Total Loss: 127.41364
Epoch[40/100], Step [20/391], Reconst Loss: 122.04998, KL Div: 10.88963, Total Loss: 132.93961
Epoch[40/100], Step [30/391], Reconst Loss: 115.84036, KL Div: 11.17138, Total Loss: 127.01174
Epoch[40/100], Step [40/391], Reconst Loss: 124.02950, KL Div: 11.16834, Total Loss: 135.19783
Epoch[40/100], Step [50/391], Reconst Loss: 119.40737, KL Div: 11.14855, Total Loss: 130.55592
Epoch[40/100], Step [60/391], Reconst Loss: 121.81082, KL Div: 11.11181, Total Loss: 132.92263
Epoch[40/100], Step [70/391], Reconst Loss: 120.41668, KL Div: 11.16824, Total Loss: 131.58492
Epoch[40/100], Step [80/391], Reconst Loss: 116.72942, KL Div: 11.02277, Total Loss: 127.75219
Epoch[40/100], Step [90/391], Reconst Loss: 121.21688, KL Div: 11.23793, Total Loss: 132.45482
Epoch[40/100], Step [100/391], Reconst Loss: 116.20889, KL Div: 11.21489, Total Loss: 127.42379
Epoch[40/100], Step [110/391], Reconst Loss: 116.89352, KL Div: 10.99286, Total Loss: 127.88638
Epoch[40/100], Step [120/391], Reconst Loss: 114.73159, KL Div: 11.26241, Total Loss: 125.99400
Epoch[40/100], Step [130/391], Reconst Loss: 116.81393, KL Div: 11.31156, Total Loss: 128.12549
Epoch[40/100], Step [140/391], Reconst Loss: 118.94786, KL Div: 11.35571, Total Loss: 130.30357
Epoch[40/100], Step [150/391], Reconst Loss: 119.20501, KL Div: 11.67080, Total Loss: 130.87581
Epoch[40/100], Step [160/391], Reconst Loss: 118.23041, KL Div: 11.56483, Total Loss: 129.79524
Epoch[40/100], Step [170/391], Reconst Loss: 114.21057, KL Div: 10.85110, Total Loss: 125.06167
Epoch[40/100], Step [180/391], Reconst Loss: 120.25591, KL Div: 10.93393, Total Loss: 131.18983
Epoch[40/100], Step [190/391], Reconst Loss: 114.21402, KL Div: 11.19176, Total Loss: 125.40578
Epoch[40/100], Step [200/391], Reconst Loss: 109.20431, KL Div: 11.26088, Total Loss: 120.46519
Epoch[40/100], Step [210/391], Reconst Loss: 111.44023, KL Div: 11.03199, Total Loss: 122.47223
Epoch[40/100], Step [220/391], Reconst Loss: 121.54266, KL Div: 10.75215, Total Loss: 132.29481
Epoch[40/100], Step [230/391], Reconst Loss: 114.64336, KL Div: 11.54460, Total Loss: 126.18796
Epoch[40/100], Step [240/391], Reconst Loss: 118.71111, KL Div: 11.11032, Total Loss: 129.82143
Epoch[40/100], Step [250/391], Reconst Loss: 119.24326, KL Div: 11.37353, Total Loss: 130.61679
Epoch[40/100], Step [260/391], Reconst Loss: 115.83675, KL Div: 10.87235, Total Loss: 126.70910
Epoch[40/100], Step [270/391], Reconst Loss: 111.98740, KL Div: 11.09338, Total Loss: 123.08078
Epoch[40/100], Step [280/391], Reconst Loss: 113.14693, KL Div: 11.39670, Total Loss: 124.54363
Epoch[40/100], Step [290/391], Reconst Loss: 114.93013, KL Div: 11.14356, Total Loss: 126.07369
Epoch[40/100], Step [300/391], Reconst Loss: 118.20593, KL Div: 11.40436, Total Loss: 129.61030
Epoch[40/100], Step [310/391], Reconst Loss: 117.73135, KL Div: 11.13044, Total Loss: 128.86178
Epoch[40/100], Step [320/391], Reconst Loss: 120.92332, KL Div: 11.17568, Total Loss: 132.09901
Epoch[40/100], Step [330/391], Reconst Loss: 119.52948, KL Div: 11.26462, Total Loss: 130.79410
Epoch[40/100], Step [340/391], Reconst Loss: 115.57487, KL Div: 11.35706, Total Loss: 126.93193
Epoch[40/100], Step [350/391], Reconst Loss: 122.50731, KL Div: 11.34155, Total Loss: 133.84886
Epoch[40/100], Step [360/391], Reconst Loss: 117.21796, KL Div: 10.72557, Total Loss: 127.94353
Epoch[40/100], Step [370/391], Reconst Loss: 114.77484, KL Div: 11.03752, Total Loss: 125.81236
Epoch[40/100], Step [380/391], Reconst Loss: 113.29587, KL Div: 11.47268, Total Loss: 124.76855
Epoch[40/100], Step [390/391], Reconst Loss: 127.45491, KL Div: 11.12918, Total Loss: 138.58409
Epoch = 40
Training epoch time =  143.51332926750183
train total loss =  128.07671734375
valid total loss =  129.21569833984375
Total epoch time =  261.6973340511322
Saving checkpoint...
Done!
Epoch[41/100], Step [10/391], Reconst Loss: 111.95135, KL Div: 11.01917, Total Loss: 122.97053
Epoch[41/100], Step [20/391], Reconst Loss: 121.72786, KL Div: 11.23502, Total Loss: 132.96288
Epoch[41/100], Step [30/391], Reconst Loss: 118.07475, KL Div: 11.40897, Total Loss: 129.48372
Epoch[41/100], Step [40/391], Reconst Loss: 118.88191, KL Div: 11.04437, Total Loss: 129.92628
Epoch[41/100], Step [50/391], Reconst Loss: 121.52763, KL Div: 11.30070, Total Loss: 132.82833
Epoch[41/100], Step [60/391], Reconst Loss: 124.79581, KL Div: 11.32225, Total Loss: 136.11807
Epoch[41/100], Step [70/391], Reconst Loss: 123.94548, KL Div: 12.14200, Total Loss: 136.08748
Epoch[41/100], Step [80/391], Reconst Loss: 115.62296, KL Div: 11.07498, Total Loss: 126.69793
Epoch[41/100], Step [90/391], Reconst Loss: 116.80865, KL Div: 11.31330, Total Loss: 128.12195
Epoch[41/100], Step [100/391], Reconst Loss: 111.37833, KL Div: 11.44024, Total Loss: 122.81856
Epoch[41/100], Step [110/391], Reconst Loss: 118.09423, KL Div: 11.27108, Total Loss: 129.36531
Epoch[41/100], Step [120/391], Reconst Loss: 116.38591, KL Div: 11.11831, Total Loss: 127.50422
Epoch[41/100], Step [130/391], Reconst Loss: 118.39783, KL Div: 11.22399, Total Loss: 129.62182
Epoch[41/100], Step [140/391], Reconst Loss: 110.95366, KL Div: 10.74324, Total Loss: 121.69690
Epoch[41/100], Step [150/391], Reconst Loss: 116.59921, KL Div: 11.35537, Total Loss: 127.95458
Epoch[41/100], Step [160/391], Reconst Loss: 120.10841, KL Div: 11.55252, Total Loss: 131.66094
Epoch[41/100], Step [170/391], Reconst Loss: 117.91315, KL Div: 11.27370, Total Loss: 129.18685
Epoch[41/100], Step [180/391], Reconst Loss: 118.94901, KL Div: 11.62389, Total Loss: 130.57290
Epoch[41/100], Step [190/391], Reconst Loss: 118.53454, KL Div: 11.69474, Total Loss: 130.22928
Epoch[41/100], Step [200/391], Reconst Loss: 110.47109, KL Div: 11.10039, Total Loss: 121.57148
Epoch[41/100], Step [210/391], Reconst Loss: 118.35892, KL Div: 11.30291, Total Loss: 129.66183
Epoch[41/100], Step [220/391], Reconst Loss: 120.43909, KL Div: 11.51324, Total Loss: 131.95232
Epoch[41/100], Step [230/391], Reconst Loss: 112.54776, KL Div: 11.44020, Total Loss: 123.98796
Epoch[41/100], Step [240/391], Reconst Loss: 113.47675, KL Div: 11.50076, Total Loss: 124.97750
Epoch[41/100], Step [250/391], Reconst Loss: 115.45244, KL Div: 11.61249, Total Loss: 127.06493
Epoch[41/100], Step [260/391], Reconst Loss: 120.52453, KL Div: 11.58273, Total Loss: 132.10726
Epoch[41/100], Step [270/391], Reconst Loss: 113.66486, KL Div: 11.57075, Total Loss: 125.23562
Epoch[41/100], Step [280/391], Reconst Loss: 115.70605, KL Div: 11.14039, Total Loss: 126.84644
Epoch[41/100], Step [290/391], Reconst Loss: 118.23386, KL Div: 12.14629, Total Loss: 130.38014
Epoch[41/100], Step [300/391], Reconst Loss: 117.33598, KL Div: 11.39614, Total Loss: 128.73212
Epoch[41/100], Step [310/391], Reconst Loss: 115.60247, KL Div: 11.01494, Total Loss: 126.61741
Epoch[41/100], Step [320/391], Reconst Loss: 118.28874, KL Div: 11.61723, Total Loss: 129.90597
Epoch[41/100], Step [330/391], Reconst Loss: 119.03626, KL Div: 11.36671, Total Loss: 130.40297
Epoch[41/100], Step [340/391], Reconst Loss: 118.57330, KL Div: 11.14472, Total Loss: 129.71802
Epoch[41/100], Step [350/391], Reconst Loss: 123.64515, KL Div: 11.36699, Total Loss: 135.01214
Epoch[41/100], Step [360/391], Reconst Loss: 117.86843, KL Div: 11.41955, Total Loss: 129.28799
Epoch[41/100], Step [370/391], Reconst Loss: 116.05657, KL Div: 10.91948, Total Loss: 126.97605
Epoch[41/100], Step [380/391], Reconst Loss: 113.36664, KL Div: 11.56592, Total Loss: 124.93256
Epoch[41/100], Step [390/391], Reconst Loss: 113.98814, KL Div: 11.15872, Total Loss: 125.14686
Epoch = 41
Training epoch time =  139.24416041374207
train total loss =  127.439605
valid total loss =  128.69857866210938
Total epoch time =  257.3571569919586
Saving checkpoint...
Done!
Epoch[42/100], Step [10/391], Reconst Loss: 121.18971, KL Div: 11.57477, Total Loss: 132.76448
Epoch[42/100], Step [20/391], Reconst Loss: 122.31985, KL Div: 11.30536, Total Loss: 133.62522
Epoch[42/100], Step [30/391], Reconst Loss: 119.76678, KL Div: 11.36833, Total Loss: 131.13511
Epoch[42/100], Step [40/391], Reconst Loss: 120.98954, KL Div: 11.53964, Total Loss: 132.52918
Epoch[42/100], Step [50/391], Reconst Loss: 115.79457, KL Div: 11.35763, Total Loss: 127.15220
Epoch[42/100], Step [60/391], Reconst Loss: 123.78930, KL Div: 11.03820, Total Loss: 134.82750
Epoch[42/100], Step [70/391], Reconst Loss: 109.76311, KL Div: 11.34582, Total Loss: 121.10893
Epoch[42/100], Step [80/391], Reconst Loss: 119.55165, KL Div: 11.13018, Total Loss: 130.68183
Epoch[42/100], Step [90/391], Reconst Loss: 121.69320, KL Div: 11.17631, Total Loss: 132.86951
Epoch[42/100], Step [100/391], Reconst Loss: 121.64050, KL Div: 11.18298, Total Loss: 132.82348
Epoch[42/100], Step [110/391], Reconst Loss: 117.76934, KL Div: 11.46946, Total Loss: 129.23880
Epoch[42/100], Step [120/391], Reconst Loss: 114.55296, KL Div: 10.97320, Total Loss: 125.52617
Epoch[42/100], Step [130/391], Reconst Loss: 116.09592, KL Div: 11.11807, Total Loss: 127.21399
Epoch[42/100], Step [140/391], Reconst Loss: 116.42952, KL Div: 11.23489, Total Loss: 127.66441
Epoch[42/100], Step [150/391], Reconst Loss: 114.06747, KL Div: 11.36701, Total Loss: 125.43449
Epoch[42/100], Step [160/391], Reconst Loss: 117.14993, KL Div: 11.14566, Total Loss: 128.29559
Epoch[42/100], Step [170/391], Reconst Loss: 118.75748, KL Div: 11.18609, Total Loss: 129.94356
Epoch[42/100], Step [180/391], Reconst Loss: 117.85390, KL Div: 11.21014, Total Loss: 129.06404
Epoch[42/100], Step [190/391], Reconst Loss: 116.10143, KL Div: 11.84118, Total Loss: 127.94260
Epoch[42/100], Step [200/391], Reconst Loss: 119.62808, KL Div: 11.68067, Total Loss: 131.30875
Epoch[42/100], Step [210/391], Reconst Loss: 118.33230, KL Div: 11.12176, Total Loss: 129.45406
Epoch[42/100], Step [220/391], Reconst Loss: 114.53983, KL Div: 10.59168, Total Loss: 125.13151
Epoch[42/100], Step [230/391], Reconst Loss: 113.68881, KL Div: 11.30873, Total Loss: 124.99755
Epoch[42/100], Step [240/391], Reconst Loss: 115.18033, KL Div: 11.62427, Total Loss: 126.80459
Epoch[42/100], Step [250/391], Reconst Loss: 115.04051, KL Div: 11.32618, Total Loss: 126.36669
Epoch[42/100], Step [260/391], Reconst Loss: 121.13275, KL Div: 10.97030, Total Loss: 132.10305
Epoch[42/100], Step [270/391], Reconst Loss: 115.21352, KL Div: 11.08187, Total Loss: 126.29539
Epoch[42/100], Step [280/391], Reconst Loss: 117.61256, KL Div: 11.22768, Total Loss: 128.84024
Epoch[42/100], Step [290/391], Reconst Loss: 114.86863, KL Div: 11.05368, Total Loss: 125.92231
Epoch[42/100], Step [300/391], Reconst Loss: 115.98477, KL Div: 11.48942, Total Loss: 127.47419
Epoch[42/100], Step [310/391], Reconst Loss: 118.74899, KL Div: 10.97751, Total Loss: 129.72650
Epoch[42/100], Step [320/391], Reconst Loss: 121.56189, KL Div: 11.14595, Total Loss: 132.70784
Epoch[42/100], Step [330/391], Reconst Loss: 116.59424, KL Div: 10.99133, Total Loss: 127.58556
Epoch[42/100], Step [340/391], Reconst Loss: 116.30151, KL Div: 11.42110, Total Loss: 127.72262
Epoch[42/100], Step [350/391], Reconst Loss: 122.65717, KL Div: 11.14330, Total Loss: 133.80047
Epoch[42/100], Step [360/391], Reconst Loss: 118.60715, KL Div: 11.70322, Total Loss: 130.31037
Epoch[42/100], Step [370/391], Reconst Loss: 114.50838, KL Div: 11.13764, Total Loss: 125.64602
Epoch[42/100], Step [380/391], Reconst Loss: 114.32875, KL Div: 11.33135, Total Loss: 125.66010
Epoch[42/100], Step [390/391], Reconst Loss: 114.98344, KL Div: 11.13876, Total Loss: 126.12219
Epoch = 42
Training epoch time =  139.54142379760742
train total loss =  127.82457169921875
valid total loss =  129.1572526123047
Total epoch time =  257.79262948036194
Saving checkpoint...
Done!
Epoch[43/100], Step [10/391], Reconst Loss: 113.36862, KL Div: 11.10353, Total Loss: 124.47215
Epoch[43/100], Step [20/391], Reconst Loss: 118.83239, KL Div: 11.41112, Total Loss: 130.24351
Epoch[43/100], Step [30/391], Reconst Loss: 117.67173, KL Div: 11.69911, Total Loss: 129.37084
Epoch[43/100], Step [40/391], Reconst Loss: 120.76896, KL Div: 11.30864, Total Loss: 132.07760
Epoch[43/100], Step [50/391], Reconst Loss: 117.39184, KL Div: 11.33979, Total Loss: 128.73163
Epoch[43/100], Step [60/391], Reconst Loss: 115.55529, KL Div: 11.04798, Total Loss: 126.60327
Epoch[43/100], Step [70/391], Reconst Loss: 117.30180, KL Div: 11.09928, Total Loss: 128.40108
Epoch[43/100], Step [80/391], Reconst Loss: 121.77578, KL Div: 11.16892, Total Loss: 132.94470
Epoch[43/100], Step [90/391], Reconst Loss: 120.10008, KL Div: 11.22564, Total Loss: 131.32572
Epoch[43/100], Step [100/391], Reconst Loss: 121.23996, KL Div: 11.47399, Total Loss: 132.71395
Epoch[43/100], Step [110/391], Reconst Loss: 120.06221, KL Div: 11.36411, Total Loss: 131.42632
Epoch[43/100], Step [120/391], Reconst Loss: 114.02237, KL Div: 11.46489, Total Loss: 125.48726
Epoch[43/100], Step [130/391], Reconst Loss: 120.37553, KL Div: 11.37475, Total Loss: 131.75028
Epoch[43/100], Step [140/391], Reconst Loss: 118.58273, KL Div: 11.45397, Total Loss: 130.03670
Epoch[43/100], Step [150/391], Reconst Loss: 117.99081, KL Div: 11.20105, Total Loss: 129.19186
Epoch[43/100], Step [160/391], Reconst Loss: 112.07602, KL Div: 11.76740, Total Loss: 123.84342
Epoch[43/100], Step [170/391], Reconst Loss: 113.67672, KL Div: 11.01725, Total Loss: 124.69397
Epoch[43/100], Step [180/391], Reconst Loss: 114.20523, KL Div: 10.92351, Total Loss: 125.12874
Epoch[43/100], Step [190/391], Reconst Loss: 115.45123, KL Div: 11.40446, Total Loss: 126.85569
Epoch[43/100], Step [200/391], Reconst Loss: 121.05712, KL Div: 11.04480, Total Loss: 132.10192
Epoch[43/100], Step [210/391], Reconst Loss: 117.03618, KL Div: 11.38350, Total Loss: 128.41968
Epoch[43/100], Step [220/391], Reconst Loss: 116.43726, KL Div: 11.49398, Total Loss: 127.93124
Epoch[43/100], Step [230/391], Reconst Loss: 111.75755, KL Div: 11.31321, Total Loss: 123.07076
Epoch[43/100], Step [240/391], Reconst Loss: 123.60672, KL Div: 11.53947, Total Loss: 135.14619
Epoch[43/100], Step [250/391], Reconst Loss: 119.99733, KL Div: 11.25207, Total Loss: 131.24940
Epoch[43/100], Step [260/391], Reconst Loss: 115.35578, KL Div: 10.98428, Total Loss: 126.34007
Epoch[43/100], Step [270/391], Reconst Loss: 129.29915, KL Div: 11.52977, Total Loss: 140.82892
Epoch[43/100], Step [280/391], Reconst Loss: 117.48315, KL Div: 11.56933, Total Loss: 129.05248
Epoch[43/100], Step [290/391], Reconst Loss: 119.50276, KL Div: 11.69282, Total Loss: 131.19558
Epoch[43/100], Step [300/391], Reconst Loss: 117.39869, KL Div: 10.96841, Total Loss: 128.36710
Epoch[43/100], Step [310/391], Reconst Loss: 122.19290, KL Div: 11.23826, Total Loss: 133.43116
Epoch[43/100], Step [320/391], Reconst Loss: 118.79199, KL Div: 11.13012, Total Loss: 129.92211
Epoch[43/100], Step [330/391], Reconst Loss: 120.83325, KL Div: 11.29578, Total Loss: 132.12903
Epoch[43/100], Step [340/391], Reconst Loss: 118.22704, KL Div: 11.71046, Total Loss: 129.93751
Epoch[43/100], Step [350/391], Reconst Loss: 119.14779, KL Div: 11.76124, Total Loss: 130.90903
Epoch[43/100], Step [360/391], Reconst Loss: 114.32346, KL Div: 11.33711, Total Loss: 125.66057
Epoch[43/100], Step [370/391], Reconst Loss: 111.71370, KL Div: 11.42206, Total Loss: 123.13576
Epoch[43/100], Step [380/391], Reconst Loss: 107.40482, KL Div: 11.21735, Total Loss: 118.62217
Epoch[43/100], Step [390/391], Reconst Loss: 115.01212, KL Div: 11.64441, Total Loss: 126.65653
Epoch = 43
Training epoch time =  139.31419253349304
train total loss =  127.295695703125
valid total loss =  128.40515573730468
Total epoch time =  257.94859623908997
Saving checkpoint...
Done!
Epoch[44/100], Step [10/391], Reconst Loss: 112.91762, KL Div: 11.24430, Total Loss: 124.16192
Epoch[44/100], Step [20/391], Reconst Loss: 117.60075, KL Div: 11.24202, Total Loss: 128.84277
Epoch[44/100], Step [30/391], Reconst Loss: 120.25169, KL Div: 11.55873, Total Loss: 131.81041
Epoch[44/100], Step [40/391], Reconst Loss: 124.34347, KL Div: 11.31781, Total Loss: 135.66128
Epoch[44/100], Step [50/391], Reconst Loss: 115.96718, KL Div: 11.39301, Total Loss: 127.36019
Epoch[44/100], Step [60/391], Reconst Loss: 116.67574, KL Div: 11.32844, Total Loss: 128.00417
Epoch[44/100], Step [70/391], Reconst Loss: 118.80811, KL Div: 11.78330, Total Loss: 130.59140
Epoch[44/100], Step [80/391], Reconst Loss: 122.32369, KL Div: 11.58469, Total Loss: 133.90838
Epoch[44/100], Step [90/391], Reconst Loss: 123.25164, KL Div: 11.50175, Total Loss: 134.75339
Epoch[44/100], Step [100/391], Reconst Loss: 116.09653, KL Div: 10.81996, Total Loss: 126.91649
Epoch[44/100], Step [110/391], Reconst Loss: 117.59228, KL Div: 11.40755, Total Loss: 128.99983
Epoch[44/100], Step [120/391], Reconst Loss: 117.82887, KL Div: 11.38993, Total Loss: 129.21879
Epoch[44/100], Step [130/391], Reconst Loss: 113.51845, KL Div: 11.50221, Total Loss: 125.02066
Epoch[44/100], Step [140/391], Reconst Loss: 114.39261, KL Div: 11.32019, Total Loss: 125.71280
Epoch[44/100], Step [150/391], Reconst Loss: 116.89622, KL Div: 11.62097, Total Loss: 128.51718
Epoch[44/100], Step [160/391], Reconst Loss: 116.93496, KL Div: 11.50496, Total Loss: 128.43992
Epoch[44/100], Step [170/391], Reconst Loss: 111.67464, KL Div: 11.19910, Total Loss: 122.87374
Epoch[44/100], Step [180/391], Reconst Loss: 117.05673, KL Div: 11.38617, Total Loss: 128.44290
Epoch[44/100], Step [190/391], Reconst Loss: 117.38777, KL Div: 11.23968, Total Loss: 128.62745
Epoch[44/100], Step [200/391], Reconst Loss: 119.19850, KL Div: 11.44602, Total Loss: 130.64452
Epoch[44/100], Step [210/391], Reconst Loss: 115.81824, KL Div: 11.50161, Total Loss: 127.31986
Epoch[44/100], Step [220/391], Reconst Loss: 113.48294, KL Div: 11.45273, Total Loss: 124.93568
Epoch[44/100], Step [230/391], Reconst Loss: 114.69366, KL Div: 11.42769, Total Loss: 126.12135
Epoch[44/100], Step [240/391], Reconst Loss: 114.85204, KL Div: 11.67493, Total Loss: 126.52697
Epoch[44/100], Step [250/391], Reconst Loss: 115.88560, KL Div: 11.73340, Total Loss: 127.61900
Epoch[44/100], Step [260/391], Reconst Loss: 108.86667, KL Div: 11.32713, Total Loss: 120.19380
Epoch[44/100], Step [270/391], Reconst Loss: 125.82548, KL Div: 11.58600, Total Loss: 137.41148
Epoch[44/100], Step [280/391], Reconst Loss: 111.00876, KL Div: 10.99992, Total Loss: 122.00868
Epoch[44/100], Step [290/391], Reconst Loss: 114.93641, KL Div: 11.79583, Total Loss: 126.73224
Epoch[44/100], Step [300/391], Reconst Loss: 115.14082, KL Div: 11.46789, Total Loss: 126.60872
Epoch[44/100], Step [310/391], Reconst Loss: 118.82886, KL Div: 11.43020, Total Loss: 130.25906
Epoch[44/100], Step [320/391], Reconst Loss: 112.39144, KL Div: 11.27445, Total Loss: 123.66589
Epoch[44/100], Step [330/391], Reconst Loss: 113.56835, KL Div: 11.09012, Total Loss: 124.65848
Epoch[44/100], Step [340/391], Reconst Loss: 120.59397, KL Div: 11.61124, Total Loss: 132.20521
Epoch[44/100], Step [350/391], Reconst Loss: 112.08899, KL Div: 10.95256, Total Loss: 123.04155
Epoch[44/100], Step [360/391], Reconst Loss: 110.84190, KL Div: 11.15013, Total Loss: 121.99204
Epoch[44/100], Step [370/391], Reconst Loss: 118.53766, KL Div: 11.05975, Total Loss: 129.59741
Epoch[44/100], Step [380/391], Reconst Loss: 114.75987, KL Div: 11.17212, Total Loss: 125.93199
Epoch[44/100], Step [390/391], Reconst Loss: 115.95387, KL Div: 11.50746, Total Loss: 127.46133
Epoch = 44
Training epoch time =  139.26509404182434
train total loss =  126.88663568359375
valid total loss =  128.07350103759765
Total epoch time =  259.99174761772156
Saving checkpoint...
Done!
Epoch[45/100], Step [10/391], Reconst Loss: 116.94307, KL Div: 11.52421, Total Loss: 128.46728
Epoch[45/100], Step [20/391], Reconst Loss: 118.97149, KL Div: 11.63675, Total Loss: 130.60824
Epoch[45/100], Step [30/391], Reconst Loss: 117.74594, KL Div: 11.24519, Total Loss: 128.99113
Epoch[45/100], Step [40/391], Reconst Loss: 122.16292, KL Div: 11.43517, Total Loss: 133.59808
Epoch[45/100], Step [50/391], Reconst Loss: 111.46091, KL Div: 11.45686, Total Loss: 122.91778
Epoch[45/100], Step [60/391], Reconst Loss: 114.60960, KL Div: 11.18019, Total Loss: 125.78980
Epoch[45/100], Step [70/391], Reconst Loss: 115.08910, KL Div: 11.06441, Total Loss: 126.15351
Epoch[45/100], Step [80/391], Reconst Loss: 115.49348, KL Div: 11.24121, Total Loss: 126.73468
Epoch[45/100], Step [90/391], Reconst Loss: 113.98087, KL Div: 11.57659, Total Loss: 125.55746
Epoch[45/100], Step [100/391], Reconst Loss: 112.26947, KL Div: 11.31258, Total Loss: 123.58205
Epoch[45/100], Step [110/391], Reconst Loss: 114.69333, KL Div: 11.36464, Total Loss: 126.05797
Epoch[45/100], Step [120/391], Reconst Loss: 126.86983, KL Div: 11.40426, Total Loss: 138.27409
Epoch[45/100], Step [130/391], Reconst Loss: 111.07206, KL Div: 11.57052, Total Loss: 122.64258
Epoch[45/100], Step [140/391], Reconst Loss: 116.50415, KL Div: 11.54548, Total Loss: 128.04963
Epoch[45/100], Step [150/391], Reconst Loss: 117.98882, KL Div: 11.51982, Total Loss: 129.50863
Epoch[45/100], Step [160/391], Reconst Loss: 122.37135, KL Div: 11.54601, Total Loss: 133.91736
Epoch[45/100], Step [170/391], Reconst Loss: 111.17206, KL Div: 11.33055, Total Loss: 122.50261
Epoch[45/100], Step [180/391], Reconst Loss: 116.81397, KL Div: 11.06915, Total Loss: 127.88312
Epoch[45/100], Step [190/391], Reconst Loss: 117.10019, KL Div: 11.62176, Total Loss: 128.72195
Epoch[45/100], Step [200/391], Reconst Loss: 122.17699, KL Div: 11.65668, Total Loss: 133.83367
Epoch[45/100], Step [210/391], Reconst Loss: 114.78490, KL Div: 10.93085, Total Loss: 125.71574
Epoch[45/100], Step [220/391], Reconst Loss: 115.00346, KL Div: 11.34272, Total Loss: 126.34618
Epoch[45/100], Step [230/391], Reconst Loss: 123.43793, KL Div: 11.64157, Total Loss: 135.07950
Epoch[45/100], Step [240/391], Reconst Loss: 115.64418, KL Div: 11.45341, Total Loss: 127.09759
Epoch[45/100], Step [250/391], Reconst Loss: 118.01691, KL Div: 11.08586, Total Loss: 129.10277
Epoch[45/100], Step [260/391], Reconst Loss: 116.31076, KL Div: 11.60800, Total Loss: 127.91876
Epoch[45/100], Step [270/391], Reconst Loss: 113.51694, KL Div: 11.17831, Total Loss: 124.69525
Epoch[45/100], Step [280/391], Reconst Loss: 116.60539, KL Div: 11.38443, Total Loss: 127.98982
Epoch[45/100], Step [290/391], Reconst Loss: 116.34106, KL Div: 11.05209, Total Loss: 127.39316
Epoch[45/100], Step [300/391], Reconst Loss: 117.09167, KL Div: 11.54115, Total Loss: 128.63282
Epoch[45/100], Step [310/391], Reconst Loss: 116.08086, KL Div: 11.23349, Total Loss: 127.31435
Epoch[45/100], Step [320/391], Reconst Loss: 114.24072, KL Div: 10.94502, Total Loss: 125.18574
Epoch[45/100], Step [330/391], Reconst Loss: 112.30167, KL Div: 11.32729, Total Loss: 123.62896
Epoch[45/100], Step [340/391], Reconst Loss: 118.11862, KL Div: 11.34215, Total Loss: 129.46078
Epoch[45/100], Step [350/391], Reconst Loss: 115.00803, KL Div: 11.35108, Total Loss: 126.35911
Epoch[45/100], Step [360/391], Reconst Loss: 117.50284, KL Div: 11.45581, Total Loss: 128.95865
Epoch[45/100], Step [370/391], Reconst Loss: 118.00819, KL Div: 11.36302, Total Loss: 129.37122
Epoch[45/100], Step [380/391], Reconst Loss: 114.51104, KL Div: 11.74752, Total Loss: 126.25856
Epoch[45/100], Step [390/391], Reconst Loss: 117.83223, KL Div: 11.51621, Total Loss: 129.34844
Epoch = 45
Training epoch time =  143.07828283309937
train total loss =  127.3899604296875
valid total loss =  128.59277025146486
Total epoch time =  261.56108593940735
Saving checkpoint...
Done!
Epoch[46/100], Step [10/391], Reconst Loss: 116.50563, KL Div: 11.19234, Total Loss: 127.69797
Epoch[46/100], Step [20/391], Reconst Loss: 117.25398, KL Div: 11.44410, Total Loss: 128.69808
Epoch[46/100], Step [30/391], Reconst Loss: 117.45193, KL Div: 11.46104, Total Loss: 128.91297
Epoch[46/100], Step [40/391], Reconst Loss: 122.66757, KL Div: 11.53709, Total Loss: 134.20466
Epoch[46/100], Step [50/391], Reconst Loss: 119.91237, KL Div: 11.53682, Total Loss: 131.44919
Epoch[46/100], Step [60/391], Reconst Loss: 114.58986, KL Div: 10.96775, Total Loss: 125.55760
Epoch[46/100], Step [70/391], Reconst Loss: 117.82516, KL Div: 11.20152, Total Loss: 129.02667
Epoch[46/100], Step [80/391], Reconst Loss: 114.79114, KL Div: 11.40014, Total Loss: 126.19128
Epoch[46/100], Step [90/391], Reconst Loss: 112.30153, KL Div: 10.97884, Total Loss: 123.28036
Epoch[46/100], Step [100/391], Reconst Loss: 115.47911, KL Div: 11.67883, Total Loss: 127.15794
Epoch[46/100], Step [110/391], Reconst Loss: 118.66690, KL Div: 11.55358, Total Loss: 130.22048
Epoch[46/100], Step [120/391], Reconst Loss: 119.26666, KL Div: 11.72336, Total Loss: 130.99002
Epoch[46/100], Step [130/391], Reconst Loss: 111.92881, KL Div: 11.57323, Total Loss: 123.50204
Epoch[46/100], Step [140/391], Reconst Loss: 115.34090, KL Div: 11.77622, Total Loss: 127.11712
Epoch[46/100], Step [150/391], Reconst Loss: 118.61860, KL Div: 11.39029, Total Loss: 130.00889
Epoch[46/100], Step [160/391], Reconst Loss: 117.40593, KL Div: 11.43633, Total Loss: 128.84226
Epoch[46/100], Step [170/391], Reconst Loss: 121.73132, KL Div: 11.40086, Total Loss: 133.13218
Epoch[46/100], Step [180/391], Reconst Loss: 121.70566, KL Div: 11.11970, Total Loss: 132.82536
Epoch[46/100], Step [190/391], Reconst Loss: 114.89093, KL Div: 11.50766, Total Loss: 126.39859
Epoch[46/100], Step [200/391], Reconst Loss: 112.44804, KL Div: 11.37727, Total Loss: 123.82532
Epoch[46/100], Step [210/391], Reconst Loss: 122.01141, KL Div: 11.14040, Total Loss: 133.15182
Epoch[46/100], Step [220/391], Reconst Loss: 121.52249, KL Div: 11.39979, Total Loss: 132.92228
Epoch[46/100], Step [230/391], Reconst Loss: 117.79294, KL Div: 10.97547, Total Loss: 128.76841
Epoch[46/100], Step [240/391], Reconst Loss: 120.61719, KL Div: 11.40753, Total Loss: 132.02471
Epoch[46/100], Step [250/391], Reconst Loss: 114.16376, KL Div: 11.65566, Total Loss: 125.81941
Epoch[46/100], Step [260/391], Reconst Loss: 114.27763, KL Div: 11.49652, Total Loss: 125.77415
Epoch[46/100], Step [270/391], Reconst Loss: 123.85054, KL Div: 11.71891, Total Loss: 135.56945
Epoch[46/100], Step [280/391], Reconst Loss: 122.85487, KL Div: 11.24381, Total Loss: 134.09867
Epoch[46/100], Step [290/391], Reconst Loss: 112.30269, KL Div: 11.55569, Total Loss: 123.85838
Epoch[46/100], Step [300/391], Reconst Loss: 115.16194, KL Div: 11.20982, Total Loss: 126.37176
Epoch[46/100], Step [310/391], Reconst Loss: 114.25410, KL Div: 11.17552, Total Loss: 125.42962
Epoch[46/100], Step [320/391], Reconst Loss: 114.80910, KL Div: 11.66845, Total Loss: 126.47755
Epoch[46/100], Step [330/391], Reconst Loss: 113.26730, KL Div: 11.17871, Total Loss: 124.44601
Epoch[46/100], Step [340/391], Reconst Loss: 116.70863, KL Div: 11.25064, Total Loss: 127.95928
Epoch[46/100], Step [350/391], Reconst Loss: 120.93298, KL Div: 11.46936, Total Loss: 132.40234
Epoch[46/100], Step [360/391], Reconst Loss: 115.01624, KL Div: 11.23203, Total Loss: 126.24826
Epoch[46/100], Step [370/391], Reconst Loss: 117.57875, KL Div: 10.92465, Total Loss: 128.50340
Epoch[46/100], Step [380/391], Reconst Loss: 117.00780, KL Div: 11.44693, Total Loss: 128.45473
Epoch[46/100], Step [390/391], Reconst Loss: 113.47313, KL Div: 11.57471, Total Loss: 125.04784
Epoch = 46
Training epoch time =  139.29965233802795
train total loss =  126.92574505859375
valid total loss =  128.1390709716797
Total epoch time =  257.48351645469666
Saving checkpoint...
Done!
Epoch[47/100], Step [10/391], Reconst Loss: 116.61919, KL Div: 11.64306, Total Loss: 128.26225
Epoch[47/100], Step [20/391], Reconst Loss: 117.74313, KL Div: 11.84922, Total Loss: 129.59234
Epoch[47/100], Step [30/391], Reconst Loss: 114.23050, KL Div: 11.53229, Total Loss: 125.76279
Epoch[47/100], Step [40/391], Reconst Loss: 115.92327, KL Div: 11.36906, Total Loss: 127.29234
Epoch[47/100], Step [50/391], Reconst Loss: 115.82103, KL Div: 11.21037, Total Loss: 127.03140
Epoch[47/100], Step [60/391], Reconst Loss: 116.45444, KL Div: 11.11326, Total Loss: 127.56770
Epoch[47/100], Step [70/391], Reconst Loss: 128.78131, KL Div: 11.13960, Total Loss: 139.92091
Epoch[47/100], Step [80/391], Reconst Loss: 118.81535, KL Div: 11.88973, Total Loss: 130.70508
Epoch[47/100], Step [90/391], Reconst Loss: 114.53053, KL Div: 11.03329, Total Loss: 125.56381
Epoch[47/100], Step [100/391], Reconst Loss: 114.82732, KL Div: 11.36115, Total Loss: 126.18847
Epoch[47/100], Step [110/391], Reconst Loss: 121.48083, KL Div: 11.26400, Total Loss: 132.74483
Epoch[47/100], Step [120/391], Reconst Loss: 113.20757, KL Div: 11.23568, Total Loss: 124.44325
Epoch[47/100], Step [130/391], Reconst Loss: 111.55022, KL Div: 11.18384, Total Loss: 122.73406
Epoch[47/100], Step [140/391], Reconst Loss: 116.05953, KL Div: 11.23064, Total Loss: 127.29017
Epoch[47/100], Step [150/391], Reconst Loss: 112.33453, KL Div: 10.91238, Total Loss: 123.24691
Epoch[47/100], Step [160/391], Reconst Loss: 118.00263, KL Div: 11.79354, Total Loss: 129.79617
Epoch[47/100], Step [170/391], Reconst Loss: 119.85431, KL Div: 11.30615, Total Loss: 131.16046
Epoch[47/100], Step [180/391], Reconst Loss: 117.01302, KL Div: 11.25028, Total Loss: 128.26330
Epoch[47/100], Step [190/391], Reconst Loss: 121.09279, KL Div: 11.80393, Total Loss: 132.89672
Epoch[47/100], Step [200/391], Reconst Loss: 118.94050, KL Div: 11.61243, Total Loss: 130.55293
Epoch[47/100], Step [210/391], Reconst Loss: 116.26985, KL Div: 11.60414, Total Loss: 127.87399
Epoch[47/100], Step [220/391], Reconst Loss: 117.96880, KL Div: 11.60328, Total Loss: 129.57208
Epoch[47/100], Step [230/391], Reconst Loss: 120.22468, KL Div: 11.58741, Total Loss: 131.81209
Epoch[47/100], Step [240/391], Reconst Loss: 122.09528, KL Div: 11.60913, Total Loss: 133.70442
Epoch[47/100], Step [250/391], Reconst Loss: 118.89777, KL Div: 11.32952, Total Loss: 130.22729
Epoch[47/100], Step [260/391], Reconst Loss: 121.86910, KL Div: 11.26887, Total Loss: 133.13797
Epoch[47/100], Step [270/391], Reconst Loss: 120.83197, KL Div: 11.65022, Total Loss: 132.48219
Epoch[47/100], Step [280/391], Reconst Loss: 120.32434, KL Div: 11.51407, Total Loss: 131.83842
Epoch[47/100], Step [290/391], Reconst Loss: 117.22896, KL Div: 11.16473, Total Loss: 128.39369
Epoch[47/100], Step [300/391], Reconst Loss: 112.69320, KL Div: 10.83450, Total Loss: 123.52770
Epoch[47/100], Step [310/391], Reconst Loss: 115.17593, KL Div: 11.55857, Total Loss: 126.73450
Epoch[47/100], Step [320/391], Reconst Loss: 120.58675, KL Div: 11.30253, Total Loss: 131.88928
Epoch[47/100], Step [330/391], Reconst Loss: 120.97906, KL Div: 11.74731, Total Loss: 132.72637
Epoch[47/100], Step [340/391], Reconst Loss: 114.58279, KL Div: 11.46222, Total Loss: 126.04501
Epoch[47/100], Step [350/391], Reconst Loss: 120.38770, KL Div: 11.53996, Total Loss: 131.92765
Epoch[47/100], Step [360/391], Reconst Loss: 115.60263, KL Div: 11.53123, Total Loss: 127.13387
Epoch[47/100], Step [370/391], Reconst Loss: 118.94115, KL Div: 11.53744, Total Loss: 130.47858
Epoch[47/100], Step [380/391], Reconst Loss: 115.34487, KL Div: 11.48834, Total Loss: 126.83321
Epoch[47/100], Step [390/391], Reconst Loss: 117.95694, KL Div: 11.39338, Total Loss: 129.35032
Epoch = 47
Training epoch time =  139.16353225708008
train total loss =  126.87719736328125
valid total loss =  128.11743846435547
Total epoch time =  257.1205201148987
Saving checkpoint...
Done!
Epoch[48/100], Step [10/391], Reconst Loss: 112.35139, KL Div: 11.13343, Total Loss: 123.48483
Epoch[48/100], Step [20/391], Reconst Loss: 113.84002, KL Div: 11.38202, Total Loss: 125.22204
Epoch[48/100], Step [30/391], Reconst Loss: 114.89996, KL Div: 11.22483, Total Loss: 126.12479
Epoch[48/100], Step [40/391], Reconst Loss: 123.82893, KL Div: 11.37657, Total Loss: 135.20551
Epoch[48/100], Step [50/391], Reconst Loss: 117.30424, KL Div: 11.01930, Total Loss: 128.32353
Epoch[48/100], Step [60/391], Reconst Loss: 111.51756, KL Div: 10.96807, Total Loss: 122.48563
Epoch[48/100], Step [70/391], Reconst Loss: 120.21050, KL Div: 11.38712, Total Loss: 131.59762
Epoch[48/100], Step [80/391], Reconst Loss: 115.79576, KL Div: 11.26046, Total Loss: 127.05622
Epoch[48/100], Step [90/391], Reconst Loss: 110.67589, KL Div: 11.46178, Total Loss: 122.13767
Epoch[48/100], Step [100/391], Reconst Loss: 120.78095, KL Div: 11.38639, Total Loss: 132.16734
Epoch[48/100], Step [110/391], Reconst Loss: 117.11888, KL Div: 10.79993, Total Loss: 127.91881
Epoch[48/100], Step [120/391], Reconst Loss: 118.63976, KL Div: 11.63525, Total Loss: 130.27501
Epoch[48/100], Step [130/391], Reconst Loss: 117.00716, KL Div: 11.53276, Total Loss: 128.53992
Epoch[48/100], Step [140/391], Reconst Loss: 116.17348, KL Div: 11.32903, Total Loss: 127.50251
Epoch[48/100], Step [150/391], Reconst Loss: 116.05050, KL Div: 11.20113, Total Loss: 127.25163
Epoch[48/100], Step [160/391], Reconst Loss: 114.49986, KL Div: 11.29313, Total Loss: 125.79299
Epoch[48/100], Step [170/391], Reconst Loss: 111.46506, KL Div: 11.60238, Total Loss: 123.06743
Epoch[48/100], Step [180/391], Reconst Loss: 111.22557, KL Div: 11.02762, Total Loss: 122.25319
Epoch[48/100], Step [190/391], Reconst Loss: 124.66185, KL Div: 11.65367, Total Loss: 136.31552
Epoch[48/100], Step [200/391], Reconst Loss: 114.27303, KL Div: 11.74399, Total Loss: 126.01701
Epoch[48/100], Step [210/391], Reconst Loss: 119.51579, KL Div: 12.05464, Total Loss: 131.57043
Epoch[48/100], Step [220/391], Reconst Loss: 112.11278, KL Div: 10.93509, Total Loss: 123.04787
Epoch[48/100], Step [230/391], Reconst Loss: 113.37975, KL Div: 11.36203, Total Loss: 124.74177
Epoch[48/100], Step [240/391], Reconst Loss: 116.91736, KL Div: 11.22281, Total Loss: 128.14017
Epoch[48/100], Step [250/391], Reconst Loss: 114.60280, KL Div: 11.36647, Total Loss: 125.96927
Epoch[48/100], Step [260/391], Reconst Loss: 118.08328, KL Div: 11.49752, Total Loss: 129.58080
Epoch[48/100], Step [270/391], Reconst Loss: 114.79298, KL Div: 11.69275, Total Loss: 126.48573
Epoch[48/100], Step [280/391], Reconst Loss: 121.11407, KL Div: 11.17332, Total Loss: 132.28739
Epoch[48/100], Step [290/391], Reconst Loss: 116.27174, KL Div: 11.53336, Total Loss: 127.80510
Epoch[48/100], Step [300/391], Reconst Loss: 106.12692, KL Div: 11.19940, Total Loss: 117.32632
Epoch[48/100], Step [310/391], Reconst Loss: 110.52951, KL Div: 11.44514, Total Loss: 121.97465
Epoch[48/100], Step [320/391], Reconst Loss: 121.37482, KL Div: 11.40382, Total Loss: 132.77863
Epoch[48/100], Step [330/391], Reconst Loss: 120.46838, KL Div: 11.59464, Total Loss: 132.06302
Epoch[48/100], Step [340/391], Reconst Loss: 116.63253, KL Div: 11.11684, Total Loss: 127.74937
Epoch[48/100], Step [350/391], Reconst Loss: 123.92325, KL Div: 11.43842, Total Loss: 135.36166
Epoch[48/100], Step [360/391], Reconst Loss: 118.84843, KL Div: 11.51955, Total Loss: 130.36799
Epoch[48/100], Step [370/391], Reconst Loss: 113.47258, KL Div: 11.29095, Total Loss: 124.76353
Epoch[48/100], Step [380/391], Reconst Loss: 117.72187, KL Div: 11.71881, Total Loss: 129.44068
Epoch[48/100], Step [390/391], Reconst Loss: 118.93652, KL Div: 11.31934, Total Loss: 130.25585
Epoch = 48
Training epoch time =  139.35908675193787
train total loss =  126.74242546875
valid total loss =  127.769623828125
Total epoch time =  257.6339147090912
Saving checkpoint...
Done!
Epoch[49/100], Step [10/391], Reconst Loss: 114.16387, KL Div: 11.79031, Total Loss: 125.95418
Epoch[49/100], Step [20/391], Reconst Loss: 115.56575, KL Div: 11.33358, Total Loss: 126.89933
Epoch[49/100], Step [30/391], Reconst Loss: 115.65072, KL Div: 11.05649, Total Loss: 126.70720
Epoch[49/100], Step [40/391], Reconst Loss: 118.15743, KL Div: 11.53156, Total Loss: 129.68900
Epoch[49/100], Step [50/391], Reconst Loss: 117.78467, KL Div: 11.21929, Total Loss: 129.00395
Epoch[49/100], Step [60/391], Reconst Loss: 112.69949, KL Div: 11.59827, Total Loss: 124.29777
Epoch[49/100], Step [70/391], Reconst Loss: 120.24313, KL Div: 11.43428, Total Loss: 131.67741
Epoch[49/100], Step [80/391], Reconst Loss: 118.02048, KL Div: 11.59766, Total Loss: 129.61814
Epoch[49/100], Step [90/391], Reconst Loss: 117.54414, KL Div: 11.39917, Total Loss: 128.94331
Epoch[49/100], Step [100/391], Reconst Loss: 117.46557, KL Div: 11.11549, Total Loss: 128.58106
Epoch[49/100], Step [110/391], Reconst Loss: 119.49414, KL Div: 11.35129, Total Loss: 130.84543
Epoch[49/100], Step [120/391], Reconst Loss: 110.74376, KL Div: 11.22488, Total Loss: 121.96864
Epoch[49/100], Step [130/391], Reconst Loss: 111.83357, KL Div: 11.47881, Total Loss: 123.31238
Epoch[49/100], Step [140/391], Reconst Loss: 114.88274, KL Div: 11.19175, Total Loss: 126.07448
Epoch[49/100], Step [150/391], Reconst Loss: 119.83527, KL Div: 11.15450, Total Loss: 130.98976
Epoch[49/100], Step [160/391], Reconst Loss: 114.18207, KL Div: 10.93915, Total Loss: 125.12122
Epoch[49/100], Step [170/391], Reconst Loss: 109.86391, KL Div: 11.47913, Total Loss: 121.34305
Epoch[49/100], Step [180/391], Reconst Loss: 112.63406, KL Div: 11.57557, Total Loss: 124.20963
Epoch[49/100], Step [190/391], Reconst Loss: 113.58741, KL Div: 11.45798, Total Loss: 125.04539
Epoch[49/100], Step [200/391], Reconst Loss: 115.67639, KL Div: 11.38201, Total Loss: 127.05840
Epoch[49/100], Step [210/391], Reconst Loss: 113.81056, KL Div: 11.14916, Total Loss: 124.95972
Epoch[49/100], Step [220/391], Reconst Loss: 112.03201, KL Div: 11.24554, Total Loss: 123.27756
Epoch[49/100], Step [230/391], Reconst Loss: 111.70992, KL Div: 11.61543, Total Loss: 123.32535
Epoch[49/100], Step [240/391], Reconst Loss: 119.73009, KL Div: 11.36183, Total Loss: 131.09192
Epoch[49/100], Step [250/391], Reconst Loss: 112.93668, KL Div: 11.13277, Total Loss: 124.06945
Epoch[49/100], Step [260/391], Reconst Loss: 115.98997, KL Div: 11.25702, Total Loss: 127.24699
Epoch[49/100], Step [270/391], Reconst Loss: 116.97208, KL Div: 11.33887, Total Loss: 128.31095
Epoch[49/100], Step [280/391], Reconst Loss: 114.39378, KL Div: 11.23234, Total Loss: 125.62612
Epoch[49/100], Step [290/391], Reconst Loss: 113.05083, KL Div: 11.48486, Total Loss: 124.53569
Epoch[49/100], Step [300/391], Reconst Loss: 124.94585, KL Div: 11.24310, Total Loss: 136.18895
Epoch[49/100], Step [310/391], Reconst Loss: 115.43416, KL Div: 11.37988, Total Loss: 126.81404
Epoch[49/100], Step [320/391], Reconst Loss: 114.54988, KL Div: 11.33933, Total Loss: 125.88922
Epoch[49/100], Step [330/391], Reconst Loss: 117.03935, KL Div: 11.27091, Total Loss: 128.31026
Epoch[49/100], Step [340/391], Reconst Loss: 109.31397, KL Div: 11.22797, Total Loss: 120.54195
Epoch[49/100], Step [350/391], Reconst Loss: 112.25529, KL Div: 10.98067, Total Loss: 123.23596
Epoch[49/100], Step [360/391], Reconst Loss: 121.62255, KL Div: 11.26090, Total Loss: 132.88345
Epoch[49/100], Step [370/391], Reconst Loss: 118.87888, KL Div: 11.56538, Total Loss: 130.44425
Epoch[49/100], Step [380/391], Reconst Loss: 111.25276, KL Div: 11.52129, Total Loss: 122.77406
Epoch[49/100], Step [390/391], Reconst Loss: 118.33827, KL Div: 11.32927, Total Loss: 129.66754
Epoch = 49
Training epoch time =  139.1935911178589
train total loss =  126.85620919921875
valid total loss =  128.17039060058593
Total epoch time =  257.36307764053345
Saving checkpoint...
Done!
Epoch[50/100], Step [10/391], Reconst Loss: 115.90720, KL Div: 11.27003, Total Loss: 127.17722
Epoch[50/100], Step [20/391], Reconst Loss: 119.28917, KL Div: 11.01272, Total Loss: 130.30189
Epoch[50/100], Step [30/391], Reconst Loss: 120.87712, KL Div: 11.37224, Total Loss: 132.24936
Epoch[50/100], Step [40/391], Reconst Loss: 110.94797, KL Div: 10.94245, Total Loss: 121.89042
Epoch[50/100], Step [50/391], Reconst Loss: 111.98632, KL Div: 11.17080, Total Loss: 123.15712
Epoch[50/100], Step [60/391], Reconst Loss: 116.75293, KL Div: 11.27846, Total Loss: 128.03138
Epoch[50/100], Step [70/391], Reconst Loss: 117.13609, KL Div: 11.26176, Total Loss: 128.39786
Epoch[50/100], Step [80/391], Reconst Loss: 119.16234, KL Div: 11.00634, Total Loss: 130.16868
Epoch[50/100], Step [90/391], Reconst Loss: 114.25646, KL Div: 10.91445, Total Loss: 125.17091
Epoch[50/100], Step [100/391], Reconst Loss: 111.99767, KL Div: 11.05750, Total Loss: 123.05516
Epoch[50/100], Step [110/391], Reconst Loss: 116.71741, KL Div: 11.14709, Total Loss: 127.86449
Epoch[50/100], Step [120/391], Reconst Loss: 116.04079, KL Div: 11.38156, Total Loss: 127.42236
Epoch[50/100], Step [130/391], Reconst Loss: 112.58916, KL Div: 11.07675, Total Loss: 123.66591
Epoch[50/100], Step [140/391], Reconst Loss: 117.52620, KL Div: 11.31697, Total Loss: 128.84317
Epoch[50/100], Step [150/391], Reconst Loss: 120.94458, KL Div: 10.95861, Total Loss: 131.90319
Epoch[50/100], Step [160/391], Reconst Loss: 118.57999, KL Div: 11.01993, Total Loss: 129.59993
Epoch[50/100], Step [170/391], Reconst Loss: 119.22705, KL Div: 11.58572, Total Loss: 130.81277
Epoch[50/100], Step [180/391], Reconst Loss: 116.69678, KL Div: 11.05699, Total Loss: 127.75378
Epoch[50/100], Step [190/391], Reconst Loss: 121.34743, KL Div: 11.45013, Total Loss: 132.79755
Epoch[50/100], Step [200/391], Reconst Loss: 115.94649, KL Div: 11.51036, Total Loss: 127.45685
Epoch[50/100], Step [210/391], Reconst Loss: 120.20484, KL Div: 11.22645, Total Loss: 131.43130
Epoch[50/100], Step [220/391], Reconst Loss: 117.54385, KL Div: 11.50024, Total Loss: 129.04408
Epoch[50/100], Step [230/391], Reconst Loss: 113.74874, KL Div: 11.57529, Total Loss: 125.32403
Epoch[50/100], Step [240/391], Reconst Loss: 117.95062, KL Div: 11.30683, Total Loss: 129.25745
Epoch[50/100], Step [250/391], Reconst Loss: 114.80092, KL Div: 11.25021, Total Loss: 126.05113
Epoch[50/100], Step [260/391], Reconst Loss: 114.75880, KL Div: 11.09108, Total Loss: 125.84988
Epoch[50/100], Step [270/391], Reconst Loss: 111.70805, KL Div: 11.25917, Total Loss: 122.96722
Epoch[50/100], Step [280/391], Reconst Loss: 118.85748, KL Div: 11.19489, Total Loss: 130.05236
Epoch[50/100], Step [290/391], Reconst Loss: 112.06163, KL Div: 11.00207, Total Loss: 123.06370
Epoch[50/100], Step [300/391], Reconst Loss: 117.19557, KL Div: 11.02259, Total Loss: 128.21816
Epoch[50/100], Step [310/391], Reconst Loss: 116.34959, KL Div: 11.05343, Total Loss: 127.40303
Epoch[50/100], Step [320/391], Reconst Loss: 120.80205, KL Div: 11.26709, Total Loss: 132.06914
Epoch[50/100], Step [330/391], Reconst Loss: 121.36852, KL Div: 11.02559, Total Loss: 132.39411
Epoch[50/100], Step [340/391], Reconst Loss: 119.67767, KL Div: 11.54023, Total Loss: 131.21790
Epoch[50/100], Step [350/391], Reconst Loss: 114.68971, KL Div: 11.24608, Total Loss: 125.93580
Epoch[50/100], Step [360/391], Reconst Loss: 116.56210, KL Div: 11.33259, Total Loss: 127.89469
Epoch[50/100], Step [370/391], Reconst Loss: 114.69070, KL Div: 11.29735, Total Loss: 125.98805
Epoch[50/100], Step [380/391], Reconst Loss: 119.72973, KL Div: 11.69902, Total Loss: 131.42875
Epoch[50/100], Step [390/391], Reconst Loss: 114.63627, KL Div: 11.09813, Total Loss: 125.73440
Epoch = 50
Training epoch time =  139.4556336402893
train total loss =  126.88917958984375
valid total loss =  128.08939660644532
Total epoch time =  257.46287775039673
Saving checkpoint...
Done!
Epoch[51/100], Step [10/391], Reconst Loss: 119.59821, KL Div: 11.60226, Total Loss: 131.20047
Epoch[51/100], Step [20/391], Reconst Loss: 118.78384, KL Div: 11.40027, Total Loss: 130.18412
Epoch[51/100], Step [30/391], Reconst Loss: 116.15961, KL Div: 11.46047, Total Loss: 127.62008
Epoch[51/100], Step [40/391], Reconst Loss: 113.47104, KL Div: 11.19682, Total Loss: 124.66786
Epoch[51/100], Step [50/391], Reconst Loss: 118.99600, KL Div: 11.32211, Total Loss: 130.31812
Epoch[51/100], Step [60/391], Reconst Loss: 122.74532, KL Div: 11.66239, Total Loss: 134.40770
Epoch[51/100], Step [70/391], Reconst Loss: 119.03469, KL Div: 11.22093, Total Loss: 130.25562
Epoch[51/100], Step [80/391], Reconst Loss: 117.31602, KL Div: 11.30524, Total Loss: 128.62127
Epoch[51/100], Step [90/391], Reconst Loss: 117.10506, KL Div: 11.20763, Total Loss: 128.31269
Epoch[51/100], Step [100/391], Reconst Loss: 115.72707, KL Div: 11.22556, Total Loss: 126.95262
Epoch[51/100], Step [110/391], Reconst Loss: 119.22865, KL Div: 11.21311, Total Loss: 130.44176
Epoch[51/100], Step [120/391], Reconst Loss: 114.93402, KL Div: 11.37393, Total Loss: 126.30795
Epoch[51/100], Step [130/391], Reconst Loss: 115.97271, KL Div: 11.74874, Total Loss: 127.72145
Epoch[51/100], Step [140/391], Reconst Loss: 111.80104, KL Div: 11.53000, Total Loss: 123.33104
Epoch[51/100], Step [150/391], Reconst Loss: 116.66354, KL Div: 11.38263, Total Loss: 128.04618
Epoch[51/100], Step [160/391], Reconst Loss: 122.98965, KL Div: 11.17977, Total Loss: 134.16942
Epoch[51/100], Step [170/391], Reconst Loss: 115.21615, KL Div: 11.12425, Total Loss: 126.34040
Epoch[51/100], Step [180/391], Reconst Loss: 115.53779, KL Div: 11.16612, Total Loss: 126.70391
Epoch[51/100], Step [190/391], Reconst Loss: 120.26025, KL Div: 11.45730, Total Loss: 131.71756
Epoch[51/100], Step [200/391], Reconst Loss: 118.50674, KL Div: 11.07984, Total Loss: 129.58658
Epoch[51/100], Step [210/391], Reconst Loss: 117.22511, KL Div: 11.40057, Total Loss: 128.62567
Epoch[51/100], Step [220/391], Reconst Loss: 118.12501, KL Div: 11.66532, Total Loss: 129.79033
Epoch[51/100], Step [230/391], Reconst Loss: 116.71384, KL Div: 11.12983, Total Loss: 127.84367
Epoch[51/100], Step [240/391], Reconst Loss: 117.47906, KL Div: 11.19846, Total Loss: 128.67752
Epoch[51/100], Step [250/391], Reconst Loss: 115.75509, KL Div: 11.52746, Total Loss: 127.28255
Epoch[51/100], Step [260/391], Reconst Loss: 117.35762, KL Div: 11.35342, Total Loss: 128.71104
Epoch[51/100], Step [270/391], Reconst Loss: 115.89670, KL Div: 11.21788, Total Loss: 127.11458
Epoch[51/100], Step [280/391], Reconst Loss: 113.43369, KL Div: 11.73072, Total Loss: 125.16441
Epoch[51/100], Step [290/391], Reconst Loss: 120.41047, KL Div: 11.34309, Total Loss: 131.75356
Epoch[51/100], Step [300/391], Reconst Loss: 115.07993, KL Div: 11.31203, Total Loss: 126.39195
Epoch[51/100], Step [310/391], Reconst Loss: 120.44460, KL Div: 11.45223, Total Loss: 131.89683
Epoch[51/100], Step [320/391], Reconst Loss: 115.51607, KL Div: 11.37657, Total Loss: 126.89263
Epoch[51/100], Step [330/391], Reconst Loss: 121.03832, KL Div: 11.38310, Total Loss: 132.42142
Epoch[51/100], Step [340/391], Reconst Loss: 113.87639, KL Div: 11.36679, Total Loss: 125.24317
Epoch[51/100], Step [350/391], Reconst Loss: 120.15831, KL Div: 11.45616, Total Loss: 131.61447
Epoch[51/100], Step [360/391], Reconst Loss: 112.59281, KL Div: 11.49856, Total Loss: 124.09138
Epoch[51/100], Step [370/391], Reconst Loss: 116.46921, KL Div: 11.56891, Total Loss: 128.03811
Epoch[51/100], Step [380/391], Reconst Loss: 117.13592, KL Div: 11.53167, Total Loss: 128.66759
Epoch[51/100], Step [390/391], Reconst Loss: 123.99058, KL Div: 11.21695, Total Loss: 135.20753
Epoch = 51
Training epoch time =  139.12682223320007
train total loss =  126.7280989453125
valid total loss =  127.93102736816407
Total epoch time =  257.1233928203583
Saving checkpoint...
Done!
Epoch[52/100], Step [10/391], Reconst Loss: 113.37013, KL Div: 11.14339, Total Loss: 124.51352
Epoch[52/100], Step [20/391], Reconst Loss: 116.22990, KL Div: 10.88074, Total Loss: 127.11064
Epoch[52/100], Step [30/391], Reconst Loss: 114.66643, KL Div: 11.17565, Total Loss: 125.84208
Epoch[52/100], Step [40/391], Reconst Loss: 120.56488, KL Div: 11.78660, Total Loss: 132.35148
Epoch[52/100], Step [50/391], Reconst Loss: 117.37434, KL Div: 11.19246, Total Loss: 128.56681
Epoch[52/100], Step [60/391], Reconst Loss: 118.23003, KL Div: 11.40895, Total Loss: 129.63898
Epoch[52/100], Step [70/391], Reconst Loss: 112.50626, KL Div: 11.34020, Total Loss: 123.84645
Epoch[52/100], Step [80/391], Reconst Loss: 111.61841, KL Div: 11.69430, Total Loss: 123.31270
Epoch[52/100], Step [90/391], Reconst Loss: 115.64954, KL Div: 11.51547, Total Loss: 127.16501
Epoch[52/100], Step [100/391], Reconst Loss: 118.57207, KL Div: 11.48764, Total Loss: 130.05971
Epoch[52/100], Step [110/391], Reconst Loss: 110.50443, KL Div: 11.59993, Total Loss: 122.10435
Epoch[52/100], Step [120/391], Reconst Loss: 118.39275, KL Div: 11.67846, Total Loss: 130.07122
Epoch[52/100], Step [130/391], Reconst Loss: 117.31398, KL Div: 11.31839, Total Loss: 128.63237
Epoch[52/100], Step [140/391], Reconst Loss: 115.72884, KL Div: 11.72947, Total Loss: 127.45830
Epoch[52/100], Step [150/391], Reconst Loss: 113.46309, KL Div: 11.97802, Total Loss: 125.44111
Epoch[52/100], Step [160/391], Reconst Loss: 107.38322, KL Div: 11.21418, Total Loss: 118.59740
Epoch[52/100], Step [170/391], Reconst Loss: 114.65805, KL Div: 11.35020, Total Loss: 126.00825
Epoch[52/100], Step [180/391], Reconst Loss: 117.00060, KL Div: 11.64277, Total Loss: 128.64336
Epoch[52/100], Step [190/391], Reconst Loss: 118.01688, KL Div: 10.83487, Total Loss: 128.85175
Epoch[52/100], Step [200/391], Reconst Loss: 114.37193, KL Div: 11.73394, Total Loss: 126.10587
Epoch[52/100], Step [210/391], Reconst Loss: 114.63780, KL Div: 11.46296, Total Loss: 126.10076
Epoch[52/100], Step [220/391], Reconst Loss: 121.58338, KL Div: 11.35715, Total Loss: 132.94054
Epoch[52/100], Step [230/391], Reconst Loss: 118.36137, KL Div: 11.43485, Total Loss: 129.79623
Epoch[52/100], Step [240/391], Reconst Loss: 115.07393, KL Div: 11.65276, Total Loss: 126.72668
Epoch[52/100], Step [250/391], Reconst Loss: 120.24075, KL Div: 11.01401, Total Loss: 131.25476
Epoch[52/100], Step [260/391], Reconst Loss: 116.44046, KL Div: 11.50298, Total Loss: 127.94344
Epoch[52/100], Step [270/391], Reconst Loss: 116.76093, KL Div: 11.62126, Total Loss: 128.38219
Epoch[52/100], Step [280/391], Reconst Loss: 111.94631, KL Div: 11.81281, Total Loss: 123.75913
Epoch[52/100], Step [290/391], Reconst Loss: 118.43394, KL Div: 11.46094, Total Loss: 129.89488
Epoch[52/100], Step [300/391], Reconst Loss: 117.42236, KL Div: 11.78824, Total Loss: 129.21060
Epoch[52/100], Step [310/391], Reconst Loss: 115.55534, KL Div: 11.15923, Total Loss: 126.71458
Epoch[52/100], Step [320/391], Reconst Loss: 116.43224, KL Div: 11.37265, Total Loss: 127.80488
Epoch[52/100], Step [330/391], Reconst Loss: 113.77829, KL Div: 11.75916, Total Loss: 125.53745
Epoch[52/100], Step [340/391], Reconst Loss: 113.19994, KL Div: 11.59299, Total Loss: 124.79294
Epoch[52/100], Step [350/391], Reconst Loss: 113.30583, KL Div: 11.16437, Total Loss: 124.47020
Epoch[52/100], Step [360/391], Reconst Loss: 115.10692, KL Div: 12.02790, Total Loss: 127.13482
Epoch[52/100], Step [370/391], Reconst Loss: 114.52884, KL Div: 11.21242, Total Loss: 125.74126
Epoch[52/100], Step [380/391], Reconst Loss: 114.50500, KL Div: 11.17904, Total Loss: 125.68404
Epoch[52/100], Step [390/391], Reconst Loss: 117.21635, KL Div: 11.73698, Total Loss: 128.95333
Epoch = 52
Training epoch time =  139.15508890151978
train total loss =  126.90325810546875
valid total loss =  128.04050217285157
Total epoch time =  257.15761494636536
Saving checkpoint...
Done!
Epoch[53/100], Step [10/391], Reconst Loss: 116.87185, KL Div: 11.71177, Total Loss: 128.58362
Epoch[53/100], Step [20/391], Reconst Loss: 112.23219, KL Div: 11.46127, Total Loss: 123.69346
Epoch[53/100], Step [30/391], Reconst Loss: 111.68700, KL Div: 11.54672, Total Loss: 123.23371
Epoch[53/100], Step [40/391], Reconst Loss: 110.29633, KL Div: 11.49398, Total Loss: 121.79031
Epoch[53/100], Step [50/391], Reconst Loss: 119.58995, KL Div: 11.78779, Total Loss: 131.37775
Epoch[53/100], Step [60/391], Reconst Loss: 111.90575, KL Div: 11.36162, Total Loss: 123.26738
Epoch[53/100], Step [70/391], Reconst Loss: 124.66828, KL Div: 11.77633, Total Loss: 136.44461
Epoch[53/100], Step [80/391], Reconst Loss: 117.99002, KL Div: 11.20986, Total Loss: 129.19988
Epoch[53/100], Step [90/391], Reconst Loss: 119.30926, KL Div: 11.30095, Total Loss: 130.61020
Epoch[53/100], Step [100/391], Reconst Loss: 114.48266, KL Div: 11.25480, Total Loss: 125.73746
Epoch[53/100], Step [110/391], Reconst Loss: 110.81225, KL Div: 11.51531, Total Loss: 122.32756
Epoch[53/100], Step [120/391], Reconst Loss: 112.51144, KL Div: 11.34976, Total Loss: 123.86120
Epoch[53/100], Step [130/391], Reconst Loss: 118.66285, KL Div: 11.64657, Total Loss: 130.30942
Epoch[53/100], Step [140/391], Reconst Loss: 119.61819, KL Div: 11.53588, Total Loss: 131.15407
Epoch[53/100], Step [150/391], Reconst Loss: 123.86649, KL Div: 11.13700, Total Loss: 135.00349
Epoch[53/100], Step [160/391], Reconst Loss: 115.36175, KL Div: 11.47133, Total Loss: 126.83308
Epoch[53/100], Step [170/391], Reconst Loss: 108.45466, KL Div: 11.28052, Total Loss: 119.73518
Epoch[53/100], Step [180/391], Reconst Loss: 110.75478, KL Div: 11.18242, Total Loss: 121.93720
Epoch[53/100], Step [190/391], Reconst Loss: 115.55054, KL Div: 11.47453, Total Loss: 127.02507
Epoch[53/100], Step [200/391], Reconst Loss: 118.70502, KL Div: 11.22334, Total Loss: 129.92835
Epoch[53/100], Step [210/391], Reconst Loss: 117.49394, KL Div: 11.25811, Total Loss: 128.75205
Epoch[53/100], Step [220/391], Reconst Loss: 115.59406, KL Div: 11.67857, Total Loss: 127.27263
Epoch[53/100], Step [230/391], Reconst Loss: 116.81380, KL Div: 12.13875, Total Loss: 128.95254
Epoch[53/100], Step [240/391], Reconst Loss: 116.34523, KL Div: 11.33238, Total Loss: 127.67761
Epoch[53/100], Step [250/391], Reconst Loss: 119.26202, KL Div: 11.45102, Total Loss: 130.71304
Epoch[53/100], Step [260/391], Reconst Loss: 114.42806, KL Div: 11.01136, Total Loss: 125.43943
Epoch[53/100], Step [270/391], Reconst Loss: 115.44174, KL Div: 11.06191, Total Loss: 126.50365
Epoch[53/100], Step [280/391], Reconst Loss: 113.98251, KL Div: 11.44833, Total Loss: 125.43085
Epoch[53/100], Step [290/391], Reconst Loss: 108.31752, KL Div: 11.53157, Total Loss: 119.84909
Epoch[53/100], Step [300/391], Reconst Loss: 117.18562, KL Div: 11.69112, Total Loss: 128.87675
Epoch[53/100], Step [310/391], Reconst Loss: 116.23489, KL Div: 11.59902, Total Loss: 127.83392
Epoch[53/100], Step [320/391], Reconst Loss: 110.18864, KL Div: 11.64590, Total Loss: 121.83453
Epoch[53/100], Step [330/391], Reconst Loss: 111.39630, KL Div: 11.69026, Total Loss: 123.08657
Epoch[53/100], Step [340/391], Reconst Loss: 109.86849, KL Div: 11.25787, Total Loss: 121.12636
Epoch[53/100], Step [350/391], Reconst Loss: 116.73048, KL Div: 11.51343, Total Loss: 128.24391
Epoch[53/100], Step [360/391], Reconst Loss: 117.64132, KL Div: 11.50695, Total Loss: 129.14827
Epoch[53/100], Step [370/391], Reconst Loss: 108.99224, KL Div: 11.40151, Total Loss: 120.39375
Epoch[53/100], Step [380/391], Reconst Loss: 120.40856, KL Div: 11.48701, Total Loss: 131.89557
Epoch[53/100], Step [390/391], Reconst Loss: 118.33828, KL Div: 11.59747, Total Loss: 129.93575
Epoch = 53
Training epoch time =  139.2954294681549
train total loss =  127.31293267578125
valid total loss =  128.5146162109375
Total epoch time =  257.64575242996216
Saving checkpoint...
Done!
Epoch[54/100], Step [10/391], Reconst Loss: 112.26328, KL Div: 11.57402, Total Loss: 123.83729
Epoch[54/100], Step [20/391], Reconst Loss: 122.84894, KL Div: 11.54247, Total Loss: 134.39141
Epoch[54/100], Step [30/391], Reconst Loss: 119.56875, KL Div: 11.38106, Total Loss: 130.94981
Epoch[54/100], Step [40/391], Reconst Loss: 117.56672, KL Div: 11.70455, Total Loss: 129.27127
Epoch[54/100], Step [50/391], Reconst Loss: 120.59932, KL Div: 12.06059, Total Loss: 132.65991
Epoch[54/100], Step [60/391], Reconst Loss: 123.11995, KL Div: 11.63760, Total Loss: 134.75755
Epoch[54/100], Step [70/391], Reconst Loss: 121.98862, KL Div: 11.46770, Total Loss: 133.45632
Epoch[54/100], Step [80/391], Reconst Loss: 119.57363, KL Div: 11.24754, Total Loss: 130.82117
Epoch[54/100], Step [90/391], Reconst Loss: 120.80000, KL Div: 11.69466, Total Loss: 132.49466
Epoch[54/100], Step [100/391], Reconst Loss: 120.72670, KL Div: 11.16790, Total Loss: 131.89460
Epoch[54/100], Step [110/391], Reconst Loss: 116.09012, KL Div: 11.73471, Total Loss: 127.82483
Epoch[54/100], Step [120/391], Reconst Loss: 118.79498, KL Div: 11.29153, Total Loss: 130.08652
Epoch[54/100], Step [130/391], Reconst Loss: 113.99347, KL Div: 11.41077, Total Loss: 125.40424
Epoch[54/100], Step [140/391], Reconst Loss: 115.90451, KL Div: 11.26453, Total Loss: 127.16904
Epoch[54/100], Step [150/391], Reconst Loss: 119.28986, KL Div: 11.36919, Total Loss: 130.65906
Epoch[54/100], Step [160/391], Reconst Loss: 119.60596, KL Div: 11.52780, Total Loss: 131.13377
Epoch[54/100], Step [170/391], Reconst Loss: 119.37623, KL Div: 11.27463, Total Loss: 130.65086
Epoch[54/100], Step [180/391], Reconst Loss: 116.15567, KL Div: 11.49350, Total Loss: 127.64917
Epoch[54/100], Step [190/391], Reconst Loss: 114.60262, KL Div: 11.14783, Total Loss: 125.75045
Epoch[54/100], Step [200/391], Reconst Loss: 106.57784, KL Div: 11.28788, Total Loss: 117.86573
Epoch[54/100], Step [210/391], Reconst Loss: 115.42448, KL Div: 11.31860, Total Loss: 126.74308
Epoch[54/100], Step [220/391], Reconst Loss: 123.56319, KL Div: 11.34946, Total Loss: 134.91264
Epoch[54/100], Step [230/391], Reconst Loss: 119.82963, KL Div: 11.48844, Total Loss: 131.31807
Epoch[54/100], Step [240/391], Reconst Loss: 116.77714, KL Div: 11.52958, Total Loss: 128.30672
Epoch[54/100], Step [250/391], Reconst Loss: 113.89869, KL Div: 11.54844, Total Loss: 125.44712
Epoch[54/100], Step [260/391], Reconst Loss: 113.08103, KL Div: 11.88330, Total Loss: 124.96433
Epoch[54/100], Step [270/391], Reconst Loss: 116.49485, KL Div: 11.63314, Total Loss: 128.12799
Epoch[54/100], Step [280/391], Reconst Loss: 118.14503, KL Div: 11.39012, Total Loss: 129.53515
Epoch[54/100], Step [290/391], Reconst Loss: 122.10789, KL Div: 11.84367, Total Loss: 133.95156
Epoch[54/100], Step [300/391], Reconst Loss: 111.70886, KL Div: 11.35271, Total Loss: 123.06157
Epoch[54/100], Step [310/391], Reconst Loss: 115.56541, KL Div: 11.40067, Total Loss: 126.96609
Epoch[54/100], Step [320/391], Reconst Loss: 118.15414, KL Div: 11.63506, Total Loss: 129.78921
Epoch[54/100], Step [330/391], Reconst Loss: 115.52460, KL Div: 11.54207, Total Loss: 127.06667
Epoch[54/100], Step [340/391], Reconst Loss: 112.44410, KL Div: 10.80036, Total Loss: 123.24446
Epoch[54/100], Step [350/391], Reconst Loss: 114.85471, KL Div: 11.18553, Total Loss: 126.04024
Epoch[54/100], Step [360/391], Reconst Loss: 113.97097, KL Div: 11.65886, Total Loss: 125.62983
Epoch[54/100], Step [370/391], Reconst Loss: 121.66640, KL Div: 11.51931, Total Loss: 133.18571
Epoch[54/100], Step [380/391], Reconst Loss: 118.01518, KL Div: 11.34996, Total Loss: 129.36514
Epoch[54/100], Step [390/391], Reconst Loss: 121.46373, KL Div: 11.44405, Total Loss: 132.90778
Epoch = 54
Training epoch time =  139.2017834186554
train total loss =  127.26678255859375
valid total loss =  128.29609747314453
Total epoch time =  257.3260681629181
Saving checkpoint...
Done!
Epoch[55/100], Step [10/391], Reconst Loss: 119.75309, KL Div: 11.62760, Total Loss: 131.38069
Epoch[55/100], Step [20/391], Reconst Loss: 116.18011, KL Div: 11.69265, Total Loss: 127.87276
Epoch[55/100], Step [30/391], Reconst Loss: 125.11814, KL Div: 11.49840, Total Loss: 136.61654
Epoch[55/100], Step [40/391], Reconst Loss: 112.12413, KL Div: 11.48984, Total Loss: 123.61397
Epoch[55/100], Step [50/391], Reconst Loss: 120.26969, KL Div: 11.34489, Total Loss: 131.61458
Epoch[55/100], Step [60/391], Reconst Loss: 119.98306, KL Div: 11.26034, Total Loss: 131.24341
Epoch[55/100], Step [70/391], Reconst Loss: 110.96777, KL Div: 11.57730, Total Loss: 122.54507
Epoch[55/100], Step [80/391], Reconst Loss: 114.12418, KL Div: 11.34678, Total Loss: 125.47096
Epoch[55/100], Step [90/391], Reconst Loss: 111.47342, KL Div: 11.45026, Total Loss: 122.92368
Epoch[55/100], Step [100/391], Reconst Loss: 116.71756, KL Div: 11.46433, Total Loss: 128.18189
Epoch[55/100], Step [110/391], Reconst Loss: 113.85378, KL Div: 11.36519, Total Loss: 125.21896
Epoch[55/100], Step [120/391], Reconst Loss: 117.06418, KL Div: 11.25190, Total Loss: 128.31608
Epoch[55/100], Step [130/391], Reconst Loss: 113.26624, KL Div: 11.32923, Total Loss: 124.59547
Epoch[55/100], Step [140/391], Reconst Loss: 119.14883, KL Div: 11.18678, Total Loss: 130.33560
Epoch[55/100], Step [150/391], Reconst Loss: 114.26270, KL Div: 11.21307, Total Loss: 125.47576
Epoch[55/100], Step [160/391], Reconst Loss: 110.91656, KL Div: 11.68076, Total Loss: 122.59732
Epoch[55/100], Step [170/391], Reconst Loss: 116.03282, KL Div: 11.40213, Total Loss: 127.43495
Epoch[55/100], Step [180/391], Reconst Loss: 122.23737, KL Div: 11.33710, Total Loss: 133.57447
Epoch[55/100], Step [190/391], Reconst Loss: 116.00146, KL Div: 11.62821, Total Loss: 127.62967
Epoch[55/100], Step [200/391], Reconst Loss: 118.72258, KL Div: 11.24187, Total Loss: 129.96445
Epoch[55/100], Step [210/391], Reconst Loss: 119.30850, KL Div: 11.45043, Total Loss: 130.75893
Epoch[55/100], Step [220/391], Reconst Loss: 117.76498, KL Div: 11.36265, Total Loss: 129.12763
Epoch[55/100], Step [230/391], Reconst Loss: 111.48753, KL Div: 11.56477, Total Loss: 123.05231
Epoch[55/100], Step [240/391], Reconst Loss: 113.04478, KL Div: 11.18156, Total Loss: 124.22634
Epoch[55/100], Step [250/391], Reconst Loss: 120.48872, KL Div: 11.33383, Total Loss: 131.82256
Epoch[55/100], Step [260/391], Reconst Loss: 117.90501, KL Div: 11.98467, Total Loss: 129.88969
Epoch[55/100], Step [270/391], Reconst Loss: 119.99043, KL Div: 11.54448, Total Loss: 131.53491
Epoch[55/100], Step [280/391], Reconst Loss: 116.22211, KL Div: 11.67715, Total Loss: 127.89925
Epoch[55/100], Step [290/391], Reconst Loss: 110.87598, KL Div: 12.01869, Total Loss: 122.89467
Epoch[55/100], Step [300/391], Reconst Loss: 117.21372, KL Div: 11.39059, Total Loss: 128.60432
Epoch[55/100], Step [310/391], Reconst Loss: 119.50919, KL Div: 11.52864, Total Loss: 131.03784
Epoch[55/100], Step [320/391], Reconst Loss: 115.67673, KL Div: 11.56820, Total Loss: 127.24493
Epoch[55/100], Step [330/391], Reconst Loss: 118.98396, KL Div: 12.01154, Total Loss: 130.99550
Epoch[55/100], Step [340/391], Reconst Loss: 112.16144, KL Div: 11.33932, Total Loss: 123.50076
Epoch[55/100], Step [350/391], Reconst Loss: 119.31037, KL Div: 11.78006, Total Loss: 131.09044
Epoch[55/100], Step [360/391], Reconst Loss: 118.70097, KL Div: 11.64836, Total Loss: 130.34933
Epoch[55/100], Step [370/391], Reconst Loss: 118.67905, KL Div: 11.46719, Total Loss: 130.14624
Epoch[55/100], Step [380/391], Reconst Loss: 116.84658, KL Div: 11.47601, Total Loss: 128.32259
Epoch[55/100], Step [390/391], Reconst Loss: 118.43303, KL Div: 11.09147, Total Loss: 129.52450
Epoch = 55
Training epoch time =  138.98076486587524
train total loss =  127.30415501953125
valid total loss =  128.5002602416992
Total epoch time =  257.43743562698364
Saving checkpoint...
Done!
Epoch[56/100], Step [10/391], Reconst Loss: 118.40469, KL Div: 11.20875, Total Loss: 129.61344
Epoch[56/100], Step [20/391], Reconst Loss: 111.40479, KL Div: 11.50470, Total Loss: 122.90948
Epoch[56/100], Step [30/391], Reconst Loss: 116.32298, KL Div: 11.50548, Total Loss: 127.82846
Epoch[56/100], Step [40/391], Reconst Loss: 117.69768, KL Div: 11.65226, Total Loss: 129.34994
Epoch[56/100], Step [50/391], Reconst Loss: 114.81792, KL Div: 11.26572, Total Loss: 126.08364
Epoch[56/100], Step [60/391], Reconst Loss: 120.41615, KL Div: 11.77554, Total Loss: 132.19170
Epoch[56/100], Step [70/391], Reconst Loss: 115.99387, KL Div: 11.67636, Total Loss: 127.67023
Epoch[56/100], Step [80/391], Reconst Loss: 112.64363, KL Div: 11.57702, Total Loss: 124.22065
Epoch[56/100], Step [90/391], Reconst Loss: 116.06898, KL Div: 11.32570, Total Loss: 127.39468
Epoch[56/100], Step [100/391], Reconst Loss: 109.73080, KL Div: 11.50736, Total Loss: 121.23816
Epoch[56/100], Step [110/391], Reconst Loss: 113.90009, KL Div: 11.23026, Total Loss: 125.13036
Epoch[56/100], Step [120/391], Reconst Loss: 114.51060, KL Div: 11.39111, Total Loss: 125.90171
Epoch[56/100], Step [130/391], Reconst Loss: 115.99970, KL Div: 11.44938, Total Loss: 127.44908
Epoch[56/100], Step [140/391], Reconst Loss: 113.96866, KL Div: 11.33125, Total Loss: 125.29991
Epoch[56/100], Step [150/391], Reconst Loss: 121.70181, KL Div: 11.58972, Total Loss: 133.29153
Epoch[56/100], Step [160/391], Reconst Loss: 114.23445, KL Div: 11.64498, Total Loss: 125.87943
Epoch[56/100], Step [170/391], Reconst Loss: 114.64361, KL Div: 11.70275, Total Loss: 126.34636
Epoch[56/100], Step [180/391], Reconst Loss: 114.04572, KL Div: 11.35418, Total Loss: 125.39990
Epoch[56/100], Step [190/391], Reconst Loss: 116.51200, KL Div: 11.31799, Total Loss: 127.83000
Epoch[56/100], Step [200/391], Reconst Loss: 117.00299, KL Div: 11.58777, Total Loss: 128.59076
Epoch[56/100], Step [210/391], Reconst Loss: 113.76867, KL Div: 11.91575, Total Loss: 125.68442
Epoch[56/100], Step [220/391], Reconst Loss: 117.86125, KL Div: 11.66096, Total Loss: 129.52221
Epoch[56/100], Step [230/391], Reconst Loss: 110.15639, KL Div: 11.47163, Total Loss: 121.62802
Epoch[56/100], Step [240/391], Reconst Loss: 117.07514, KL Div: 11.84173, Total Loss: 128.91687
Epoch[56/100], Step [250/391], Reconst Loss: 116.63657, KL Div: 10.99795, Total Loss: 127.63451
Epoch[56/100], Step [260/391], Reconst Loss: 113.14848, KL Div: 11.27432, Total Loss: 124.42280
Epoch[56/100], Step [270/391], Reconst Loss: 113.94162, KL Div: 11.31476, Total Loss: 125.25638
Epoch[56/100], Step [280/391], Reconst Loss: 111.72456, KL Div: 11.21652, Total Loss: 122.94108
Epoch[56/100], Step [290/391], Reconst Loss: 118.84574, KL Div: 11.61158, Total Loss: 130.45732
Epoch[56/100], Step [300/391], Reconst Loss: 121.63281, KL Div: 11.56810, Total Loss: 133.20091
Epoch[56/100], Step [310/391], Reconst Loss: 119.73374, KL Div: 11.18904, Total Loss: 130.92278
Epoch[56/100], Step [320/391], Reconst Loss: 113.04434, KL Div: 11.52394, Total Loss: 124.56828
Epoch[56/100], Step [330/391], Reconst Loss: 115.34031, KL Div: 11.88617, Total Loss: 127.22648
Epoch[56/100], Step [340/391], Reconst Loss: 118.48781, KL Div: 11.64466, Total Loss: 130.13247
Epoch[56/100], Step [350/391], Reconst Loss: 120.62514, KL Div: 11.47835, Total Loss: 132.10349
Epoch[56/100], Step [360/391], Reconst Loss: 114.00259, KL Div: 11.43904, Total Loss: 125.44163
Epoch[56/100], Step [370/391], Reconst Loss: 120.30999, KL Div: 11.15461, Total Loss: 131.46460
Epoch[56/100], Step [380/391], Reconst Loss: 119.50735, KL Div: 11.41830, Total Loss: 130.92564
Epoch[56/100], Step [390/391], Reconst Loss: 119.94946, KL Div: 11.38294, Total Loss: 131.33240
Epoch = 56
Training epoch time =  139.16948533058167
train total loss =  126.90790494140624
valid total loss =  128.11199505615235
Total epoch time =  257.52804732322693
Saving checkpoint...
Done!
Epoch[57/100], Step [10/391], Reconst Loss: 114.62501, KL Div: 11.79651, Total Loss: 126.42151
Epoch[57/100], Step [20/391], Reconst Loss: 115.99892, KL Div: 11.46766, Total Loss: 127.46659
Epoch[57/100], Step [30/391], Reconst Loss: 111.97366, KL Div: 11.28748, Total Loss: 123.26114
Epoch[57/100], Step [40/391], Reconst Loss: 115.73908, KL Div: 11.33974, Total Loss: 127.07882
Epoch[57/100], Step [50/391], Reconst Loss: 115.59836, KL Div: 11.56024, Total Loss: 127.15860
Epoch[57/100], Step [60/391], Reconst Loss: 117.43890, KL Div: 11.25876, Total Loss: 128.69765
Epoch[57/100], Step [70/391], Reconst Loss: 121.79993, KL Div: 11.24372, Total Loss: 133.04365
Epoch[57/100], Step [80/391], Reconst Loss: 113.98708, KL Div: 11.28611, Total Loss: 125.27319
Epoch[57/100], Step [90/391], Reconst Loss: 119.05217, KL Div: 11.57891, Total Loss: 130.63108
Epoch[57/100], Step [100/391], Reconst Loss: 115.34380, KL Div: 11.38325, Total Loss: 126.72704
Epoch[57/100], Step [110/391], Reconst Loss: 112.74287, KL Div: 11.22294, Total Loss: 123.96582
Epoch[57/100], Step [120/391], Reconst Loss: 114.79556, KL Div: 11.31442, Total Loss: 126.10998
Epoch[57/100], Step [130/391], Reconst Loss: 120.18059, KL Div: 11.54779, Total Loss: 131.72838
Epoch[57/100], Step [140/391], Reconst Loss: 116.96058, KL Div: 11.60666, Total Loss: 128.56724
Epoch[57/100], Step [150/391], Reconst Loss: 121.97187, KL Div: 11.58968, Total Loss: 133.56155
Epoch[57/100], Step [160/391], Reconst Loss: 117.66018, KL Div: 11.58076, Total Loss: 129.24094
Epoch[57/100], Step [170/391], Reconst Loss: 112.24547, KL Div: 11.58042, Total Loss: 123.82588
Epoch[57/100], Step [180/391], Reconst Loss: 118.23347, KL Div: 11.38035, Total Loss: 129.61382
Epoch[57/100], Step [190/391], Reconst Loss: 119.63824, KL Div: 11.06868, Total Loss: 130.70693
Epoch[57/100], Step [200/391], Reconst Loss: 112.59808, KL Div: 11.55610, Total Loss: 124.15419
Epoch[57/100], Step [210/391], Reconst Loss: 117.94275, KL Div: 11.52398, Total Loss: 129.46673
Epoch[57/100], Step [220/391], Reconst Loss: 116.21542, KL Div: 11.39194, Total Loss: 127.60735
Epoch[57/100], Step [230/391], Reconst Loss: 116.89047, KL Div: 11.67976, Total Loss: 128.57023
Epoch[57/100], Step [240/391], Reconst Loss: 116.62706, KL Div: 11.23385, Total Loss: 127.86091
Epoch[57/100], Step [250/391], Reconst Loss: 112.99062, KL Div: 11.14126, Total Loss: 124.13188
Epoch[57/100], Step [260/391], Reconst Loss: 112.85621, KL Div: 11.54685, Total Loss: 124.40305
Epoch[57/100], Step [270/391], Reconst Loss: 117.86375, KL Div: 11.36713, Total Loss: 129.23088
Epoch[57/100], Step [280/391], Reconst Loss: 110.99115, KL Div: 10.83559, Total Loss: 121.82674
Epoch[57/100], Step [290/391], Reconst Loss: 116.00545, KL Div: 10.78947, Total Loss: 126.79492
Epoch[57/100], Step [300/391], Reconst Loss: 114.45933, KL Div: 11.43521, Total Loss: 125.89453
Epoch[57/100], Step [310/391], Reconst Loss: 114.40150, KL Div: 11.59610, Total Loss: 125.99760
Epoch[57/100], Step [320/391], Reconst Loss: 122.00668, KL Div: 11.11167, Total Loss: 133.11834
Epoch[57/100], Step [330/391], Reconst Loss: 112.47556, KL Div: 11.34274, Total Loss: 123.81830
Epoch[57/100], Step [340/391], Reconst Loss: 114.54709, KL Div: 11.09802, Total Loss: 125.64511
Epoch[57/100], Step [350/391], Reconst Loss: 116.96808, KL Div: 11.19926, Total Loss: 128.16734
Epoch[57/100], Step [360/391], Reconst Loss: 119.33548, KL Div: 11.63876, Total Loss: 130.97424
Epoch[57/100], Step [370/391], Reconst Loss: 121.32198, KL Div: 11.42052, Total Loss: 132.74250
Epoch[57/100], Step [380/391], Reconst Loss: 114.80843, KL Div: 11.59788, Total Loss: 126.40631
Epoch[57/100], Step [390/391], Reconst Loss: 116.72443, KL Div: 11.67711, Total Loss: 128.40153
Epoch = 57
Training epoch time =  139.40542125701904
train total loss =  126.96867958984375
valid total loss =  127.97663466796875
Total epoch time =  257.8766620159149
Saving checkpoint...
Done!
Epoch[58/100], Step [10/391], Reconst Loss: 120.64079, KL Div: 11.33339, Total Loss: 131.97418
Epoch[58/100], Step [20/391], Reconst Loss: 120.68601, KL Div: 11.52673, Total Loss: 132.21274
Epoch[58/100], Step [30/391], Reconst Loss: 113.24921, KL Div: 11.34404, Total Loss: 124.59325
Epoch[58/100], Step [40/391], Reconst Loss: 109.45164, KL Div: 11.44513, Total Loss: 120.89677
Epoch[58/100], Step [50/391], Reconst Loss: 119.23936, KL Div: 11.64389, Total Loss: 130.88326
Epoch[58/100], Step [60/391], Reconst Loss: 112.87279, KL Div: 11.50060, Total Loss: 124.37338
Epoch[58/100], Step [70/391], Reconst Loss: 113.71041, KL Div: 11.45631, Total Loss: 125.16672
Epoch[58/100], Step [80/391], Reconst Loss: 115.63782, KL Div: 11.35887, Total Loss: 126.99669
Epoch[58/100], Step [90/391], Reconst Loss: 120.31733, KL Div: 11.96476, Total Loss: 132.28209
Epoch[58/100], Step [100/391], Reconst Loss: 110.73978, KL Div: 11.31623, Total Loss: 122.05601
Epoch[58/100], Step [110/391], Reconst Loss: 119.16022, KL Div: 10.97461, Total Loss: 130.13483
Epoch[58/100], Step [120/391], Reconst Loss: 116.06226, KL Div: 11.71127, Total Loss: 127.77353
Epoch[58/100], Step [130/391], Reconst Loss: 113.54074, KL Div: 11.63564, Total Loss: 125.17639
Epoch[58/100], Step [140/391], Reconst Loss: 113.30002, KL Div: 11.26685, Total Loss: 124.56687
Epoch[58/100], Step [150/391], Reconst Loss: 117.08294, KL Div: 11.55541, Total Loss: 128.63835
Epoch[58/100], Step [160/391], Reconst Loss: 118.64088, KL Div: 11.83471, Total Loss: 130.47560
Epoch[58/100], Step [170/391], Reconst Loss: 117.54785, KL Div: 11.16263, Total Loss: 128.71048
Epoch[58/100], Step [180/391], Reconst Loss: 115.86691, KL Div: 11.36048, Total Loss: 127.22740
Epoch[58/100], Step [190/391], Reconst Loss: 120.29906, KL Div: 11.33355, Total Loss: 131.63261
Epoch[58/100], Step [200/391], Reconst Loss: 116.71953, KL Div: 11.19958, Total Loss: 127.91911
Epoch[58/100], Step [210/391], Reconst Loss: 108.90374, KL Div: 11.30890, Total Loss: 120.21264
Epoch[58/100], Step [220/391], Reconst Loss: 115.26630, KL Div: 11.49769, Total Loss: 126.76399
Epoch[58/100], Step [230/391], Reconst Loss: 121.25940, KL Div: 11.80421, Total Loss: 133.06360
Epoch[58/100], Step [240/391], Reconst Loss: 118.04652, KL Div: 11.36032, Total Loss: 129.40684
Epoch[58/100], Step [250/391], Reconst Loss: 113.58975, KL Div: 11.65391, Total Loss: 125.24366
Epoch[58/100], Step [260/391], Reconst Loss: 110.38403, KL Div: 11.30867, Total Loss: 121.69270
Epoch[58/100], Step [270/391], Reconst Loss: 119.20528, KL Div: 11.23753, Total Loss: 130.44280
Epoch[58/100], Step [280/391], Reconst Loss: 119.74349, KL Div: 11.54548, Total Loss: 131.28897
Epoch[58/100], Step [290/391], Reconst Loss: 117.34825, KL Div: 11.57078, Total Loss: 128.91903
Epoch[58/100], Step [300/391], Reconst Loss: 120.65399, KL Div: 11.56051, Total Loss: 132.21450
Epoch[58/100], Step [310/391], Reconst Loss: 119.95567, KL Div: 11.34634, Total Loss: 131.30202
Epoch[58/100], Step [320/391], Reconst Loss: 109.53287, KL Div: 11.41113, Total Loss: 120.94400
Epoch[58/100], Step [330/391], Reconst Loss: 114.80270, KL Div: 11.43069, Total Loss: 126.23338
Epoch[58/100], Step [340/391], Reconst Loss: 122.99067, KL Div: 10.91269, Total Loss: 133.90335
Epoch[58/100], Step [350/391], Reconst Loss: 113.61885, KL Div: 11.64235, Total Loss: 125.26120
Epoch[58/100], Step [360/391], Reconst Loss: 118.77455, KL Div: 11.64534, Total Loss: 130.41989
Epoch[58/100], Step [370/391], Reconst Loss: 117.08409, KL Div: 11.58986, Total Loss: 128.67395
Epoch[58/100], Step [380/391], Reconst Loss: 117.88681, KL Div: 11.44170, Total Loss: 129.32851
Epoch[58/100], Step [390/391], Reconst Loss: 111.28668, KL Div: 11.32020, Total Loss: 122.60688
Epoch = 58
Training epoch time =  139.255450963974
train total loss =  126.5659875
valid total loss =  127.72533334960937
Total epoch time =  257.4439046382904
Saving checkpoint...
Done!
Epoch[59/100], Step [10/391], Reconst Loss: 112.55820, KL Div: 11.61172, Total Loss: 124.16993
Epoch[59/100], Step [20/391], Reconst Loss: 113.96864, KL Div: 11.31829, Total Loss: 125.28693
Epoch[59/100], Step [30/391], Reconst Loss: 116.86275, KL Div: 11.89578, Total Loss: 128.75853
Epoch[59/100], Step [40/391], Reconst Loss: 120.57988, KL Div: 11.32667, Total Loss: 131.90655
Epoch[59/100], Step [50/391], Reconst Loss: 121.58264, KL Div: 11.76744, Total Loss: 133.35008
Epoch[59/100], Step [60/391], Reconst Loss: 117.09385, KL Div: 11.18065, Total Loss: 128.27450
Epoch[59/100], Step [70/391], Reconst Loss: 115.64012, KL Div: 11.27584, Total Loss: 126.91596
Epoch[59/100], Step [80/391], Reconst Loss: 115.67915, KL Div: 11.22659, Total Loss: 126.90574
Epoch[59/100], Step [90/391], Reconst Loss: 114.41338, KL Div: 11.55463, Total Loss: 125.96800
Epoch[59/100], Step [100/391], Reconst Loss: 117.31796, KL Div: 11.38665, Total Loss: 128.70462
Epoch[59/100], Step [110/391], Reconst Loss: 112.33566, KL Div: 11.57593, Total Loss: 123.91158
Epoch[59/100], Step [120/391], Reconst Loss: 119.56392, KL Div: 11.57242, Total Loss: 131.13633
Epoch[59/100], Step [130/391], Reconst Loss: 118.35318, KL Div: 11.62256, Total Loss: 129.97574
Epoch[59/100], Step [140/391], Reconst Loss: 118.06879, KL Div: 11.67850, Total Loss: 129.74729
Epoch[59/100], Step [150/391], Reconst Loss: 112.70586, KL Div: 11.26853, Total Loss: 123.97440
Epoch[59/100], Step [160/391], Reconst Loss: 118.40083, KL Div: 11.91436, Total Loss: 130.31519
Epoch[59/100], Step [170/391], Reconst Loss: 114.95441, KL Div: 11.69229, Total Loss: 126.64670
Epoch[59/100], Step [180/391], Reconst Loss: 118.50598, KL Div: 11.49012, Total Loss: 129.99610
Epoch[59/100], Step [190/391], Reconst Loss: 115.55341, KL Div: 11.51742, Total Loss: 127.07083
Epoch[59/100], Step [200/391], Reconst Loss: 120.21620, KL Div: 11.59798, Total Loss: 131.81419
Epoch[59/100], Step [210/391], Reconst Loss: 118.62331, KL Div: 11.37874, Total Loss: 130.00205
Epoch[59/100], Step [220/391], Reconst Loss: 115.56305, KL Div: 11.74675, Total Loss: 127.30979
Epoch[59/100], Step [230/391], Reconst Loss: 118.09821, KL Div: 11.62642, Total Loss: 129.72463
Epoch[59/100], Step [240/391], Reconst Loss: 116.53862, KL Div: 11.18734, Total Loss: 127.72596
Epoch[59/100], Step [250/391], Reconst Loss: 118.22770, KL Div: 11.42256, Total Loss: 129.65026
Epoch[59/100], Step [260/391], Reconst Loss: 114.82208, KL Div: 11.60610, Total Loss: 126.42818
Epoch[59/100], Step [270/391], Reconst Loss: 113.05080, KL Div: 11.40797, Total Loss: 124.45876
Epoch[59/100], Step [280/391], Reconst Loss: 118.46410, KL Div: 11.14798, Total Loss: 129.61207
Epoch[59/100], Step [290/391], Reconst Loss: 116.52821, KL Div: 11.49713, Total Loss: 128.02533
Epoch[59/100], Step [300/391], Reconst Loss: 117.17848, KL Div: 11.86239, Total Loss: 129.04087
Epoch[59/100], Step [310/391], Reconst Loss: 113.55724, KL Div: 12.05002, Total Loss: 125.60727
Epoch[59/100], Step [320/391], Reconst Loss: 118.47482, KL Div: 11.16896, Total Loss: 129.64378
Epoch[59/100], Step [330/391], Reconst Loss: 116.10734, KL Div: 11.71587, Total Loss: 127.82321
Epoch[59/100], Step [340/391], Reconst Loss: 116.57571, KL Div: 11.76110, Total Loss: 128.33682
Epoch[59/100], Step [350/391], Reconst Loss: 116.81354, KL Div: 11.31273, Total Loss: 128.12627
Epoch[59/100], Step [360/391], Reconst Loss: 118.95371, KL Div: 11.50741, Total Loss: 130.46113
Epoch[59/100], Step [370/391], Reconst Loss: 119.67262, KL Div: 11.74396, Total Loss: 131.41658
Epoch[59/100], Step [380/391], Reconst Loss: 119.61652, KL Div: 11.75933, Total Loss: 131.37585
Epoch[59/100], Step [390/391], Reconst Loss: 114.45729, KL Div: 11.66969, Total Loss: 126.12698
Epoch = 59
Training epoch time =  139.28744411468506
train total loss =  126.19286220703125
valid total loss =  127.34354533691406
Total epoch time =  257.6336319446564
Saving checkpoint...
Done!
Epoch[60/100], Step [10/391], Reconst Loss: 113.25136, KL Div: 11.85090, Total Loss: 125.10226
Epoch[60/100], Step [20/391], Reconst Loss: 115.05618, KL Div: 11.21576, Total Loss: 126.27194
Epoch[60/100], Step [30/391], Reconst Loss: 119.45311, KL Div: 11.65648, Total Loss: 131.10959
Epoch[60/100], Step [40/391], Reconst Loss: 117.59410, KL Div: 11.69330, Total Loss: 129.28740
Epoch[60/100], Step [50/391], Reconst Loss: 117.77946, KL Div: 11.74037, Total Loss: 129.51983
Epoch[60/100], Step [60/391], Reconst Loss: 112.72613, KL Div: 11.60081, Total Loss: 124.32693
Epoch[60/100], Step [70/391], Reconst Loss: 117.60954, KL Div: 11.27868, Total Loss: 128.88823
Epoch[60/100], Step [80/391], Reconst Loss: 107.78020, KL Div: 11.60238, Total Loss: 119.38258
Epoch[60/100], Step [90/391], Reconst Loss: 113.03819, KL Div: 11.47819, Total Loss: 124.51638
Epoch[60/100], Step [100/391], Reconst Loss: 114.48502, KL Div: 11.61173, Total Loss: 126.09675
Epoch[60/100], Step [110/391], Reconst Loss: 118.98676, KL Div: 11.64699, Total Loss: 130.63374
Epoch[60/100], Step [120/391], Reconst Loss: 113.65017, KL Div: 11.23963, Total Loss: 124.88980
Epoch[60/100], Step [130/391], Reconst Loss: 115.73807, KL Div: 11.60163, Total Loss: 127.33970
Epoch[60/100], Step [140/391], Reconst Loss: 113.23405, KL Div: 11.45877, Total Loss: 124.69281
Epoch[60/100], Step [150/391], Reconst Loss: 118.45781, KL Div: 11.67727, Total Loss: 130.13508
Epoch[60/100], Step [160/391], Reconst Loss: 111.36673, KL Div: 11.58244, Total Loss: 122.94917
Epoch[60/100], Step [170/391], Reconst Loss: 121.69989, KL Div: 11.70013, Total Loss: 133.40002
Epoch[60/100], Step [180/391], Reconst Loss: 115.91782, KL Div: 11.61499, Total Loss: 127.53281
Epoch[60/100], Step [190/391], Reconst Loss: 120.33577, KL Div: 11.55145, Total Loss: 131.88721
Epoch[60/100], Step [200/391], Reconst Loss: 116.92252, KL Div: 11.42621, Total Loss: 128.34873
Epoch[60/100], Step [210/391], Reconst Loss: 113.27290, KL Div: 11.48840, Total Loss: 124.76131
Epoch[60/100], Step [220/391], Reconst Loss: 115.25779, KL Div: 11.55401, Total Loss: 126.81180
Epoch[60/100], Step [230/391], Reconst Loss: 110.93225, KL Div: 11.35951, Total Loss: 122.29176
Epoch[60/100], Step [240/391], Reconst Loss: 124.60890, KL Div: 11.53603, Total Loss: 136.14493
Epoch[60/100], Step [250/391], Reconst Loss: 117.74658, KL Div: 11.83144, Total Loss: 129.57802
Epoch[60/100], Step [260/391], Reconst Loss: 114.79518, KL Div: 11.85773, Total Loss: 126.65291
Epoch[60/100], Step [270/391], Reconst Loss: 120.03584, KL Div: 11.72931, Total Loss: 131.76515
Epoch[60/100], Step [280/391], Reconst Loss: 113.46820, KL Div: 11.54583, Total Loss: 125.01403
Epoch[60/100], Step [290/391], Reconst Loss: 109.87360, KL Div: 11.16904, Total Loss: 121.04264
Epoch[60/100], Step [300/391], Reconst Loss: 117.52513, KL Div: 11.67607, Total Loss: 129.20120
Epoch[60/100], Step [310/391], Reconst Loss: 118.99559, KL Div: 11.29087, Total Loss: 130.28647
Epoch[60/100], Step [320/391], Reconst Loss: 109.83618, KL Div: 11.52965, Total Loss: 121.36583
Epoch[60/100], Step [330/391], Reconst Loss: 118.70494, KL Div: 11.50306, Total Loss: 130.20800
Epoch[60/100], Step [340/391], Reconst Loss: 112.33229, KL Div: 11.11648, Total Loss: 123.44877
Epoch[60/100], Step [350/391], Reconst Loss: 116.14507, KL Div: 11.67584, Total Loss: 127.82090
Epoch[60/100], Step [360/391], Reconst Loss: 114.07388, KL Div: 11.49382, Total Loss: 125.56770
Epoch[60/100], Step [370/391], Reconst Loss: 111.59524, KL Div: 10.97506, Total Loss: 122.57030
Epoch[60/100], Step [380/391], Reconst Loss: 120.20738, KL Div: 11.55127, Total Loss: 131.75865
Epoch[60/100], Step [390/391], Reconst Loss: 114.85310, KL Div: 11.78235, Total Loss: 126.63544
Epoch = 60
Training epoch time =  139.51910519599915
train total loss =  126.7855641015625
valid total loss =  127.83126206054688
Total epoch time =  257.7365231513977
Saving checkpoint...
Done!
Epoch[61/100], Step [10/391], Reconst Loss: 112.88489, KL Div: 11.42321, Total Loss: 124.30809
Epoch[61/100], Step [20/391], Reconst Loss: 111.69243, KL Div: 11.55186, Total Loss: 123.24429
Epoch[61/100], Step [30/391], Reconst Loss: 114.48246, KL Div: 11.67564, Total Loss: 126.15810
Epoch[61/100], Step [40/391], Reconst Loss: 114.86863, KL Div: 11.37759, Total Loss: 126.24622
Epoch[61/100], Step [50/391], Reconst Loss: 112.96848, KL Div: 10.82480, Total Loss: 123.79328
Epoch[61/100], Step [60/391], Reconst Loss: 118.22964, KL Div: 11.55704, Total Loss: 129.78667
Epoch[61/100], Step [70/391], Reconst Loss: 115.23404, KL Div: 11.34334, Total Loss: 126.57738
Epoch[61/100], Step [80/391], Reconst Loss: 120.98618, KL Div: 11.31880, Total Loss: 132.30498
Epoch[61/100], Step [90/391], Reconst Loss: 119.69920, KL Div: 11.44912, Total Loss: 131.14833
Epoch[61/100], Step [100/391], Reconst Loss: 114.20650, KL Div: 11.26424, Total Loss: 125.47074
Epoch[61/100], Step [110/391], Reconst Loss: 116.59468, KL Div: 11.50038, Total Loss: 128.09506
Epoch[61/100], Step [120/391], Reconst Loss: 116.18639, KL Div: 11.63176, Total Loss: 127.81814
Epoch[61/100], Step [130/391], Reconst Loss: 111.21451, KL Div: 11.59686, Total Loss: 122.81137
Epoch[61/100], Step [140/391], Reconst Loss: 118.52548, KL Div: 11.02250, Total Loss: 129.54798
Epoch[61/100], Step [150/391], Reconst Loss: 114.08485, KL Div: 11.51728, Total Loss: 125.60213
Epoch[61/100], Step [160/391], Reconst Loss: 114.46519, KL Div: 11.15850, Total Loss: 125.62370
Epoch[61/100], Step [170/391], Reconst Loss: 117.13854, KL Div: 11.67049, Total Loss: 128.80903
Epoch[61/100], Step [180/391], Reconst Loss: 115.85907, KL Div: 11.62743, Total Loss: 127.48650
Epoch[61/100], Step [190/391], Reconst Loss: 112.05952, KL Div: 11.35195, Total Loss: 123.41146
Epoch[61/100], Step [200/391], Reconst Loss: 118.50451, KL Div: 11.52485, Total Loss: 130.02936
Epoch[61/100], Step [210/391], Reconst Loss: 120.57256, KL Div: 11.74951, Total Loss: 132.32206
Epoch[61/100], Step [220/391], Reconst Loss: 110.26628, KL Div: 11.66807, Total Loss: 121.93435
Epoch[61/100], Step [230/391], Reconst Loss: 116.80763, KL Div: 11.64029, Total Loss: 128.44792
Epoch[61/100], Step [240/391], Reconst Loss: 119.45023, KL Div: 11.12845, Total Loss: 130.57867
Epoch[61/100], Step [250/391], Reconst Loss: 120.92992, KL Div: 11.26468, Total Loss: 132.19460
Epoch[61/100], Step [260/391], Reconst Loss: 114.52983, KL Div: 11.62655, Total Loss: 126.15638
Epoch[61/100], Step [270/391], Reconst Loss: 114.02423, KL Div: 11.20870, Total Loss: 125.23293
Epoch[61/100], Step [280/391], Reconst Loss: 118.90408, KL Div: 11.49407, Total Loss: 130.39815
Epoch[61/100], Step [290/391], Reconst Loss: 110.50791, KL Div: 10.95418, Total Loss: 121.46209
Epoch[61/100], Step [300/391], Reconst Loss: 120.74749, KL Div: 11.88129, Total Loss: 132.62878
Epoch[61/100], Step [310/391], Reconst Loss: 115.51308, KL Div: 11.76183, Total Loss: 127.27490
Epoch[61/100], Step [320/391], Reconst Loss: 116.35364, KL Div: 11.82513, Total Loss: 128.17877
Epoch[61/100], Step [330/391], Reconst Loss: 116.12508, KL Div: 11.57457, Total Loss: 127.69965
Epoch[61/100], Step [340/391], Reconst Loss: 119.29321, KL Div: 11.31140, Total Loss: 130.60462
Epoch[61/100], Step [350/391], Reconst Loss: 114.02416, KL Div: 11.42849, Total Loss: 125.45266
Epoch[61/100], Step [360/391], Reconst Loss: 118.11732, KL Div: 11.56587, Total Loss: 129.68319
Epoch[61/100], Step [370/391], Reconst Loss: 115.67892, KL Div: 11.71208, Total Loss: 127.39100
Epoch[61/100], Step [380/391], Reconst Loss: 116.00047, KL Div: 11.39261, Total Loss: 127.39308
Epoch[61/100], Step [390/391], Reconst Loss: 119.64520, KL Div: 11.22745, Total Loss: 130.87265
Epoch = 61
Training epoch time =  139.83128023147583
train total loss =  126.44694794921875
valid total loss =  127.83002783203125
Total epoch time =  258.442813873291
Saving checkpoint...
Done!
Epoch[62/100], Step [10/391], Reconst Loss: 118.14349, KL Div: 11.41655, Total Loss: 129.56005
Epoch[62/100], Step [20/391], Reconst Loss: 115.63283, KL Div: 11.47652, Total Loss: 127.10935
Epoch[62/100], Step [30/391], Reconst Loss: 115.35432, KL Div: 11.28313, Total Loss: 126.63744
Epoch[62/100], Step [40/391], Reconst Loss: 114.58638, KL Div: 11.59656, Total Loss: 126.18294
Epoch[62/100], Step [50/391], Reconst Loss: 114.50198, KL Div: 12.06619, Total Loss: 126.56816
Epoch[62/100], Step [60/391], Reconst Loss: 113.30167, KL Div: 11.15351, Total Loss: 124.45517
Epoch[62/100], Step [70/391], Reconst Loss: 122.46700, KL Div: 11.30360, Total Loss: 133.77060
Epoch[62/100], Step [80/391], Reconst Loss: 118.11888, KL Div: 11.45820, Total Loss: 129.57708
Epoch[62/100], Step [90/391], Reconst Loss: 112.98954, KL Div: 11.10515, Total Loss: 124.09469
Epoch[62/100], Step [100/391], Reconst Loss: 113.38984, KL Div: 11.55029, Total Loss: 124.94013
Epoch[62/100], Step [110/391], Reconst Loss: 121.91437, KL Div: 11.44853, Total Loss: 133.36290
Epoch[62/100], Step [120/391], Reconst Loss: 116.75760, KL Div: 11.31842, Total Loss: 128.07601
Epoch[62/100], Step [130/391], Reconst Loss: 124.82166, KL Div: 11.55382, Total Loss: 136.37547
Epoch[62/100], Step [140/391], Reconst Loss: 117.99110, KL Div: 11.36263, Total Loss: 129.35373
Epoch[62/100], Step [150/391], Reconst Loss: 117.71197, KL Div: 11.22794, Total Loss: 128.93991
Epoch[62/100], Step [160/391], Reconst Loss: 116.15601, KL Div: 11.38520, Total Loss: 127.54121
Epoch[62/100], Step [170/391], Reconst Loss: 115.45280, KL Div: 11.61661, Total Loss: 127.06941
Epoch[62/100], Step [180/391], Reconst Loss: 119.81178, KL Div: 11.48100, Total Loss: 131.29278
Epoch[62/100], Step [190/391], Reconst Loss: 118.72717, KL Div: 11.48427, Total Loss: 130.21144
Epoch[62/100], Step [200/391], Reconst Loss: 110.68957, KL Div: 11.25455, Total Loss: 121.94412
Epoch[62/100], Step [210/391], Reconst Loss: 119.17154, KL Div: 11.80571, Total Loss: 130.97725
Epoch[62/100], Step [220/391], Reconst Loss: 109.58814, KL Div: 11.15516, Total Loss: 120.74330
Epoch[62/100], Step [230/391], Reconst Loss: 119.17799, KL Div: 11.32679, Total Loss: 130.50478
Epoch[62/100], Step [240/391], Reconst Loss: 119.10651, KL Div: 11.32063, Total Loss: 130.42714
Epoch[62/100], Step [250/391], Reconst Loss: 116.54807, KL Div: 11.34100, Total Loss: 127.88906
Epoch[62/100], Step [260/391], Reconst Loss: 117.71937, KL Div: 11.21340, Total Loss: 128.93277
Epoch[62/100], Step [270/391], Reconst Loss: 112.79497, KL Div: 11.34589, Total Loss: 124.14085
Epoch[62/100], Step [280/391], Reconst Loss: 119.13568, KL Div: 11.23347, Total Loss: 130.36915
Epoch[62/100], Step [290/391], Reconst Loss: 109.57219, KL Div: 11.70890, Total Loss: 121.28109
Epoch[62/100], Step [300/391], Reconst Loss: 113.80762, KL Div: 11.04339, Total Loss: 124.85101
Epoch[62/100], Step [310/391], Reconst Loss: 116.77028, KL Div: 11.43596, Total Loss: 128.20624
Epoch[62/100], Step [320/391], Reconst Loss: 119.47774, KL Div: 11.46314, Total Loss: 130.94088
Epoch[62/100], Step [330/391], Reconst Loss: 116.80344, KL Div: 11.30376, Total Loss: 128.10720
Epoch[62/100], Step [340/391], Reconst Loss: 117.28810, KL Div: 11.77946, Total Loss: 129.06756
Epoch[62/100], Step [350/391], Reconst Loss: 114.57752, KL Div: 11.54086, Total Loss: 126.11838
Epoch[62/100], Step [360/391], Reconst Loss: 119.99936, KL Div: 11.57233, Total Loss: 131.57169
Epoch[62/100], Step [370/391], Reconst Loss: 112.59335, KL Div: 11.49094, Total Loss: 124.08429
Epoch[62/100], Step [380/391], Reconst Loss: 119.12316, KL Div: 11.40457, Total Loss: 130.52773
Epoch[62/100], Step [390/391], Reconst Loss: 111.75298, KL Div: 11.73124, Total Loss: 123.48422
Epoch = 62
Training epoch time =  139.64945721626282
train total loss =  126.70557892578125
valid total loss =  127.98153757324219
Total epoch time =  258.1685280799866
Saving checkpoint...
Done!
Epoch[63/100], Step [10/391], Reconst Loss: 115.02625, KL Div: 11.64888, Total Loss: 126.67513
Epoch[63/100], Step [20/391], Reconst Loss: 119.05070, KL Div: 11.47777, Total Loss: 130.52848
Epoch[63/100], Step [30/391], Reconst Loss: 111.94070, KL Div: 10.89341, Total Loss: 122.83411
Epoch[63/100], Step [40/391], Reconst Loss: 117.70612, KL Div: 11.53003, Total Loss: 129.23615
Epoch[63/100], Step [50/391], Reconst Loss: 121.84306, KL Div: 10.73553, Total Loss: 132.57859
Epoch[63/100], Step [60/391], Reconst Loss: 119.88393, KL Div: 11.76832, Total Loss: 131.65226
Epoch[63/100], Step [70/391], Reconst Loss: 114.90717, KL Div: 11.83870, Total Loss: 126.74586
Epoch[63/100], Step [80/391], Reconst Loss: 114.65639, KL Div: 11.10341, Total Loss: 125.75980
Epoch[63/100], Step [90/391], Reconst Loss: 115.69160, KL Div: 11.04155, Total Loss: 126.73315
Epoch[63/100], Step [100/391], Reconst Loss: 116.36012, KL Div: 11.53923, Total Loss: 127.89935
Epoch[63/100], Step [110/391], Reconst Loss: 118.11659, KL Div: 11.31311, Total Loss: 129.42970
Epoch[63/100], Step [120/391], Reconst Loss: 118.36666, KL Div: 11.34383, Total Loss: 129.71049
Epoch[63/100], Step [130/391], Reconst Loss: 116.48981, KL Div: 11.16639, Total Loss: 127.65621
Epoch[63/100], Step [140/391], Reconst Loss: 109.88807, KL Div: 11.07711, Total Loss: 120.96518
Epoch[63/100], Step [150/391], Reconst Loss: 118.25874, KL Div: 11.10273, Total Loss: 129.36148
Epoch[63/100], Step [160/391], Reconst Loss: 119.06514, KL Div: 11.15464, Total Loss: 130.21978
Epoch[63/100], Step [170/391], Reconst Loss: 119.36662, KL Div: 11.35999, Total Loss: 130.72662
Epoch[63/100], Step [180/391], Reconst Loss: 110.72661, KL Div: 11.48890, Total Loss: 122.21551
Epoch[63/100], Step [190/391], Reconst Loss: 116.50922, KL Div: 11.61940, Total Loss: 128.12862
Epoch[63/100], Step [200/391], Reconst Loss: 112.52684, KL Div: 11.75008, Total Loss: 124.27692
Epoch[63/100], Step [210/391], Reconst Loss: 112.92361, KL Div: 11.46061, Total Loss: 124.38422
Epoch[63/100], Step [220/391], Reconst Loss: 114.28654, KL Div: 11.57276, Total Loss: 125.85931
Epoch[63/100], Step [230/391], Reconst Loss: 113.15492, KL Div: 11.42050, Total Loss: 124.57543
Epoch[63/100], Step [240/391], Reconst Loss: 116.65499, KL Div: 11.25209, Total Loss: 127.90708
Epoch[63/100], Step [250/391], Reconst Loss: 111.63860, KL Div: 11.11960, Total Loss: 122.75821
Epoch[63/100], Step [260/391], Reconst Loss: 113.77097, KL Div: 11.59838, Total Loss: 125.36935
Epoch[63/100], Step [270/391], Reconst Loss: 119.91411, KL Div: 11.48322, Total Loss: 131.39733
Epoch[63/100], Step [280/391], Reconst Loss: 119.86751, KL Div: 10.91994, Total Loss: 130.78745
Epoch[63/100], Step [290/391], Reconst Loss: 119.66000, KL Div: 11.61877, Total Loss: 131.27877
Epoch[63/100], Step [300/391], Reconst Loss: 114.03122, KL Div: 11.27037, Total Loss: 125.30159
Epoch[63/100], Step [310/391], Reconst Loss: 118.49870, KL Div: 11.41929, Total Loss: 129.91799
Epoch[63/100], Step [320/391], Reconst Loss: 112.98605, KL Div: 11.50303, Total Loss: 124.48907
Epoch[63/100], Step [330/391], Reconst Loss: 112.72600, KL Div: 11.05032, Total Loss: 123.77631
Epoch[63/100], Step [340/391], Reconst Loss: 113.36056, KL Div: 11.34302, Total Loss: 124.70358
Epoch[63/100], Step [350/391], Reconst Loss: 118.84756, KL Div: 11.51798, Total Loss: 130.36555
Epoch[63/100], Step [360/391], Reconst Loss: 117.76434, KL Div: 11.06474, Total Loss: 128.82908
Epoch[63/100], Step [370/391], Reconst Loss: 120.22903, KL Div: 11.49496, Total Loss: 131.72399
Epoch[63/100], Step [380/391], Reconst Loss: 115.84612, KL Div: 11.09135, Total Loss: 126.93746
Epoch[63/100], Step [390/391], Reconst Loss: 119.57240, KL Div: 11.58726, Total Loss: 131.15966
Epoch = 63
Training epoch time =  139.49445605278015
train total loss =  126.484576015625
valid total loss =  127.84373397216797
Total epoch time =  257.9223213195801
Saving checkpoint...
Done!
Epoch[64/100], Step [10/391], Reconst Loss: 116.59315, KL Div: 11.56797, Total Loss: 128.16112
Epoch[64/100], Step [20/391], Reconst Loss: 122.94202, KL Div: 11.62587, Total Loss: 134.56789
Epoch[64/100], Step [30/391], Reconst Loss: 113.84980, KL Div: 11.26311, Total Loss: 125.11291
Epoch[64/100], Step [40/391], Reconst Loss: 117.11807, KL Div: 11.41212, Total Loss: 128.53020
Epoch[64/100], Step [50/391], Reconst Loss: 110.36864, KL Div: 11.58410, Total Loss: 121.95273
Epoch[64/100], Step [60/391], Reconst Loss: 107.26006, KL Div: 10.64725, Total Loss: 117.90731
Epoch[64/100], Step [70/391], Reconst Loss: 118.66731, KL Div: 10.91614, Total Loss: 129.58346
Epoch[64/100], Step [80/391], Reconst Loss: 123.46191, KL Div: 11.60502, Total Loss: 135.06693
Epoch[64/100], Step [90/391], Reconst Loss: 111.45232, KL Div: 11.44555, Total Loss: 122.89786
Epoch[64/100], Step [100/391], Reconst Loss: 114.08363, KL Div: 11.48216, Total Loss: 125.56579
Epoch[64/100], Step [110/391], Reconst Loss: 117.81940, KL Div: 11.25167, Total Loss: 129.07107
Epoch[64/100], Step [120/391], Reconst Loss: 118.27555, KL Div: 11.10798, Total Loss: 129.38353
Epoch[64/100], Step [130/391], Reconst Loss: 115.15898, KL Div: 10.99233, Total Loss: 126.15131
Epoch[64/100], Step [140/391], Reconst Loss: 114.12677, KL Div: 11.21426, Total Loss: 125.34103
Epoch[64/100], Step [150/391], Reconst Loss: 110.09485, KL Div: 11.93308, Total Loss: 122.02793
Epoch[64/100], Step [160/391], Reconst Loss: 115.28355, KL Div: 11.09188, Total Loss: 126.37544
Epoch[64/100], Step [170/391], Reconst Loss: 117.14068, KL Div: 11.45736, Total Loss: 128.59804
Epoch[64/100], Step [180/391], Reconst Loss: 117.44209, KL Div: 11.82143, Total Loss: 129.26352
Epoch[64/100], Step [190/391], Reconst Loss: 116.54674, KL Div: 11.61586, Total Loss: 128.16260
Epoch[64/100], Step [200/391], Reconst Loss: 109.29781, KL Div: 11.09914, Total Loss: 120.39695
Epoch[64/100], Step [210/391], Reconst Loss: 114.92480, KL Div: 11.19479, Total Loss: 126.11959
Epoch[64/100], Step [220/391], Reconst Loss: 120.79937, KL Div: 11.87648, Total Loss: 132.67585
Epoch[64/100], Step [230/391], Reconst Loss: 112.32649, KL Div: 11.62280, Total Loss: 123.94929
Epoch[64/100], Step [240/391], Reconst Loss: 107.03310, KL Div: 11.44935, Total Loss: 118.48244
Epoch[64/100], Step [250/391], Reconst Loss: 116.26361, KL Div: 11.57832, Total Loss: 127.84193
Epoch[64/100], Step [260/391], Reconst Loss: 114.28475, KL Div: 11.52416, Total Loss: 125.80891
Epoch[64/100], Step [270/391], Reconst Loss: 112.60538, KL Div: 11.55258, Total Loss: 124.15796
Epoch[64/100], Step [280/391], Reconst Loss: 115.75493, KL Div: 11.41532, Total Loss: 127.17025
Epoch[64/100], Step [290/391], Reconst Loss: 112.93343, KL Div: 11.17241, Total Loss: 124.10585
Epoch[64/100], Step [300/391], Reconst Loss: 114.95256, KL Div: 11.36056, Total Loss: 126.31312
Epoch[64/100], Step [310/391], Reconst Loss: 116.29772, KL Div: 11.62050, Total Loss: 127.91822
Epoch[64/100], Step [320/391], Reconst Loss: 123.16010, KL Div: 11.44601, Total Loss: 134.60611
Epoch[64/100], Step [330/391], Reconst Loss: 117.88055, KL Div: 11.45517, Total Loss: 129.33573
Epoch[64/100], Step [340/391], Reconst Loss: 118.88730, KL Div: 11.37160, Total Loss: 130.25890
Epoch[64/100], Step [350/391], Reconst Loss: 115.72169, KL Div: 11.48898, Total Loss: 127.21067
Epoch[64/100], Step [360/391], Reconst Loss: 117.92495, KL Div: 11.47396, Total Loss: 129.39891
Epoch[64/100], Step [370/391], Reconst Loss: 109.61795, KL Div: 11.38963, Total Loss: 121.00758
Epoch[64/100], Step [380/391], Reconst Loss: 114.38222, KL Div: 11.38021, Total Loss: 125.76243
Epoch[64/100], Step [390/391], Reconst Loss: 115.30224, KL Div: 11.05565, Total Loss: 126.35789
Epoch = 64
Training epoch time =  139.2347927093506
train total loss =  126.47280703125
valid total loss =  127.74492145996093
Total epoch time =  257.29075956344604
Saving checkpoint...
Done!
Epoch[65/100], Step [10/391], Reconst Loss: 120.08674, KL Div: 11.49996, Total Loss: 131.58670
Epoch[65/100], Step [20/391], Reconst Loss: 117.14199, KL Div: 11.75927, Total Loss: 128.90126
Epoch[65/100], Step [30/391], Reconst Loss: 115.10414, KL Div: 11.38550, Total Loss: 126.48964
Epoch[65/100], Step [40/391], Reconst Loss: 112.32983, KL Div: 11.66382, Total Loss: 123.99365
Epoch[65/100], Step [50/391], Reconst Loss: 115.76240, KL Div: 11.37902, Total Loss: 127.14141
Epoch[65/100], Step [60/391], Reconst Loss: 118.18217, KL Div: 11.38600, Total Loss: 129.56817
Epoch[65/100], Step [70/391], Reconst Loss: 118.08003, KL Div: 11.49682, Total Loss: 129.57685
Epoch[65/100], Step [80/391], Reconst Loss: 119.09431, KL Div: 11.36658, Total Loss: 130.46089
Epoch[65/100], Step [90/391], Reconst Loss: 108.35179, KL Div: 11.48989, Total Loss: 119.84168
Epoch[65/100], Step [100/391], Reconst Loss: 113.26543, KL Div: 11.12328, Total Loss: 124.38871
Epoch[65/100], Step [110/391], Reconst Loss: 118.06989, KL Div: 11.43234, Total Loss: 129.50224
Epoch[65/100], Step [120/391], Reconst Loss: 113.42523, KL Div: 11.53804, Total Loss: 124.96327
Epoch[65/100], Step [130/391], Reconst Loss: 116.85924, KL Div: 11.53507, Total Loss: 128.39431
Epoch[65/100], Step [140/391], Reconst Loss: 115.52354, KL Div: 11.16948, Total Loss: 126.69303
Epoch[65/100], Step [150/391], Reconst Loss: 115.04507, KL Div: 11.34286, Total Loss: 126.38794
Epoch[65/100], Step [160/391], Reconst Loss: 113.03615, KL Div: 11.52424, Total Loss: 124.56039
Epoch[65/100], Step [170/391], Reconst Loss: 114.04005, KL Div: 11.45651, Total Loss: 125.49656
Epoch[65/100], Step [180/391], Reconst Loss: 119.84903, KL Div: 11.35284, Total Loss: 131.20187
Epoch[65/100], Step [190/391], Reconst Loss: 121.06239, KL Div: 11.83613, Total Loss: 132.89852
Epoch[65/100], Step [200/391], Reconst Loss: 108.66643, KL Div: 11.24775, Total Loss: 119.91418
Epoch[65/100], Step [210/391], Reconst Loss: 116.53210, KL Div: 11.83697, Total Loss: 128.36908
Epoch[65/100], Step [220/391], Reconst Loss: 122.16654, KL Div: 11.36857, Total Loss: 133.53511
Epoch[65/100], Step [230/391], Reconst Loss: 117.73939, KL Div: 11.85900, Total Loss: 129.59839
Epoch[65/100], Step [240/391], Reconst Loss: 109.67304, KL Div: 11.16462, Total Loss: 120.83766
Epoch[65/100], Step [250/391], Reconst Loss: 117.95754, KL Div: 11.99231, Total Loss: 129.94985
Epoch[65/100], Step [260/391], Reconst Loss: 115.00861, KL Div: 11.42452, Total Loss: 126.43313
Epoch[65/100], Step [270/391], Reconst Loss: 113.75937, KL Div: 11.53430, Total Loss: 125.29366
Epoch[65/100], Step [280/391], Reconst Loss: 114.12564, KL Div: 11.65772, Total Loss: 125.78336
Epoch[65/100], Step [290/391], Reconst Loss: 115.58295, KL Div: 11.52765, Total Loss: 127.11061
Epoch[65/100], Step [300/391], Reconst Loss: 113.28904, KL Div: 11.61028, Total Loss: 124.89932
Epoch[65/100], Step [310/391], Reconst Loss: 117.62740, KL Div: 11.41156, Total Loss: 129.03896
Epoch[65/100], Step [320/391], Reconst Loss: 108.75403, KL Div: 11.72313, Total Loss: 120.47716
Epoch[65/100], Step [330/391], Reconst Loss: 120.33134, KL Div: 11.70421, Total Loss: 132.03556
Epoch[65/100], Step [340/391], Reconst Loss: 119.88620, KL Div: 10.93728, Total Loss: 130.82348
Epoch[65/100], Step [350/391], Reconst Loss: 113.11038, KL Div: 11.76730, Total Loss: 124.87768
Epoch[65/100], Step [360/391], Reconst Loss: 112.23558, KL Div: 11.34309, Total Loss: 123.57867
Epoch[65/100], Step [370/391], Reconst Loss: 113.34440, KL Div: 11.49051, Total Loss: 124.83491
Epoch[65/100], Step [380/391], Reconst Loss: 122.06961, KL Div: 11.43147, Total Loss: 133.50108
Epoch[65/100], Step [390/391], Reconst Loss: 121.28640, KL Div: 11.59492, Total Loss: 132.88132
Epoch = 65
Training epoch time =  139.3713300228119
train total loss =  126.192374296875
valid total loss =  127.53442259521485
Total epoch time =  257.362753868103
Saving checkpoint...
Done!
Epoch[66/100], Step [10/391], Reconst Loss: 111.60595, KL Div: 11.40843, Total Loss: 123.01438
Epoch[66/100], Step [20/391], Reconst Loss: 110.61782, KL Div: 11.23301, Total Loss: 121.85083
Epoch[66/100], Step [30/391], Reconst Loss: 120.16460, KL Div: 11.52224, Total Loss: 131.68683
Epoch[66/100], Step [40/391], Reconst Loss: 115.56055, KL Div: 11.17382, Total Loss: 126.73437
Epoch[66/100], Step [50/391], Reconst Loss: 115.75339, KL Div: 11.84708, Total Loss: 127.60047
Epoch[66/100], Step [60/391], Reconst Loss: 111.19292, KL Div: 11.65807, Total Loss: 122.85099
Epoch[66/100], Step [70/391], Reconst Loss: 110.67468, KL Div: 11.28091, Total Loss: 121.95559
Epoch[66/100], Step [80/391], Reconst Loss: 108.32893, KL Div: 11.16594, Total Loss: 119.49487
Epoch[66/100], Step [90/391], Reconst Loss: 113.88653, KL Div: 11.30508, Total Loss: 125.19161
Epoch[66/100], Step [100/391], Reconst Loss: 118.41685, KL Div: 11.11005, Total Loss: 129.52690
Epoch[66/100], Step [110/391], Reconst Loss: 115.26900, KL Div: 11.51111, Total Loss: 126.78011
Epoch[66/100], Step [120/391], Reconst Loss: 108.20878, KL Div: 11.29062, Total Loss: 119.49940
Epoch[66/100], Step [130/391], Reconst Loss: 116.84007, KL Div: 11.49493, Total Loss: 128.33500
Epoch[66/100], Step [140/391], Reconst Loss: 117.80879, KL Div: 11.12029, Total Loss: 128.92908
Epoch[66/100], Step [150/391], Reconst Loss: 116.36943, KL Div: 11.45293, Total Loss: 127.82236
Epoch[66/100], Step [160/391], Reconst Loss: 114.14075, KL Div: 11.12503, Total Loss: 125.26578
Epoch[66/100], Step [170/391], Reconst Loss: 114.14964, KL Div: 11.32108, Total Loss: 125.47072
Epoch[66/100], Step [180/391], Reconst Loss: 116.26031, KL Div: 11.52483, Total Loss: 127.78515
Epoch[66/100], Step [190/391], Reconst Loss: 108.75565, KL Div: 11.49224, Total Loss: 120.24789
Epoch[66/100], Step [200/391], Reconst Loss: 117.00906, KL Div: 11.48469, Total Loss: 128.49376
Epoch[66/100], Step [210/391], Reconst Loss: 119.31976, KL Div: 11.27234, Total Loss: 130.59210
Epoch[66/100], Step [220/391], Reconst Loss: 115.92584, KL Div: 11.36793, Total Loss: 127.29377
Epoch[66/100], Step [230/391], Reconst Loss: 118.93878, KL Div: 11.69378, Total Loss: 130.63256
Epoch[66/100], Step [240/391], Reconst Loss: 118.56021, KL Div: 11.55273, Total Loss: 130.11294
Epoch[66/100], Step [250/391], Reconst Loss: 121.46672, KL Div: 11.39154, Total Loss: 132.85826
Epoch[66/100], Step [260/391], Reconst Loss: 116.47395, KL Div: 11.82321, Total Loss: 128.29716
Epoch[66/100], Step [270/391], Reconst Loss: 114.67981, KL Div: 11.40198, Total Loss: 126.08179
Epoch[66/100], Step [280/391], Reconst Loss: 109.80681, KL Div: 11.39377, Total Loss: 121.20058
Epoch[66/100], Step [290/391], Reconst Loss: 118.05296, KL Div: 11.06490, Total Loss: 129.11786
Epoch[66/100], Step [300/391], Reconst Loss: 120.36002, KL Div: 11.56228, Total Loss: 131.92230
Epoch[66/100], Step [310/391], Reconst Loss: 116.26345, KL Div: 11.17136, Total Loss: 127.43481
Epoch[66/100], Step [320/391], Reconst Loss: 116.01133, KL Div: 11.25055, Total Loss: 127.26188
Epoch[66/100], Step [330/391], Reconst Loss: 120.04403, KL Div: 11.36770, Total Loss: 131.41173
Epoch[66/100], Step [340/391], Reconst Loss: 115.94236, KL Div: 11.38592, Total Loss: 127.32828
Epoch[66/100], Step [350/391], Reconst Loss: 120.43973, KL Div: 11.44035, Total Loss: 131.88008
Epoch[66/100], Step [360/391], Reconst Loss: 114.65843, KL Div: 11.39823, Total Loss: 126.05666
Epoch[66/100], Step [370/391], Reconst Loss: 108.54055, KL Div: 11.22133, Total Loss: 119.76188
Epoch[66/100], Step [380/391], Reconst Loss: 115.61530, KL Div: 11.41776, Total Loss: 127.03306
Epoch[66/100], Step [390/391], Reconst Loss: 117.25794, KL Div: 11.36459, Total Loss: 128.62253
Epoch = 66
Training epoch time =  139.34497117996216
train total loss =  126.15222220703124
valid total loss =  127.48915408935547
Total epoch time =  257.69706630706787
Saving checkpoint...
Done!
Epoch[67/100], Step [10/391], Reconst Loss: 114.12314, KL Div: 11.59482, Total Loss: 125.71796
Epoch[67/100], Step [20/391], Reconst Loss: 109.12457, KL Div: 11.26648, Total Loss: 120.39105
Epoch[67/100], Step [30/391], Reconst Loss: 115.54750, KL Div: 11.23100, Total Loss: 126.77850
Epoch[67/100], Step [40/391], Reconst Loss: 116.85530, KL Div: 11.09032, Total Loss: 127.94562
Epoch[67/100], Step [50/391], Reconst Loss: 115.83065, KL Div: 11.46342, Total Loss: 127.29407
Epoch[67/100], Step [60/391], Reconst Loss: 117.90770, KL Div: 11.23387, Total Loss: 129.14157
Epoch[67/100], Step [70/391], Reconst Loss: 108.75209, KL Div: 11.57440, Total Loss: 120.32649
Epoch[67/100], Step [80/391], Reconst Loss: 122.74454, KL Div: 11.29021, Total Loss: 134.03474
Epoch[67/100], Step [90/391], Reconst Loss: 115.24153, KL Div: 11.23305, Total Loss: 126.47458
Epoch[67/100], Step [100/391], Reconst Loss: 108.90002, KL Div: 10.94375, Total Loss: 119.84378
Epoch[67/100], Step [110/391], Reconst Loss: 113.30837, KL Div: 11.66557, Total Loss: 124.97394
Epoch[67/100], Step [120/391], Reconst Loss: 117.06297, KL Div: 11.55368, Total Loss: 128.61665
Epoch[67/100], Step [130/391], Reconst Loss: 110.96000, KL Div: 11.39932, Total Loss: 122.35932
Epoch[67/100], Step [140/391], Reconst Loss: 112.99910, KL Div: 11.10418, Total Loss: 124.10328
Epoch[67/100], Step [150/391], Reconst Loss: 114.40408, KL Div: 11.88080, Total Loss: 126.28488
Epoch[67/100], Step [160/391], Reconst Loss: 117.08391, KL Div: 11.67713, Total Loss: 128.76104
Epoch[67/100], Step [170/391], Reconst Loss: 118.09023, KL Div: 11.13472, Total Loss: 129.22495
Epoch[67/100], Step [180/391], Reconst Loss: 115.40022, KL Div: 11.40717, Total Loss: 126.80739
Epoch[67/100], Step [190/391], Reconst Loss: 121.74285, KL Div: 11.88171, Total Loss: 133.62456
Epoch[67/100], Step [200/391], Reconst Loss: 119.03130, KL Div: 11.35626, Total Loss: 130.38755
Epoch[67/100], Step [210/391], Reconst Loss: 112.25063, KL Div: 11.27326, Total Loss: 123.52390
Epoch[67/100], Step [220/391], Reconst Loss: 121.34898, KL Div: 11.61908, Total Loss: 132.96806
Epoch[67/100], Step [230/391], Reconst Loss: 115.72925, KL Div: 11.32551, Total Loss: 127.05476
Epoch[67/100], Step [240/391], Reconst Loss: 113.24898, KL Div: 11.08394, Total Loss: 124.33292
Epoch[67/100], Step [250/391], Reconst Loss: 110.03338, KL Div: 11.45441, Total Loss: 121.48779
Epoch[67/100], Step [260/391], Reconst Loss: 118.58091, KL Div: 10.91862, Total Loss: 129.49953
Epoch[67/100], Step [270/391], Reconst Loss: 114.21423, KL Div: 11.13008, Total Loss: 125.34432
Epoch[67/100], Step [280/391], Reconst Loss: 117.75980, KL Div: 11.39078, Total Loss: 129.15058
Epoch[67/100], Step [290/391], Reconst Loss: 120.29809, KL Div: 11.71106, Total Loss: 132.00914
Epoch[67/100], Step [300/391], Reconst Loss: 111.48572, KL Div: 11.11012, Total Loss: 122.59584
Epoch[67/100], Step [310/391], Reconst Loss: 114.14297, KL Div: 11.67849, Total Loss: 125.82146
Epoch[67/100], Step [320/391], Reconst Loss: 118.09588, KL Div: 11.38170, Total Loss: 129.47758
Epoch[67/100], Step [330/391], Reconst Loss: 115.62132, KL Div: 11.15035, Total Loss: 126.77167
Epoch[67/100], Step [340/391], Reconst Loss: 120.21134, KL Div: 11.21914, Total Loss: 131.43049
Epoch[67/100], Step [350/391], Reconst Loss: 121.14867, KL Div: 11.69251, Total Loss: 132.84118
Epoch[67/100], Step [360/391], Reconst Loss: 115.14131, KL Div: 11.74889, Total Loss: 126.89020
Epoch[67/100], Step [370/391], Reconst Loss: 111.80534, KL Div: 11.46969, Total Loss: 123.27504
Epoch[67/100], Step [380/391], Reconst Loss: 113.85567, KL Div: 11.10658, Total Loss: 124.96224
Epoch[67/100], Step [390/391], Reconst Loss: 110.14279, KL Div: 11.53210, Total Loss: 121.67489
Epoch = 67
Training epoch time =  139.52633714675903
train total loss =  126.4094773828125
valid total loss =  127.59509787597656
Total epoch time =  257.89241671562195
Saving checkpoint...
Done!
Epoch[68/100], Step [10/391], Reconst Loss: 118.49566, KL Div: 11.51566, Total Loss: 130.01132
Epoch[68/100], Step [20/391], Reconst Loss: 119.08797, KL Div: 11.38549, Total Loss: 130.47346
Epoch[68/100], Step [30/391], Reconst Loss: 112.60091, KL Div: 11.25352, Total Loss: 123.85442
Epoch[68/100], Step [40/391], Reconst Loss: 113.41728, KL Div: 11.06812, Total Loss: 124.48540
Epoch[68/100], Step [50/391], Reconst Loss: 115.33723, KL Div: 10.81788, Total Loss: 126.15512
Epoch[68/100], Step [60/391], Reconst Loss: 115.10608, KL Div: 11.12215, Total Loss: 126.22823
Epoch[68/100], Step [70/391], Reconst Loss: 118.81541, KL Div: 11.37554, Total Loss: 130.19096
Epoch[68/100], Step [80/391], Reconst Loss: 111.66861, KL Div: 11.40443, Total Loss: 123.07304
Epoch[68/100], Step [90/391], Reconst Loss: 118.94098, KL Div: 11.22622, Total Loss: 130.16720
Epoch[68/100], Step [100/391], Reconst Loss: 115.14558, KL Div: 11.63859, Total Loss: 126.78416
Epoch[68/100], Step [110/391], Reconst Loss: 115.58171, KL Div: 11.67851, Total Loss: 127.26022
Epoch[68/100], Step [120/391], Reconst Loss: 119.62030, KL Div: 11.54283, Total Loss: 131.16313
Epoch[68/100], Step [130/391], Reconst Loss: 124.93218, KL Div: 11.55499, Total Loss: 136.48717
Epoch[68/100], Step [140/391], Reconst Loss: 119.29410, KL Div: 11.07817, Total Loss: 130.37227
Epoch[68/100], Step [150/391], Reconst Loss: 123.13514, KL Div: 11.45507, Total Loss: 134.59021
Epoch[68/100], Step [160/391], Reconst Loss: 113.51942, KL Div: 11.37457, Total Loss: 124.89398
Epoch[68/100], Step [170/391], Reconst Loss: 116.78780, KL Div: 11.38311, Total Loss: 128.17090
Epoch[68/100], Step [180/391], Reconst Loss: 117.58772, KL Div: 11.32690, Total Loss: 128.91461
Epoch[68/100], Step [190/391], Reconst Loss: 114.87733, KL Div: 11.29297, Total Loss: 126.17030
Epoch[68/100], Step [200/391], Reconst Loss: 116.20976, KL Div: 11.42282, Total Loss: 127.63259
Epoch[68/100], Step [210/391], Reconst Loss: 107.23316, KL Div: 11.84128, Total Loss: 119.07445
Epoch[68/100], Step [220/391], Reconst Loss: 116.75790, KL Div: 10.97006, Total Loss: 127.72796
Epoch[68/100], Step [230/391], Reconst Loss: 117.38727, KL Div: 11.47469, Total Loss: 128.86195
Epoch[68/100], Step [240/391], Reconst Loss: 115.00719, KL Div: 11.32763, Total Loss: 126.33483
Epoch[68/100], Step [250/391], Reconst Loss: 116.05046, KL Div: 11.42655, Total Loss: 127.47701
Epoch[68/100], Step [260/391], Reconst Loss: 120.58422, KL Div: 11.45184, Total Loss: 132.03607
Epoch[68/100], Step [270/391], Reconst Loss: 114.48428, KL Div: 11.46320, Total Loss: 125.94748
Epoch[68/100], Step [280/391], Reconst Loss: 114.37810, KL Div: 11.11109, Total Loss: 125.48919
Epoch[68/100], Step [290/391], Reconst Loss: 116.92183, KL Div: 12.02317, Total Loss: 128.94500
Epoch[68/100], Step [300/391], Reconst Loss: 122.83822, KL Div: 11.62880, Total Loss: 134.46702
Epoch[68/100], Step [310/391], Reconst Loss: 119.10640, KL Div: 11.43911, Total Loss: 130.54551
Epoch[68/100], Step [320/391], Reconst Loss: 115.57767, KL Div: 11.50320, Total Loss: 127.08087
Epoch[68/100], Step [330/391], Reconst Loss: 111.82874, KL Div: 11.50073, Total Loss: 123.32948
Epoch[68/100], Step [340/391], Reconst Loss: 115.89700, KL Div: 11.73084, Total Loss: 127.62784
Epoch[68/100], Step [350/391], Reconst Loss: 113.02395, KL Div: 11.29962, Total Loss: 124.32357
Epoch[68/100], Step [360/391], Reconst Loss: 120.69928, KL Div: 11.51406, Total Loss: 132.21334
Epoch[68/100], Step [370/391], Reconst Loss: 114.71709, KL Div: 11.59768, Total Loss: 126.31478
Epoch[68/100], Step [380/391], Reconst Loss: 112.16386, KL Div: 11.26239, Total Loss: 123.42625
Epoch[68/100], Step [390/391], Reconst Loss: 115.33421, KL Div: 11.25380, Total Loss: 126.58801
Epoch = 68
Training epoch time =  139.15113925933838
train total loss =  126.53830138671874
valid total loss =  127.8235123413086
Total epoch time =  257.6334550380707
Saving checkpoint...
Done!
Epoch[69/100], Step [10/391], Reconst Loss: 119.69083, KL Div: 11.69113, Total Loss: 131.38196
Epoch[69/100], Step [20/391], Reconst Loss: 119.76160, KL Div: 11.58812, Total Loss: 131.34972
Epoch[69/100], Step [30/391], Reconst Loss: 118.54474, KL Div: 11.66916, Total Loss: 130.21390
Epoch[69/100], Step [40/391], Reconst Loss: 116.52420, KL Div: 11.10909, Total Loss: 127.63329
Epoch[69/100], Step [50/391], Reconst Loss: 123.37103, KL Div: 11.71918, Total Loss: 135.09021
Epoch[69/100], Step [60/391], Reconst Loss: 112.48326, KL Div: 11.29584, Total Loss: 123.77910
Epoch[69/100], Step [70/391], Reconst Loss: 111.43999, KL Div: 11.43654, Total Loss: 122.87653
Epoch[69/100], Step [80/391], Reconst Loss: 114.96269, KL Div: 11.27107, Total Loss: 126.23377
Epoch[69/100], Step [90/391], Reconst Loss: 116.41518, KL Div: 11.12112, Total Loss: 127.53630
Epoch[69/100], Step [100/391], Reconst Loss: 119.46057, KL Div: 11.48141, Total Loss: 130.94198
Epoch[69/100], Step [110/391], Reconst Loss: 112.03477, KL Div: 11.49838, Total Loss: 123.53315
Epoch[69/100], Step [120/391], Reconst Loss: 119.75715, KL Div: 11.37006, Total Loss: 131.12721
Epoch[69/100], Step [130/391], Reconst Loss: 117.54440, KL Div: 11.57886, Total Loss: 129.12325
Epoch[69/100], Step [140/391], Reconst Loss: 121.50488, KL Div: 11.55029, Total Loss: 133.05516
Epoch[69/100], Step [150/391], Reconst Loss: 112.77030, KL Div: 11.30589, Total Loss: 124.07619
Epoch[69/100], Step [160/391], Reconst Loss: 113.16376, KL Div: 11.46342, Total Loss: 124.62719
Epoch[69/100], Step [170/391], Reconst Loss: 107.66475, KL Div: 11.43218, Total Loss: 119.09693
Epoch[69/100], Step [180/391], Reconst Loss: 121.09071, KL Div: 11.40432, Total Loss: 132.49504
Epoch[69/100], Step [190/391], Reconst Loss: 117.01665, KL Div: 11.77045, Total Loss: 128.78709
Epoch[69/100], Step [200/391], Reconst Loss: 115.37649, KL Div: 11.79998, Total Loss: 127.17647
Epoch[69/100], Step [210/391], Reconst Loss: 113.77817, KL Div: 11.69289, Total Loss: 125.47106
Epoch[69/100], Step [220/391], Reconst Loss: 112.76950, KL Div: 11.45021, Total Loss: 124.21971
Epoch[69/100], Step [230/391], Reconst Loss: 114.44775, KL Div: 12.01760, Total Loss: 126.46535
Epoch[69/100], Step [240/391], Reconst Loss: 112.33011, KL Div: 11.59683, Total Loss: 123.92694
Epoch[69/100], Step [250/391], Reconst Loss: 118.18439, KL Div: 11.59629, Total Loss: 129.78068
Epoch[69/100], Step [260/391], Reconst Loss: 114.07262, KL Div: 11.51018, Total Loss: 125.58279
Epoch[69/100], Step [270/391], Reconst Loss: 121.10033, KL Div: 11.88386, Total Loss: 132.98418
Epoch[69/100], Step [280/391], Reconst Loss: 115.77463, KL Div: 11.80970, Total Loss: 127.58432
Epoch[69/100], Step [290/391], Reconst Loss: 113.37532, KL Div: 11.48644, Total Loss: 124.86176
Epoch[69/100], Step [300/391], Reconst Loss: 110.91608, KL Div: 11.27426, Total Loss: 122.19034
Epoch[69/100], Step [310/391], Reconst Loss: 116.36763, KL Div: 11.36645, Total Loss: 127.73408
Epoch[69/100], Step [320/391], Reconst Loss: 117.73931, KL Div: 11.30854, Total Loss: 129.04785
Epoch[69/100], Step [330/391], Reconst Loss: 114.41315, KL Div: 11.60266, Total Loss: 126.01581
Epoch[69/100], Step [340/391], Reconst Loss: 120.21763, KL Div: 11.04732, Total Loss: 131.26495
Epoch[69/100], Step [350/391], Reconst Loss: 117.24040, KL Div: 11.69579, Total Loss: 128.93619
Epoch[69/100], Step [360/391], Reconst Loss: 113.27794, KL Div: 11.48134, Total Loss: 124.75928
Epoch[69/100], Step [370/391], Reconst Loss: 114.71591, KL Div: 11.49652, Total Loss: 126.21243
Epoch[69/100], Step [380/391], Reconst Loss: 117.08833, KL Div: 11.17724, Total Loss: 128.26557
Epoch[69/100], Step [390/391], Reconst Loss: 114.86932, KL Div: 11.67049, Total Loss: 126.53981
Epoch = 69
Training epoch time =  139.09413647651672
train total loss =  126.17225771484375
valid total loss =  127.35558908691407
Total epoch time =  257.4213411808014
Saving checkpoint...
Done!
Epoch[70/100], Step [10/391], Reconst Loss: 115.62011, KL Div: 11.31925, Total Loss: 126.93936
Epoch[70/100], Step [20/391], Reconst Loss: 125.32865, KL Div: 11.63450, Total Loss: 136.96315
Epoch[70/100], Step [30/391], Reconst Loss: 114.50671, KL Div: 11.12333, Total Loss: 125.63004
Epoch[70/100], Step [40/391], Reconst Loss: 109.70341, KL Div: 11.31493, Total Loss: 121.01834
Epoch[70/100], Step [50/391], Reconst Loss: 114.33969, KL Div: 11.39323, Total Loss: 125.73292
Epoch[70/100], Step [60/391], Reconst Loss: 117.27711, KL Div: 11.77294, Total Loss: 129.05005
Epoch[70/100], Step [70/391], Reconst Loss: 115.84369, KL Div: 11.35570, Total Loss: 127.19939
Epoch[70/100], Step [80/391], Reconst Loss: 116.90087, KL Div: 11.64306, Total Loss: 128.54393
Epoch[70/100], Step [90/391], Reconst Loss: 113.95694, KL Div: 11.55567, Total Loss: 125.51261
Epoch[70/100], Step [100/391], Reconst Loss: 113.43889, KL Div: 11.54877, Total Loss: 124.98766
Epoch[70/100], Step [110/391], Reconst Loss: 114.80013, KL Div: 11.30589, Total Loss: 126.10601
Epoch[70/100], Step [120/391], Reconst Loss: 119.76562, KL Div: 11.70597, Total Loss: 131.47160
Epoch[70/100], Step [130/391], Reconst Loss: 118.06127, KL Div: 11.15464, Total Loss: 129.21591
Epoch[70/100], Step [140/391], Reconst Loss: 115.79826, KL Div: 11.20544, Total Loss: 127.00369
Epoch[70/100], Step [150/391], Reconst Loss: 118.39774, KL Div: 11.89563, Total Loss: 130.29338
Epoch[70/100], Step [160/391], Reconst Loss: 119.01743, KL Div: 11.48147, Total Loss: 130.49890
Epoch[70/100], Step [170/391], Reconst Loss: 115.36086, KL Div: 10.93432, Total Loss: 126.29518
Epoch[70/100], Step [180/391], Reconst Loss: 116.86581, KL Div: 11.64235, Total Loss: 128.50816
Epoch[70/100], Step [190/391], Reconst Loss: 115.67809, KL Div: 11.17618, Total Loss: 126.85427
Epoch[70/100], Step [200/391], Reconst Loss: 119.77775, KL Div: 11.53846, Total Loss: 131.31621
Epoch[70/100], Step [210/391], Reconst Loss: 117.76826, KL Div: 11.30154, Total Loss: 129.06981
Epoch[70/100], Step [220/391], Reconst Loss: 112.67594, KL Div: 11.10944, Total Loss: 123.78538
Epoch[70/100], Step [230/391], Reconst Loss: 109.90106, KL Div: 11.18930, Total Loss: 121.09036
Epoch[70/100], Step [240/391], Reconst Loss: 121.08239, KL Div: 11.66859, Total Loss: 132.75098
Epoch[70/100], Step [250/391], Reconst Loss: 112.51065, KL Div: 11.72081, Total Loss: 124.23146
Epoch[70/100], Step [260/391], Reconst Loss: 114.63071, KL Div: 11.83333, Total Loss: 126.46404
Epoch[70/100], Step [270/391], Reconst Loss: 116.61195, KL Div: 11.61201, Total Loss: 128.22397
Epoch[70/100], Step [280/391], Reconst Loss: 112.54124, KL Div: 11.57840, Total Loss: 124.11964
Epoch[70/100], Step [290/391], Reconst Loss: 116.01442, KL Div: 11.61597, Total Loss: 127.63039
Epoch[70/100], Step [300/391], Reconst Loss: 121.33447, KL Div: 10.93322, Total Loss: 132.26768
Epoch[70/100], Step [310/391], Reconst Loss: 116.13148, KL Div: 11.66463, Total Loss: 127.79611
Epoch[70/100], Step [320/391], Reconst Loss: 116.63344, KL Div: 11.64019, Total Loss: 128.27363
Epoch[70/100], Step [330/391], Reconst Loss: 119.85835, KL Div: 11.20256, Total Loss: 131.06091
Epoch[70/100], Step [340/391], Reconst Loss: 116.79185, KL Div: 11.53877, Total Loss: 128.33062
Epoch[70/100], Step [350/391], Reconst Loss: 118.34472, KL Div: 12.08694, Total Loss: 130.43166
Epoch[70/100], Step [360/391], Reconst Loss: 115.80209, KL Div: 11.88643, Total Loss: 127.68851
Epoch[70/100], Step [370/391], Reconst Loss: 115.42152, KL Div: 11.94190, Total Loss: 127.36342
Epoch[70/100], Step [380/391], Reconst Loss: 123.49732, KL Div: 11.44815, Total Loss: 134.94547
Epoch[70/100], Step [390/391], Reconst Loss: 119.25757, KL Div: 11.46556, Total Loss: 130.72313
Epoch = 70
Training epoch time =  139.29321718215942
train total loss =  126.41878509765625
valid total loss =  127.73594075927734
Total epoch time =  257.63849782943726
Saving checkpoint...
Done!
Epoch[71/100], Step [10/391], Reconst Loss: 112.46491, KL Div: 11.69885, Total Loss: 124.16376
Epoch[71/100], Step [20/391], Reconst Loss: 113.32287, KL Div: 11.66446, Total Loss: 124.98732
Epoch[71/100], Step [30/391], Reconst Loss: 118.80307, KL Div: 11.52582, Total Loss: 130.32889
Epoch[71/100], Step [40/391], Reconst Loss: 115.27332, KL Div: 11.32661, Total Loss: 126.59992
Epoch[71/100], Step [50/391], Reconst Loss: 117.35310, KL Div: 11.53945, Total Loss: 128.89254
Epoch[71/100], Step [60/391], Reconst Loss: 114.27748, KL Div: 11.30953, Total Loss: 125.58701
Epoch[71/100], Step [70/391], Reconst Loss: 115.05740, KL Div: 11.47447, Total Loss: 126.53188
Epoch[71/100], Step [80/391], Reconst Loss: 118.94115, KL Div: 11.45554, Total Loss: 130.39668
Epoch[71/100], Step [90/391], Reconst Loss: 113.20474, KL Div: 11.27318, Total Loss: 124.47792
Epoch[71/100], Step [100/391], Reconst Loss: 113.79205, KL Div: 11.42602, Total Loss: 125.21806
Epoch[71/100], Step [110/391], Reconst Loss: 118.99119, KL Div: 12.10829, Total Loss: 131.09948
Epoch[71/100], Step [120/391], Reconst Loss: 120.16833, KL Div: 11.83503, Total Loss: 132.00336
Epoch[71/100], Step [130/391], Reconst Loss: 124.54131, KL Div: 11.67634, Total Loss: 136.21764
Epoch[71/100], Step [140/391], Reconst Loss: 116.55069, KL Div: 11.19378, Total Loss: 127.74447
Epoch[71/100], Step [150/391], Reconst Loss: 117.29370, KL Div: 11.82826, Total Loss: 129.12197
Epoch[71/100], Step [160/391], Reconst Loss: 113.98144, KL Div: 11.75088, Total Loss: 125.73231
Epoch[71/100], Step [170/391], Reconst Loss: 116.44369, KL Div: 11.25637, Total Loss: 127.70006
Epoch[71/100], Step [180/391], Reconst Loss: 109.66068, KL Div: 11.52297, Total Loss: 121.18365
Epoch[71/100], Step [190/391], Reconst Loss: 114.93845, KL Div: 11.59018, Total Loss: 126.52862
Epoch[71/100], Step [200/391], Reconst Loss: 114.83913, KL Div: 11.52005, Total Loss: 126.35918
Epoch[71/100], Step [210/391], Reconst Loss: 115.84137, KL Div: 10.99650, Total Loss: 126.83787
Epoch[71/100], Step [220/391], Reconst Loss: 112.63327, KL Div: 11.31361, Total Loss: 123.94688
Epoch[71/100], Step [230/391], Reconst Loss: 114.07426, KL Div: 11.63447, Total Loss: 125.70873
Epoch[71/100], Step [240/391], Reconst Loss: 116.15979, KL Div: 11.49263, Total Loss: 127.65242
Epoch[71/100], Step [250/391], Reconst Loss: 118.34825, KL Div: 11.37522, Total Loss: 129.72347
Epoch[71/100], Step [260/391], Reconst Loss: 112.57134, KL Div: 11.57053, Total Loss: 124.14187
Epoch[71/100], Step [270/391], Reconst Loss: 113.05634, KL Div: 11.37358, Total Loss: 124.42991
Epoch[71/100], Step [280/391], Reconst Loss: 113.08705, KL Div: 11.66948, Total Loss: 124.75653
Epoch[71/100], Step [290/391], Reconst Loss: 115.85175, KL Div: 11.03916, Total Loss: 126.89091
Epoch[71/100], Step [300/391], Reconst Loss: 126.43503, KL Div: 11.79734, Total Loss: 138.23237
Epoch[71/100], Step [310/391], Reconst Loss: 115.79008, KL Div: 11.71592, Total Loss: 127.50600
Epoch[71/100], Step [320/391], Reconst Loss: 122.30309, KL Div: 11.37455, Total Loss: 133.67764
Epoch[71/100], Step [330/391], Reconst Loss: 118.20253, KL Div: 11.56188, Total Loss: 129.76441
Epoch[71/100], Step [340/391], Reconst Loss: 118.15195, KL Div: 11.73650, Total Loss: 129.88844
Epoch[71/100], Step [350/391], Reconst Loss: 115.83897, KL Div: 11.42700, Total Loss: 127.26597
Epoch[71/100], Step [360/391], Reconst Loss: 118.49376, KL Div: 11.42087, Total Loss: 129.91463
Epoch[71/100], Step [370/391], Reconst Loss: 114.19752, KL Div: 10.98747, Total Loss: 125.18499
Epoch[71/100], Step [380/391], Reconst Loss: 119.51396, KL Div: 11.15559, Total Loss: 130.66955
Epoch[71/100], Step [390/391], Reconst Loss: 120.03339, KL Div: 11.59623, Total Loss: 131.62962
Epoch = 71
Training epoch time =  139.71561884880066
train total loss =  126.39292357421876
valid total loss =  127.70165148925781
Total epoch time =  258.0490698814392
Saving checkpoint...
Done!
Epoch[72/100], Step [10/391], Reconst Loss: 115.22141, KL Div: 11.54834, Total Loss: 126.76975
Epoch[72/100], Step [20/391], Reconst Loss: 114.47295, KL Div: 11.33636, Total Loss: 125.80930
Epoch[72/100], Step [30/391], Reconst Loss: 115.91084, KL Div: 11.64504, Total Loss: 127.55587
Epoch[72/100], Step [40/391], Reconst Loss: 113.76867, KL Div: 11.24856, Total Loss: 125.01723
Epoch[72/100], Step [50/391], Reconst Loss: 115.35110, KL Div: 11.84686, Total Loss: 127.19797
Epoch[72/100], Step [60/391], Reconst Loss: 112.26976, KL Div: 11.44268, Total Loss: 123.71244
Epoch[72/100], Step [70/391], Reconst Loss: 118.12070, KL Div: 11.48919, Total Loss: 129.60990
Epoch[72/100], Step [80/391], Reconst Loss: 117.86242, KL Div: 11.78008, Total Loss: 129.64250
Epoch[72/100], Step [90/391], Reconst Loss: 117.50417, KL Div: 12.00605, Total Loss: 129.51021
Epoch[72/100], Step [100/391], Reconst Loss: 116.86368, KL Div: 11.42445, Total Loss: 128.28813
Epoch[72/100], Step [110/391], Reconst Loss: 123.76212, KL Div: 11.88771, Total Loss: 135.64982
Epoch[72/100], Step [120/391], Reconst Loss: 116.01151, KL Div: 11.39437, Total Loss: 127.40588
Epoch[72/100], Step [130/391], Reconst Loss: 114.50027, KL Div: 11.41962, Total Loss: 125.91989
Epoch[72/100], Step [140/391], Reconst Loss: 116.10339, KL Div: 11.56204, Total Loss: 127.66543
Epoch[72/100], Step [150/391], Reconst Loss: 120.01257, KL Div: 11.98151, Total Loss: 131.99408
Epoch[72/100], Step [160/391], Reconst Loss: 114.36620, KL Div: 11.10452, Total Loss: 125.47072
Epoch[72/100], Step [170/391], Reconst Loss: 115.76057, KL Div: 11.24095, Total Loss: 127.00151
Epoch[72/100], Step [180/391], Reconst Loss: 123.01826, KL Div: 11.94791, Total Loss: 134.96617
Epoch[72/100], Step [190/391], Reconst Loss: 116.93896, KL Div: 11.28946, Total Loss: 128.22842
Epoch[72/100], Step [200/391], Reconst Loss: 114.32325, KL Div: 11.86143, Total Loss: 126.18468
Epoch[72/100], Step [210/391], Reconst Loss: 115.08243, KL Div: 11.80624, Total Loss: 126.88866
Epoch[72/100], Step [220/391], Reconst Loss: 111.64229, KL Div: 11.73569, Total Loss: 123.37798
Epoch[72/100], Step [230/391], Reconst Loss: 111.17686, KL Div: 11.52509, Total Loss: 122.70195
Epoch[72/100], Step [240/391], Reconst Loss: 118.56767, KL Div: 11.39840, Total Loss: 129.96607
Epoch[72/100], Step [250/391], Reconst Loss: 116.48028, KL Div: 11.44360, Total Loss: 127.92388
Epoch[72/100], Step [260/391], Reconst Loss: 114.91347, KL Div: 11.51358, Total Loss: 126.42705
Epoch[72/100], Step [270/391], Reconst Loss: 117.70285, KL Div: 11.59226, Total Loss: 129.29511
Epoch[72/100], Step [280/391], Reconst Loss: 111.91066, KL Div: 11.16869, Total Loss: 123.07935
Epoch[72/100], Step [290/391], Reconst Loss: 116.13415, KL Div: 11.65892, Total Loss: 127.79307
Epoch[72/100], Step [300/391], Reconst Loss: 115.67030, KL Div: 11.71887, Total Loss: 127.38917
Epoch[72/100], Step [310/391], Reconst Loss: 113.86487, KL Div: 11.52344, Total Loss: 125.38831
Epoch[72/100], Step [320/391], Reconst Loss: 122.31001, KL Div: 11.75715, Total Loss: 134.06716
Epoch[72/100], Step [330/391], Reconst Loss: 117.08911, KL Div: 11.92014, Total Loss: 129.00926
Epoch[72/100], Step [340/391], Reconst Loss: 115.58614, KL Div: 11.32121, Total Loss: 126.90734
Epoch[72/100], Step [350/391], Reconst Loss: 113.35665, KL Div: 11.51548, Total Loss: 124.87214
Epoch[72/100], Step [360/391], Reconst Loss: 117.34093, KL Div: 11.44924, Total Loss: 128.79017
Epoch[72/100], Step [370/391], Reconst Loss: 108.82851, KL Div: 11.60904, Total Loss: 120.43755
Epoch[72/100], Step [380/391], Reconst Loss: 110.80779, KL Div: 11.29270, Total Loss: 122.10049
Epoch[72/100], Step [390/391], Reconst Loss: 116.14178, KL Div: 11.67796, Total Loss: 127.81975
Epoch = 72
Training epoch time =  139.32677221298218
train total loss =  126.25921142578125
valid total loss =  127.77701193847656
Total epoch time =  257.67041993141174
Saving checkpoint...
Done!
Epoch[73/100], Step [10/391], Reconst Loss: 115.80038, KL Div: 11.28590, Total Loss: 127.08629
Epoch[73/100], Step [20/391], Reconst Loss: 114.43714, KL Div: 11.85099, Total Loss: 126.28813
Epoch[73/100], Step [30/391], Reconst Loss: 112.48077, KL Div: 11.78650, Total Loss: 124.26726
Epoch[73/100], Step [40/391], Reconst Loss: 116.57913, KL Div: 11.63409, Total Loss: 128.21322
Epoch[73/100], Step [50/391], Reconst Loss: 111.48772, KL Div: 11.68922, Total Loss: 123.17693
Epoch[73/100], Step [60/391], Reconst Loss: 112.84817, KL Div: 11.71554, Total Loss: 124.56370
Epoch[73/100], Step [70/391], Reconst Loss: 122.34479, KL Div: 11.56867, Total Loss: 133.91346
Epoch[73/100], Step [80/391], Reconst Loss: 117.38093, KL Div: 11.43682, Total Loss: 128.81775
Epoch[73/100], Step [90/391], Reconst Loss: 121.25403, KL Div: 11.52274, Total Loss: 132.77677
Epoch[73/100], Step [100/391], Reconst Loss: 115.58770, KL Div: 11.77633, Total Loss: 127.36402
Epoch[73/100], Step [110/391], Reconst Loss: 116.31200, KL Div: 11.53180, Total Loss: 127.84380
Epoch[73/100], Step [120/391], Reconst Loss: 118.50784, KL Div: 11.54595, Total Loss: 130.05379
Epoch[73/100], Step [130/391], Reconst Loss: 109.81582, KL Div: 11.72555, Total Loss: 121.54137
Epoch[73/100], Step [140/391], Reconst Loss: 115.78798, KL Div: 11.64930, Total Loss: 127.43728
Epoch[73/100], Step [150/391], Reconst Loss: 118.12924, KL Div: 11.76927, Total Loss: 129.89851
Epoch[73/100], Step [160/391], Reconst Loss: 109.96657, KL Div: 11.68458, Total Loss: 121.65115
Epoch[73/100], Step [170/391], Reconst Loss: 111.02579, KL Div: 11.30024, Total Loss: 122.32603
Epoch[73/100], Step [180/391], Reconst Loss: 110.51276, KL Div: 11.31276, Total Loss: 121.82553
Epoch[73/100], Step [190/391], Reconst Loss: 111.25372, KL Div: 12.14508, Total Loss: 123.39881
Epoch[73/100], Step [200/391], Reconst Loss: 117.77168, KL Div: 11.76183, Total Loss: 129.53351
Epoch[73/100], Step [210/391], Reconst Loss: 115.21922, KL Div: 11.36783, Total Loss: 126.58705
Epoch[73/100], Step [220/391], Reconst Loss: 117.11523, KL Div: 11.60996, Total Loss: 128.72519
Epoch[73/100], Step [230/391], Reconst Loss: 118.86707, KL Div: 11.68502, Total Loss: 130.55209
Epoch[73/100], Step [240/391], Reconst Loss: 116.87617, KL Div: 11.63139, Total Loss: 128.50756
Epoch[73/100], Step [250/391], Reconst Loss: 115.49866, KL Div: 11.92823, Total Loss: 127.42689
Epoch[73/100], Step [260/391], Reconst Loss: 113.78310, KL Div: 11.84594, Total Loss: 125.62905
Epoch[73/100], Step [270/391], Reconst Loss: 118.69652, KL Div: 11.16650, Total Loss: 129.86302
Epoch[73/100], Step [280/391], Reconst Loss: 111.89056, KL Div: 11.60634, Total Loss: 123.49691
Epoch[73/100], Step [290/391], Reconst Loss: 122.74359, KL Div: 11.45830, Total Loss: 134.20189
Epoch[73/100], Step [300/391], Reconst Loss: 114.41936, KL Div: 11.78830, Total Loss: 126.20766
Epoch[73/100], Step [310/391], Reconst Loss: 115.07162, KL Div: 11.61745, Total Loss: 126.68908
Epoch[73/100], Step [320/391], Reconst Loss: 116.70242, KL Div: 11.77115, Total Loss: 128.47357
Epoch[73/100], Step [330/391], Reconst Loss: 114.66856, KL Div: 11.73023, Total Loss: 126.39880
Epoch[73/100], Step [340/391], Reconst Loss: 119.01952, KL Div: 11.65744, Total Loss: 130.67695
Epoch[73/100], Step [350/391], Reconst Loss: 119.48177, KL Div: 11.78346, Total Loss: 131.26522
Epoch[73/100], Step [360/391], Reconst Loss: 114.63818, KL Div: 11.74943, Total Loss: 126.38761
Epoch[73/100], Step [370/391], Reconst Loss: 118.57481, KL Div: 11.89552, Total Loss: 130.47033
Epoch[73/100], Step [380/391], Reconst Loss: 118.84411, KL Div: 11.47640, Total Loss: 130.32051
Epoch[73/100], Step [390/391], Reconst Loss: 119.36660, KL Div: 11.61269, Total Loss: 130.97929
Epoch = 73
Training epoch time =  139.41354203224182
train total loss =  125.81009119140624
valid total loss =  127.3541990966797
Total epoch time =  257.8287789821625
Saving checkpoint...
Done!
Epoch[74/100], Step [10/391], Reconst Loss: 115.78993, KL Div: 11.90034, Total Loss: 127.69027
Epoch[74/100], Step [20/391], Reconst Loss: 110.19667, KL Div: 11.72676, Total Loss: 121.92343
Epoch[74/100], Step [30/391], Reconst Loss: 110.71485, KL Div: 11.69798, Total Loss: 122.41283
Epoch[74/100], Step [40/391], Reconst Loss: 107.39445, KL Div: 11.88011, Total Loss: 119.27457
Epoch[74/100], Step [50/391], Reconst Loss: 109.26009, KL Div: 11.60354, Total Loss: 120.86363
Epoch[74/100], Step [60/391], Reconst Loss: 119.77391, KL Div: 11.64677, Total Loss: 131.42068
Epoch[74/100], Step [70/391], Reconst Loss: 116.03231, KL Div: 11.57584, Total Loss: 127.60815
Epoch[74/100], Step [80/391], Reconst Loss: 111.03339, KL Div: 11.51615, Total Loss: 122.54953
Epoch[74/100], Step [90/391], Reconst Loss: 112.72806, KL Div: 11.83342, Total Loss: 124.56148
Epoch[74/100], Step [100/391], Reconst Loss: 118.63889, KL Div: 11.27025, Total Loss: 129.90913
Epoch[74/100], Step [110/391], Reconst Loss: 122.35986, KL Div: 11.64138, Total Loss: 134.00124
Epoch[74/100], Step [120/391], Reconst Loss: 115.43829, KL Div: 11.34930, Total Loss: 126.78759
Epoch[74/100], Step [130/391], Reconst Loss: 115.26517, KL Div: 11.29703, Total Loss: 126.56220
Epoch[74/100], Step [140/391], Reconst Loss: 118.06836, KL Div: 11.60563, Total Loss: 129.67399
Epoch[74/100], Step [150/391], Reconst Loss: 106.72383, KL Div: 10.76133, Total Loss: 117.48517
Epoch[74/100], Step [160/391], Reconst Loss: 110.50099, KL Div: 11.39978, Total Loss: 121.90077
Epoch[74/100], Step [170/391], Reconst Loss: 113.83653, KL Div: 11.23227, Total Loss: 125.06880
Epoch[74/100], Step [180/391], Reconst Loss: 118.89082, KL Div: 11.55069, Total Loss: 130.44151
Epoch[74/100], Step [190/391], Reconst Loss: 119.07562, KL Div: 11.78734, Total Loss: 130.86296
Epoch[74/100], Step [200/391], Reconst Loss: 115.98628, KL Div: 11.20879, Total Loss: 127.19507
Epoch[74/100], Step [210/391], Reconst Loss: 112.68533, KL Div: 11.31635, Total Loss: 124.00169
Epoch[74/100], Step [220/391], Reconst Loss: 119.28162, KL Div: 11.17629, Total Loss: 130.45790
Epoch[74/100], Step [230/391], Reconst Loss: 111.23901, KL Div: 12.05845, Total Loss: 123.29746
Epoch[74/100], Step [240/391], Reconst Loss: 111.01645, KL Div: 11.04534, Total Loss: 122.06179
Epoch[74/100], Step [250/391], Reconst Loss: 115.75456, KL Div: 11.32918, Total Loss: 127.08375
Epoch[74/100], Step [260/391], Reconst Loss: 116.23844, KL Div: 11.51816, Total Loss: 127.75660
Epoch[74/100], Step [270/391], Reconst Loss: 118.06976, KL Div: 11.26596, Total Loss: 129.33572
Epoch[74/100], Step [280/391], Reconst Loss: 113.25793, KL Div: 11.45087, Total Loss: 124.70881
Epoch[74/100], Step [290/391], Reconst Loss: 115.76366, KL Div: 11.25974, Total Loss: 127.02340
Epoch[74/100], Step [300/391], Reconst Loss: 120.53130, KL Div: 11.23941, Total Loss: 131.77071
Epoch[74/100], Step [310/391], Reconst Loss: 117.61179, KL Div: 11.85142, Total Loss: 129.46322
Epoch[74/100], Step [320/391], Reconst Loss: 119.06573, KL Div: 11.50418, Total Loss: 130.56991
Epoch[74/100], Step [330/391], Reconst Loss: 121.93696, KL Div: 11.71077, Total Loss: 133.64773
Epoch[74/100], Step [340/391], Reconst Loss: 115.76198, KL Div: 11.58024, Total Loss: 127.34222
Epoch[74/100], Step [350/391], Reconst Loss: 112.35459, KL Div: 11.68578, Total Loss: 124.04037
Epoch[74/100], Step [360/391], Reconst Loss: 110.21977, KL Div: 11.55129, Total Loss: 121.77106
Epoch[74/100], Step [370/391], Reconst Loss: 108.98499, KL Div: 11.34081, Total Loss: 120.32580
Epoch[74/100], Step [380/391], Reconst Loss: 114.02831, KL Div: 11.05254, Total Loss: 125.08084
Epoch[74/100], Step [390/391], Reconst Loss: 116.32984, KL Div: 11.12762, Total Loss: 127.45747
Epoch = 74
Training epoch time =  138.9447250366211
train total loss =  126.24795169921875
valid total loss =  127.77689650878906
Total epoch time =  257.7098157405853
Saving checkpoint...
Done!
Epoch[75/100], Step [10/391], Reconst Loss: 118.22028, KL Div: 11.86444, Total Loss: 130.08472
Epoch[75/100], Step [20/391], Reconst Loss: 117.02029, KL Div: 11.44489, Total Loss: 128.46519
Epoch[75/100], Step [30/391], Reconst Loss: 115.82665, KL Div: 11.50421, Total Loss: 127.33087
Epoch[75/100], Step [40/391], Reconst Loss: 117.12372, KL Div: 11.65948, Total Loss: 128.78320
Epoch[75/100], Step [50/391], Reconst Loss: 111.52066, KL Div: 11.17559, Total Loss: 122.69625
Epoch[75/100], Step [60/391], Reconst Loss: 112.77314, KL Div: 11.13672, Total Loss: 123.90986
Epoch[75/100], Step [70/391], Reconst Loss: 114.34978, KL Div: 11.14603, Total Loss: 125.49581
Epoch[75/100], Step [80/391], Reconst Loss: 111.95726, KL Div: 11.63757, Total Loss: 123.59483
Epoch[75/100], Step [90/391], Reconst Loss: 114.11395, KL Div: 11.07400, Total Loss: 125.18795
Epoch[75/100], Step [100/391], Reconst Loss: 115.39680, KL Div: 10.90391, Total Loss: 126.30071
Epoch[75/100], Step [110/391], Reconst Loss: 115.72897, KL Div: 11.39087, Total Loss: 127.11984
Epoch[75/100], Step [120/391], Reconst Loss: 118.84957, KL Div: 11.67315, Total Loss: 130.52272
Epoch[75/100], Step [130/391], Reconst Loss: 120.93523, KL Div: 11.43422, Total Loss: 132.36946
Epoch[75/100], Step [140/391], Reconst Loss: 115.57120, KL Div: 11.70674, Total Loss: 127.27794
Epoch[75/100], Step [150/391], Reconst Loss: 111.06495, KL Div: 10.94224, Total Loss: 122.00718
Epoch[75/100], Step [160/391], Reconst Loss: 115.70042, KL Div: 11.32947, Total Loss: 127.02989
Epoch[75/100], Step [170/391], Reconst Loss: 116.44756, KL Div: 11.29551, Total Loss: 127.74306
Epoch[75/100], Step [180/391], Reconst Loss: 117.03647, KL Div: 11.70717, Total Loss: 128.74364
Epoch[75/100], Step [190/391], Reconst Loss: 115.07208, KL Div: 11.53841, Total Loss: 126.61049
Epoch[75/100], Step [200/391], Reconst Loss: 116.90177, KL Div: 11.57612, Total Loss: 128.47790
Epoch[75/100], Step [210/391], Reconst Loss: 115.33845, KL Div: 11.06106, Total Loss: 126.39951
Epoch[75/100], Step [220/391], Reconst Loss: 128.60718, KL Div: 10.88315, Total Loss: 139.49033
Epoch[75/100], Step [230/391], Reconst Loss: 116.10638, KL Div: 11.10858, Total Loss: 127.21496
Epoch[75/100], Step [240/391], Reconst Loss: 116.83897, KL Div: 11.65096, Total Loss: 128.48993
Epoch[75/100], Step [250/391], Reconst Loss: 114.80347, KL Div: 11.70504, Total Loss: 126.50852
Epoch[75/100], Step [260/391], Reconst Loss: 112.33099, KL Div: 11.11274, Total Loss: 123.44373
Epoch[75/100], Step [270/391], Reconst Loss: 113.22009, KL Div: 11.66695, Total Loss: 124.88703
Epoch[75/100], Step [280/391], Reconst Loss: 116.34247, KL Div: 11.34798, Total Loss: 127.69045
Epoch[75/100], Step [290/391], Reconst Loss: 115.56277, KL Div: 11.43175, Total Loss: 126.99451
Epoch[75/100], Step [300/391], Reconst Loss: 114.03436, KL Div: 11.66511, Total Loss: 125.69947
Epoch[75/100], Step [310/391], Reconst Loss: 118.35422, KL Div: 11.32243, Total Loss: 129.67665
Epoch[75/100], Step [320/391], Reconst Loss: 111.32025, KL Div: 11.69380, Total Loss: 123.01405
Epoch[75/100], Step [330/391], Reconst Loss: 113.16587, KL Div: 11.72689, Total Loss: 124.89276
Epoch[75/100], Step [340/391], Reconst Loss: 118.13619, KL Div: 11.32118, Total Loss: 129.45737
Epoch[75/100], Step [350/391], Reconst Loss: 119.36871, KL Div: 11.55865, Total Loss: 130.92736
Epoch[75/100], Step [360/391], Reconst Loss: 115.20414, KL Div: 11.29798, Total Loss: 126.50212
Epoch[75/100], Step [370/391], Reconst Loss: 118.46799, KL Div: 11.39886, Total Loss: 129.86686
Epoch[75/100], Step [380/391], Reconst Loss: 115.88050, KL Div: 11.59334, Total Loss: 127.47384
Epoch[75/100], Step [390/391], Reconst Loss: 117.13659, KL Div: 11.52265, Total Loss: 128.65924
Epoch = 75
Training epoch time =  139.48819828033447
train total loss =  126.51723888671874
valid total loss =  128.08810107421874
Total epoch time =  257.8249464035034
Saving checkpoint...
Done!
Epoch[76/100], Step [10/391], Reconst Loss: 113.98989, KL Div: 11.26491, Total Loss: 125.25480
Epoch[76/100], Step [20/391], Reconst Loss: 119.03297, KL Div: 11.44780, Total Loss: 130.48077
Epoch[76/100], Step [30/391], Reconst Loss: 111.98234, KL Div: 11.65007, Total Loss: 123.63241
Epoch[76/100], Step [40/391], Reconst Loss: 120.28593, KL Div: 11.32090, Total Loss: 131.60683
Epoch[76/100], Step [50/391], Reconst Loss: 116.30740, KL Div: 11.68109, Total Loss: 127.98849
Epoch[76/100], Step [60/391], Reconst Loss: 114.40497, KL Div: 11.08371, Total Loss: 125.48867
Epoch[76/100], Step [70/391], Reconst Loss: 118.94498, KL Div: 11.41416, Total Loss: 130.35914
Epoch[76/100], Step [80/391], Reconst Loss: 119.52099, KL Div: 11.63672, Total Loss: 131.15770
Epoch[76/100], Step [90/391], Reconst Loss: 117.61171, KL Div: 11.64300, Total Loss: 129.25471
Epoch[76/100], Step [100/391], Reconst Loss: 117.65796, KL Div: 11.11906, Total Loss: 128.77701
Epoch[76/100], Step [110/391], Reconst Loss: 114.07184, KL Div: 11.30165, Total Loss: 125.37349
Epoch[76/100], Step [120/391], Reconst Loss: 112.20053, KL Div: 11.70894, Total Loss: 123.90947
Epoch[76/100], Step [130/391], Reconst Loss: 109.53015, KL Div: 11.14839, Total Loss: 120.67854
Epoch[76/100], Step [140/391], Reconst Loss: 118.90424, KL Div: 11.26409, Total Loss: 130.16833
Epoch[76/100], Step [150/391], Reconst Loss: 114.95799, KL Div: 11.29702, Total Loss: 126.25501
Epoch[76/100], Step [160/391], Reconst Loss: 117.98052, KL Div: 11.72290, Total Loss: 129.70343
Epoch[76/100], Step [170/391], Reconst Loss: 124.06519, KL Div: 11.20709, Total Loss: 135.27228
Epoch[76/100], Step [180/391], Reconst Loss: 112.93570, KL Div: 11.18077, Total Loss: 124.11647
Epoch[76/100], Step [190/391], Reconst Loss: 113.57788, KL Div: 11.64544, Total Loss: 125.22332
Epoch[76/100], Step [200/391], Reconst Loss: 114.43568, KL Div: 11.22389, Total Loss: 125.65957
Epoch[76/100], Step [210/391], Reconst Loss: 111.83786, KL Div: 11.49714, Total Loss: 123.33500
Epoch[76/100], Step [220/391], Reconst Loss: 117.48006, KL Div: 11.36364, Total Loss: 128.84370
Epoch[76/100], Step [230/391], Reconst Loss: 117.46475, KL Div: 11.66019, Total Loss: 129.12494
Epoch[76/100], Step [240/391], Reconst Loss: 115.77219, KL Div: 11.71384, Total Loss: 127.48602
Epoch[76/100], Step [250/391], Reconst Loss: 114.75659, KL Div: 11.33345, Total Loss: 126.09004
Epoch[76/100], Step [260/391], Reconst Loss: 117.79444, KL Div: 11.42189, Total Loss: 129.21633
Epoch[76/100], Step [270/391], Reconst Loss: 113.76226, KL Div: 11.50849, Total Loss: 125.27075
Epoch[76/100], Step [280/391], Reconst Loss: 114.50111, KL Div: 11.88396, Total Loss: 126.38507
Epoch[76/100], Step [290/391], Reconst Loss: 121.63640, KL Div: 11.77723, Total Loss: 133.41363
Epoch[76/100], Step [300/391], Reconst Loss: 112.49184, KL Div: 11.33249, Total Loss: 123.82433
Epoch[76/100], Step [310/391], Reconst Loss: 121.80020, KL Div: 11.73968, Total Loss: 133.53988
Epoch[76/100], Step [320/391], Reconst Loss: 116.46088, KL Div: 11.30678, Total Loss: 127.76766
Epoch[76/100], Step [330/391], Reconst Loss: 114.89040, KL Div: 11.83382, Total Loss: 126.72421
Epoch[76/100], Step [340/391], Reconst Loss: 114.94093, KL Div: 11.48050, Total Loss: 126.42143
Epoch[76/100], Step [350/391], Reconst Loss: 117.65697, KL Div: 11.18830, Total Loss: 128.84527
Epoch[76/100], Step [360/391], Reconst Loss: 114.51248, KL Div: 11.90458, Total Loss: 126.41706
Epoch[76/100], Step [370/391], Reconst Loss: 119.23454, KL Div: 11.93241, Total Loss: 131.16695
Epoch[76/100], Step [380/391], Reconst Loss: 116.15648, KL Div: 11.24778, Total Loss: 127.40426
Epoch[76/100], Step [390/391], Reconst Loss: 110.77067, KL Div: 11.76446, Total Loss: 122.53513
Epoch = 76
Training epoch time =  139.40119647979736
train total loss =  125.9082219140625
valid total loss =  127.34954851074218
Total epoch time =  257.51683473587036
Saving checkpoint...
Done!
Epoch[77/100], Step [10/391], Reconst Loss: 110.36012, KL Div: 11.12813, Total Loss: 121.48824
Epoch[77/100], Step [20/391], Reconst Loss: 119.49380, KL Div: 11.85442, Total Loss: 131.34822
Epoch[77/100], Step [30/391], Reconst Loss: 118.74586, KL Div: 11.62247, Total Loss: 130.36833
Epoch[77/100], Step [40/391], Reconst Loss: 110.12173, KL Div: 11.64685, Total Loss: 121.76858
Epoch[77/100], Step [50/391], Reconst Loss: 115.74593, KL Div: 11.26322, Total Loss: 127.00915
Epoch[77/100], Step [60/391], Reconst Loss: 113.85426, KL Div: 11.33234, Total Loss: 125.18661
Epoch[77/100], Step [70/391], Reconst Loss: 118.14325, KL Div: 11.66250, Total Loss: 129.80575
Epoch[77/100], Step [80/391], Reconst Loss: 112.44330, KL Div: 11.78831, Total Loss: 124.23161
Epoch[77/100], Step [90/391], Reconst Loss: 121.52262, KL Div: 11.81138, Total Loss: 133.33400
Epoch[77/100], Step [100/391], Reconst Loss: 116.07098, KL Div: 11.09654, Total Loss: 127.16752
Epoch[77/100], Step [110/391], Reconst Loss: 117.52425, KL Div: 11.77187, Total Loss: 129.29613
Epoch[77/100], Step [120/391], Reconst Loss: 111.40458, KL Div: 11.50721, Total Loss: 122.91179
Epoch[77/100], Step [130/391], Reconst Loss: 118.20202, KL Div: 11.55767, Total Loss: 129.75969
Epoch[77/100], Step [140/391], Reconst Loss: 112.03352, KL Div: 11.36574, Total Loss: 123.39926
Epoch[77/100], Step [150/391], Reconst Loss: 118.08923, KL Div: 11.89635, Total Loss: 129.98559
Epoch[77/100], Step [160/391], Reconst Loss: 117.64103, KL Div: 11.89020, Total Loss: 129.53123
Epoch[77/100], Step [170/391], Reconst Loss: 109.82085, KL Div: 11.86016, Total Loss: 121.68100
Epoch[77/100], Step [180/391], Reconst Loss: 118.42635, KL Div: 11.76506, Total Loss: 130.19140
Epoch[77/100], Step [190/391], Reconst Loss: 114.66231, KL Div: 11.48368, Total Loss: 126.14599
Epoch[77/100], Step [200/391], Reconst Loss: 116.82121, KL Div: 11.45350, Total Loss: 128.27471
Epoch[77/100], Step [210/391], Reconst Loss: 114.70953, KL Div: 11.53146, Total Loss: 126.24098
Epoch[77/100], Step [220/391], Reconst Loss: 111.42271, KL Div: 11.69858, Total Loss: 123.12128
Epoch[77/100], Step [230/391], Reconst Loss: 109.74695, KL Div: 11.54003, Total Loss: 121.28698
Epoch[77/100], Step [240/391], Reconst Loss: 111.11435, KL Div: 11.31656, Total Loss: 122.43091
Epoch[77/100], Step [250/391], Reconst Loss: 113.86923, KL Div: 11.43578, Total Loss: 125.30501
Epoch[77/100], Step [260/391], Reconst Loss: 108.06208, KL Div: 11.27986, Total Loss: 119.34194
Epoch[77/100], Step [270/391], Reconst Loss: 121.82562, KL Div: 11.34462, Total Loss: 133.17024
Epoch[77/100], Step [280/391], Reconst Loss: 105.43886, KL Div: 11.24262, Total Loss: 116.68147
Epoch[77/100], Step [290/391], Reconst Loss: 117.08403, KL Div: 11.45169, Total Loss: 128.53572
Epoch[77/100], Step [300/391], Reconst Loss: 114.03365, KL Div: 11.33289, Total Loss: 125.36653
Epoch[77/100], Step [310/391], Reconst Loss: 111.38712, KL Div: 11.65586, Total Loss: 123.04297
Epoch[77/100], Step [320/391], Reconst Loss: 111.50401, KL Div: 11.13001, Total Loss: 122.63403
Epoch[77/100], Step [330/391], Reconst Loss: 116.98660, KL Div: 11.32240, Total Loss: 128.30900
Epoch[77/100], Step [340/391], Reconst Loss: 117.32955, KL Div: 11.42433, Total Loss: 128.75388
Epoch[77/100], Step [350/391], Reconst Loss: 116.01130, KL Div: 11.40200, Total Loss: 127.41330
Epoch[77/100], Step [360/391], Reconst Loss: 118.39143, KL Div: 11.61370, Total Loss: 130.00512
Epoch[77/100], Step [370/391], Reconst Loss: 117.14558, KL Div: 11.74955, Total Loss: 128.89513
Epoch[77/100], Step [380/391], Reconst Loss: 112.84312, KL Div: 11.40829, Total Loss: 124.25141
Epoch[77/100], Step [390/391], Reconst Loss: 113.10715, KL Div: 11.32533, Total Loss: 124.43248
Epoch = 77
Training epoch time =  139.19404673576355
train total loss =  125.5455603515625
valid total loss =  127.12833098144532
Total epoch time =  257.4095504283905
Saving checkpoint...
Done!
Epoch[78/100], Step [10/391], Reconst Loss: 118.95509, KL Div: 11.42410, Total Loss: 130.37919
Epoch[78/100], Step [20/391], Reconst Loss: 113.30289, KL Div: 11.60328, Total Loss: 124.90616
Epoch[78/100], Step [30/391], Reconst Loss: 119.84003, KL Div: 11.40075, Total Loss: 131.24077
Epoch[78/100], Step [40/391], Reconst Loss: 115.41786, KL Div: 11.58953, Total Loss: 127.00739
Epoch[78/100], Step [50/391], Reconst Loss: 117.90758, KL Div: 10.97403, Total Loss: 128.88160
Epoch[78/100], Step [60/391], Reconst Loss: 119.06194, KL Div: 11.45655, Total Loss: 130.51849
Epoch[78/100], Step [70/391], Reconst Loss: 115.94099, KL Div: 10.99464, Total Loss: 126.93564
Epoch[78/100], Step [80/391], Reconst Loss: 116.89959, KL Div: 11.59661, Total Loss: 128.49620
Epoch[78/100], Step [90/391], Reconst Loss: 118.52793, KL Div: 11.47192, Total Loss: 129.99985
Epoch[78/100], Step [100/391], Reconst Loss: 115.29014, KL Div: 11.92259, Total Loss: 127.21273
Epoch[78/100], Step [110/391], Reconst Loss: 113.85211, KL Div: 11.33520, Total Loss: 125.18731
Epoch[78/100], Step [120/391], Reconst Loss: 114.09788, KL Div: 11.64159, Total Loss: 125.73947
Epoch[78/100], Step [130/391], Reconst Loss: 114.28729, KL Div: 11.38807, Total Loss: 125.67536
Epoch[78/100], Step [140/391], Reconst Loss: 119.88895, KL Div: 11.55891, Total Loss: 131.44786
Epoch[78/100], Step [150/391], Reconst Loss: 115.93230, KL Div: 11.62018, Total Loss: 127.55248
Epoch[78/100], Step [160/391], Reconst Loss: 117.80469, KL Div: 11.51978, Total Loss: 129.32447
Epoch[78/100], Step [170/391], Reconst Loss: 118.61766, KL Div: 11.18064, Total Loss: 129.79830
Epoch[78/100], Step [180/391], Reconst Loss: 112.06164, KL Div: 11.38645, Total Loss: 123.44809
Epoch[78/100], Step [190/391], Reconst Loss: 115.97154, KL Div: 11.69920, Total Loss: 127.67074
Epoch[78/100], Step [200/391], Reconst Loss: 114.66437, KL Div: 11.96684, Total Loss: 126.63121
Epoch[78/100], Step [210/391], Reconst Loss: 113.86869, KL Div: 11.26463, Total Loss: 125.13332
Epoch[78/100], Step [220/391], Reconst Loss: 115.02273, KL Div: 11.47339, Total Loss: 126.49612
Epoch[78/100], Step [230/391], Reconst Loss: 117.20865, KL Div: 11.93717, Total Loss: 129.14582
Epoch[78/100], Step [240/391], Reconst Loss: 115.71075, KL Div: 11.66337, Total Loss: 127.37413
Epoch[78/100], Step [250/391], Reconst Loss: 119.26749, KL Div: 11.12154, Total Loss: 130.38903
Epoch[78/100], Step [260/391], Reconst Loss: 114.28339, KL Div: 11.30290, Total Loss: 125.58628
Epoch[78/100], Step [270/391], Reconst Loss: 114.03712, KL Div: 11.84340, Total Loss: 125.88052
Epoch[78/100], Step [280/391], Reconst Loss: 114.40434, KL Div: 11.56737, Total Loss: 125.97170
Epoch[78/100], Step [290/391], Reconst Loss: 116.47131, KL Div: 11.19686, Total Loss: 127.66817
Epoch[78/100], Step [300/391], Reconst Loss: 114.56193, KL Div: 11.73170, Total Loss: 126.29363
Epoch[78/100], Step [310/391], Reconst Loss: 115.55489, KL Div: 11.45910, Total Loss: 127.01399
Epoch[78/100], Step [320/391], Reconst Loss: 112.96880, KL Div: 11.24691, Total Loss: 124.21571
Epoch[78/100], Step [330/391], Reconst Loss: 114.67352, KL Div: 11.42254, Total Loss: 126.09605
Epoch[78/100], Step [340/391], Reconst Loss: 115.92619, KL Div: 11.54255, Total Loss: 127.46873
Epoch[78/100], Step [350/391], Reconst Loss: 112.70152, KL Div: 11.78313, Total Loss: 124.48465
Epoch[78/100], Step [360/391], Reconst Loss: 112.20183, KL Div: 11.56859, Total Loss: 123.77042
Epoch[78/100], Step [370/391], Reconst Loss: 112.68855, KL Div: 11.23346, Total Loss: 123.92200
Epoch[78/100], Step [380/391], Reconst Loss: 119.91675, KL Div: 11.41397, Total Loss: 131.33071
Epoch[78/100], Step [390/391], Reconst Loss: 118.22906, KL Div: 11.87791, Total Loss: 130.10696
Epoch = 78
Training epoch time =  139.1832151412964
train total loss =  125.63711236328125
valid total loss =  127.1414359375
Total epoch time =  257.1589996814728
Saving checkpoint...
Done!
Epoch[79/100], Step [10/391], Reconst Loss: 113.87447, KL Div: 11.77837, Total Loss: 125.65283
Epoch[79/100], Step [20/391], Reconst Loss: 114.27392, KL Div: 11.72627, Total Loss: 126.00019
Epoch[79/100], Step [30/391], Reconst Loss: 109.96391, KL Div: 11.41082, Total Loss: 121.37473
Epoch[79/100], Step [40/391], Reconst Loss: 116.04925, KL Div: 11.49326, Total Loss: 127.54251
Epoch[79/100], Step [50/391], Reconst Loss: 111.67380, KL Div: 11.62535, Total Loss: 123.29915
Epoch[79/100], Step [60/391], Reconst Loss: 115.85599, KL Div: 11.13828, Total Loss: 126.99427
Epoch[79/100], Step [70/391], Reconst Loss: 119.82442, KL Div: 11.56948, Total Loss: 131.39390
Epoch[79/100], Step [80/391], Reconst Loss: 115.56384, KL Div: 11.45347, Total Loss: 127.01731
Epoch[79/100], Step [90/391], Reconst Loss: 113.79079, KL Div: 11.16154, Total Loss: 124.95233
Epoch[79/100], Step [100/391], Reconst Loss: 119.48460, KL Div: 11.71169, Total Loss: 131.19629
Epoch[79/100], Step [110/391], Reconst Loss: 114.25903, KL Div: 11.49804, Total Loss: 125.75707
Epoch[79/100], Step [120/391], Reconst Loss: 116.45665, KL Div: 11.25537, Total Loss: 127.71202
Epoch[79/100], Step [130/391], Reconst Loss: 117.89622, KL Div: 11.63589, Total Loss: 129.53211
Epoch[79/100], Step [140/391], Reconst Loss: 117.99634, KL Div: 11.21254, Total Loss: 129.20888
Epoch[79/100], Step [150/391], Reconst Loss: 114.54134, KL Div: 11.45141, Total Loss: 125.99274
Epoch[79/100], Step [160/391], Reconst Loss: 112.18403, KL Div: 11.34374, Total Loss: 123.52777
Epoch[79/100], Step [170/391], Reconst Loss: 117.55901, KL Div: 10.99954, Total Loss: 128.55855
Epoch[79/100], Step [180/391], Reconst Loss: 112.37618, KL Div: 11.77878, Total Loss: 124.15496
Epoch[79/100], Step [190/391], Reconst Loss: 115.72755, KL Div: 11.68944, Total Loss: 127.41698
Epoch[79/100], Step [200/391], Reconst Loss: 116.73322, KL Div: 11.45670, Total Loss: 128.18992
Epoch[79/100], Step [210/391], Reconst Loss: 110.11141, KL Div: 11.16564, Total Loss: 121.27705
Epoch[79/100], Step [220/391], Reconst Loss: 117.24323, KL Div: 11.43370, Total Loss: 128.67693
Epoch[79/100], Step [230/391], Reconst Loss: 117.12167, KL Div: 11.37640, Total Loss: 128.49807
Epoch[79/100], Step [240/391], Reconst Loss: 118.67624, KL Div: 11.66795, Total Loss: 130.34419
Epoch[79/100], Step [250/391], Reconst Loss: 115.68046, KL Div: 11.82289, Total Loss: 127.50335
Epoch[79/100], Step [260/391], Reconst Loss: 119.35611, KL Div: 10.91720, Total Loss: 130.27331
Epoch[79/100], Step [270/391], Reconst Loss: 114.43203, KL Div: 11.39562, Total Loss: 125.82765
Epoch[79/100], Step [280/391], Reconst Loss: 120.84789, KL Div: 11.63544, Total Loss: 132.48332
Epoch[79/100], Step [290/391], Reconst Loss: 114.80753, KL Div: 11.17744, Total Loss: 125.98496
Epoch[79/100], Step [300/391], Reconst Loss: 112.24594, KL Div: 11.05240, Total Loss: 123.29834
Epoch[79/100], Step [310/391], Reconst Loss: 110.61238, KL Div: 11.86106, Total Loss: 122.47344
Epoch[79/100], Step [320/391], Reconst Loss: 110.99847, KL Div: 11.22225, Total Loss: 122.22073
Epoch[79/100], Step [330/391], Reconst Loss: 120.45432, KL Div: 11.20315, Total Loss: 131.65746
Epoch[79/100], Step [340/391], Reconst Loss: 115.36371, KL Div: 10.94684, Total Loss: 126.31055
Epoch[79/100], Step [350/391], Reconst Loss: 119.43208, KL Div: 11.18891, Total Loss: 130.62099
Epoch[79/100], Step [360/391], Reconst Loss: 112.26588, KL Div: 11.54776, Total Loss: 123.81364
Epoch[79/100], Step [370/391], Reconst Loss: 119.04384, KL Div: 11.96448, Total Loss: 131.00832
Epoch[79/100], Step [380/391], Reconst Loss: 114.67559, KL Div: 11.06232, Total Loss: 125.73791
Epoch[79/100], Step [390/391], Reconst Loss: 115.04514, KL Div: 11.53626, Total Loss: 126.58139
Epoch = 79
Training epoch time =  139.30604076385498
train total loss =  125.9566394921875
valid total loss =  127.4230427734375
Total epoch time =  257.6054103374481
Saving checkpoint...
Done!
Epoch[80/100], Step [10/391], Reconst Loss: 113.78072, KL Div: 11.35550, Total Loss: 125.13621
Epoch[80/100], Step [20/391], Reconst Loss: 120.70444, KL Div: 10.95734, Total Loss: 131.66178
Epoch[80/100], Step [30/391], Reconst Loss: 114.96869, KL Div: 11.42512, Total Loss: 126.39380
Epoch[80/100], Step [40/391], Reconst Loss: 113.52673, KL Div: 11.78003, Total Loss: 125.30676
Epoch[80/100], Step [50/391], Reconst Loss: 118.20421, KL Div: 11.56344, Total Loss: 129.76765
Epoch[80/100], Step [60/391], Reconst Loss: 112.97702, KL Div: 10.86938, Total Loss: 123.84640
Epoch[80/100], Step [70/391], Reconst Loss: 123.28946, KL Div: 11.37958, Total Loss: 134.66904
Epoch[80/100], Step [80/391], Reconst Loss: 115.62277, KL Div: 11.78691, Total Loss: 127.40968
Epoch[80/100], Step [90/391], Reconst Loss: 117.12868, KL Div: 11.29050, Total Loss: 128.41918
Epoch[80/100], Step [100/391], Reconst Loss: 110.05309, KL Div: 11.13998, Total Loss: 121.19307
Epoch[80/100], Step [110/391], Reconst Loss: 117.26820, KL Div: 11.28640, Total Loss: 128.55460
Epoch[80/100], Step [120/391], Reconst Loss: 121.61510, KL Div: 11.27328, Total Loss: 132.88838
Epoch[80/100], Step [130/391], Reconst Loss: 118.49915, KL Div: 10.93958, Total Loss: 129.43872
Epoch[80/100], Step [140/391], Reconst Loss: 121.54333, KL Div: 11.22244, Total Loss: 132.76577
Epoch[80/100], Step [150/391], Reconst Loss: 109.20478, KL Div: 11.32551, Total Loss: 120.53029
Epoch[80/100], Step [160/391], Reconst Loss: 115.84729, KL Div: 11.21890, Total Loss: 127.06619
Epoch[80/100], Step [170/391], Reconst Loss: 115.05851, KL Div: 11.47614, Total Loss: 126.53465
Epoch[80/100], Step [180/391], Reconst Loss: 121.01473, KL Div: 11.70308, Total Loss: 132.71781
Epoch[80/100], Step [190/391], Reconst Loss: 120.01945, KL Div: 11.35905, Total Loss: 131.37851
Epoch[80/100], Step [200/391], Reconst Loss: 117.63040, KL Div: 10.97918, Total Loss: 128.60959
Epoch[80/100], Step [210/391], Reconst Loss: 119.78632, KL Div: 11.14976, Total Loss: 130.93608
Epoch[80/100], Step [220/391], Reconst Loss: 118.20374, KL Div: 11.33632, Total Loss: 129.54006
Epoch[80/100], Step [230/391], Reconst Loss: 116.91619, KL Div: 11.04813, Total Loss: 127.96432
Epoch[80/100], Step [240/391], Reconst Loss: 114.84899, KL Div: 11.20474, Total Loss: 126.05374
Epoch[80/100], Step [250/391], Reconst Loss: 112.42502, KL Div: 11.12245, Total Loss: 123.54747
Epoch[80/100], Step [260/391], Reconst Loss: 120.55803, KL Div: 11.22669, Total Loss: 131.78471
Epoch[80/100], Step [270/391], Reconst Loss: 117.37738, KL Div: 11.64503, Total Loss: 129.02241
Epoch[80/100], Step [280/391], Reconst Loss: 112.35427, KL Div: 11.29633, Total Loss: 123.65060
Epoch[80/100], Step [290/391], Reconst Loss: 114.81071, KL Div: 11.44184, Total Loss: 126.25255
Epoch[80/100], Step [300/391], Reconst Loss: 112.38747, KL Div: 11.91604, Total Loss: 124.30351
Epoch[80/100], Step [310/391], Reconst Loss: 110.69389, KL Div: 11.47817, Total Loss: 122.17207
Epoch[80/100], Step [320/391], Reconst Loss: 114.41307, KL Div: 11.50908, Total Loss: 125.92215
Epoch[80/100], Step [330/391], Reconst Loss: 113.93604, KL Div: 11.34199, Total Loss: 125.27803
Epoch[80/100], Step [340/391], Reconst Loss: 118.57887, KL Div: 10.94985, Total Loss: 129.52872
Epoch[80/100], Step [350/391], Reconst Loss: 110.53700, KL Div: 11.58734, Total Loss: 122.12434
Epoch[80/100], Step [360/391], Reconst Loss: 116.23206, KL Div: 11.32631, Total Loss: 127.55836
Epoch[80/100], Step [370/391], Reconst Loss: 120.45193, KL Div: 11.37225, Total Loss: 131.82419
Epoch[80/100], Step [380/391], Reconst Loss: 114.53625, KL Div: 11.39009, Total Loss: 125.92634
Epoch[80/100], Step [390/391], Reconst Loss: 110.93182, KL Div: 11.12811, Total Loss: 122.05993
Epoch = 80
Training epoch time =  139.1246886253357
train total loss =  126.458877421875
valid total loss =  127.82828332519532
Total epoch time =  257.556759595871
Saving checkpoint...
Done!
Epoch[81/100], Step [10/391], Reconst Loss: 114.78561, KL Div: 11.26592, Total Loss: 126.05152
Epoch[81/100], Step [20/391], Reconst Loss: 119.10602, KL Div: 11.58702, Total Loss: 130.69304
Epoch[81/100], Step [30/391], Reconst Loss: 116.44326, KL Div: 11.45470, Total Loss: 127.89796
Epoch[81/100], Step [40/391], Reconst Loss: 113.37442, KL Div: 11.21435, Total Loss: 124.58877
Epoch[81/100], Step [50/391], Reconst Loss: 116.12513, KL Div: 11.52913, Total Loss: 127.65426
Epoch[81/100], Step [60/391], Reconst Loss: 118.14316, KL Div: 10.81225, Total Loss: 128.95541
Epoch[81/100], Step [70/391], Reconst Loss: 111.09473, KL Div: 11.42280, Total Loss: 122.51753
Epoch[81/100], Step [80/391], Reconst Loss: 116.18725, KL Div: 11.74038, Total Loss: 127.92763
Epoch[81/100], Step [90/391], Reconst Loss: 114.26782, KL Div: 11.15104, Total Loss: 125.41886
Epoch[81/100], Step [100/391], Reconst Loss: 121.38266, KL Div: 11.76883, Total Loss: 133.15149
Epoch[81/100], Step [110/391], Reconst Loss: 107.13664, KL Div: 11.26613, Total Loss: 118.40278
Epoch[81/100], Step [120/391], Reconst Loss: 108.91743, KL Div: 11.53888, Total Loss: 120.45632
Epoch[81/100], Step [130/391], Reconst Loss: 120.66858, KL Div: 11.09472, Total Loss: 131.76330
Epoch[81/100], Step [140/391], Reconst Loss: 122.24648, KL Div: 11.35786, Total Loss: 133.60433
Epoch[81/100], Step [150/391], Reconst Loss: 116.63247, KL Div: 11.62117, Total Loss: 128.25364
Epoch[81/100], Step [160/391], Reconst Loss: 118.95767, KL Div: 11.17228, Total Loss: 130.12995
Epoch[81/100], Step [170/391], Reconst Loss: 115.45054, KL Div: 11.62354, Total Loss: 127.07408
Epoch[81/100], Step [180/391], Reconst Loss: 116.64236, KL Div: 11.60332, Total Loss: 128.24568
Epoch[81/100], Step [190/391], Reconst Loss: 114.22205, KL Div: 11.58155, Total Loss: 125.80360
Epoch[81/100], Step [200/391], Reconst Loss: 116.12389, KL Div: 11.60368, Total Loss: 127.72757
Epoch[81/100], Step [210/391], Reconst Loss: 118.59798, KL Div: 11.22885, Total Loss: 129.82683
Epoch[81/100], Step [220/391], Reconst Loss: 115.97839, KL Div: 11.77892, Total Loss: 127.75731
Epoch[81/100], Step [230/391], Reconst Loss: 117.56347, KL Div: 11.45154, Total Loss: 129.01500
Epoch[81/100], Step [240/391], Reconst Loss: 118.04001, KL Div: 10.91310, Total Loss: 128.95311
Epoch[81/100], Step [250/391], Reconst Loss: 117.63744, KL Div: 11.71394, Total Loss: 129.35138
Epoch[81/100], Step [260/391], Reconst Loss: 112.44748, KL Div: 11.29456, Total Loss: 123.74204
Epoch[81/100], Step [270/391], Reconst Loss: 113.44307, KL Div: 11.34591, Total Loss: 124.78898
Epoch[81/100], Step [280/391], Reconst Loss: 117.94086, KL Div: 11.50575, Total Loss: 129.44661
Epoch[81/100], Step [290/391], Reconst Loss: 114.87053, KL Div: 11.74351, Total Loss: 126.61404
Epoch[81/100], Step [300/391], Reconst Loss: 121.52441, KL Div: 11.30381, Total Loss: 132.82822
Epoch[81/100], Step [310/391], Reconst Loss: 108.26057, KL Div: 11.39264, Total Loss: 119.65321
Epoch[81/100], Step [320/391], Reconst Loss: 112.16648, KL Div: 10.95371, Total Loss: 123.12019
Epoch[81/100], Step [330/391], Reconst Loss: 118.70829, KL Div: 11.62786, Total Loss: 130.33615
Epoch[81/100], Step [340/391], Reconst Loss: 119.81522, KL Div: 11.39419, Total Loss: 131.20941
Epoch[81/100], Step [350/391], Reconst Loss: 115.80045, KL Div: 11.52946, Total Loss: 127.32990
Epoch[81/100], Step [360/391], Reconst Loss: 126.87130, KL Div: 11.55851, Total Loss: 138.42981
Epoch[81/100], Step [370/391], Reconst Loss: 117.12460, KL Div: 10.85825, Total Loss: 127.98286
Epoch[81/100], Step [380/391], Reconst Loss: 116.18237, KL Div: 11.08752, Total Loss: 127.26989
Epoch[81/100], Step [390/391], Reconst Loss: 116.74496, KL Div: 11.38727, Total Loss: 128.13223
Epoch = 81
Training epoch time =  139.18358969688416
train total loss =  127.34119267578124
valid total loss =  128.7620125
Total epoch time =  257.3805284500122
Saving checkpoint...
Done!
Epoch[82/100], Step [10/391], Reconst Loss: 120.23663, KL Div: 11.32762, Total Loss: 131.56426
Epoch[82/100], Step [20/391], Reconst Loss: 113.05882, KL Div: 10.89238, Total Loss: 123.95120
Epoch[82/100], Step [30/391], Reconst Loss: 122.76497, KL Div: 11.61791, Total Loss: 134.38287
Epoch[82/100], Step [40/391], Reconst Loss: 113.39830, KL Div: 11.23267, Total Loss: 124.63097
Epoch[82/100], Step [50/391], Reconst Loss: 116.89932, KL Div: 11.11789, Total Loss: 128.01722
Epoch[82/100], Step [60/391], Reconst Loss: 120.31364, KL Div: 11.83797, Total Loss: 132.15161
Epoch[82/100], Step [70/391], Reconst Loss: 117.76251, KL Div: 11.17171, Total Loss: 128.93422
Epoch[82/100], Step [80/391], Reconst Loss: 111.12335, KL Div: 11.09516, Total Loss: 122.21851
Epoch[82/100], Step [90/391], Reconst Loss: 114.09662, KL Div: 11.02121, Total Loss: 125.11783
Epoch[82/100], Step [100/391], Reconst Loss: 111.73075, KL Div: 11.49257, Total Loss: 123.22333
Epoch[82/100], Step [110/391], Reconst Loss: 121.23195, KL Div: 11.12018, Total Loss: 132.35213
Epoch[82/100], Step [120/391], Reconst Loss: 117.61029, KL Div: 11.61551, Total Loss: 129.22580
Epoch[82/100], Step [130/391], Reconst Loss: 120.29800, KL Div: 11.56946, Total Loss: 131.86745
Epoch[82/100], Step [140/391], Reconst Loss: 115.97327, KL Div: 11.02719, Total Loss: 127.00046
Epoch[82/100], Step [150/391], Reconst Loss: 110.62549, KL Div: 11.25914, Total Loss: 121.88463
Epoch[82/100], Step [160/391], Reconst Loss: 118.01334, KL Div: 11.26656, Total Loss: 129.27991
Epoch[82/100], Step [170/391], Reconst Loss: 111.94678, KL Div: 11.31473, Total Loss: 123.26152
Epoch[82/100], Step [180/391], Reconst Loss: 117.60758, KL Div: 11.61954, Total Loss: 129.22712
Epoch[82/100], Step [190/391], Reconst Loss: 111.53025, KL Div: 11.52531, Total Loss: 123.05556
Epoch[82/100], Step [200/391], Reconst Loss: 114.10869, KL Div: 10.85780, Total Loss: 124.96649
Epoch[82/100], Step [210/391], Reconst Loss: 114.60544, KL Div: 11.01656, Total Loss: 125.62200
Epoch[82/100], Step [220/391], Reconst Loss: 115.64551, KL Div: 11.54759, Total Loss: 127.19310
Epoch[82/100], Step [230/391], Reconst Loss: 114.75140, KL Div: 11.46012, Total Loss: 126.21152
Epoch[82/100], Step [240/391], Reconst Loss: 113.47671, KL Div: 11.12344, Total Loss: 124.60015
Epoch[82/100], Step [250/391], Reconst Loss: 121.73436, KL Div: 11.16462, Total Loss: 132.89898
Epoch[82/100], Step [260/391], Reconst Loss: 124.18799, KL Div: 11.67301, Total Loss: 135.86100
Epoch[82/100], Step [270/391], Reconst Loss: 107.09551, KL Div: 11.28408, Total Loss: 118.37960
Epoch[82/100], Step [280/391], Reconst Loss: 114.02742, KL Div: 11.35057, Total Loss: 125.37799
Epoch[82/100], Step [290/391], Reconst Loss: 109.97654, KL Div: 11.36181, Total Loss: 121.33835
Epoch[82/100], Step [300/391], Reconst Loss: 120.35138, KL Div: 11.03878, Total Loss: 131.39016
Epoch[82/100], Step [310/391], Reconst Loss: 122.07671, KL Div: 11.70792, Total Loss: 133.78462
Epoch[82/100], Step [320/391], Reconst Loss: 122.35254, KL Div: 11.25268, Total Loss: 133.60522
Epoch[82/100], Step [330/391], Reconst Loss: 114.31099, KL Div: 11.37206, Total Loss: 125.68305
Epoch[82/100], Step [340/391], Reconst Loss: 111.72646, KL Div: 11.24362, Total Loss: 122.97007
Epoch[82/100], Step [350/391], Reconst Loss: 122.30078, KL Div: 11.27687, Total Loss: 133.57766
Epoch[82/100], Step [360/391], Reconst Loss: 113.56482, KL Div: 11.28533, Total Loss: 124.85015
Epoch[82/100], Step [370/391], Reconst Loss: 113.85710, KL Div: 11.64828, Total Loss: 125.50539
Epoch[82/100], Step [380/391], Reconst Loss: 112.39853, KL Div: 11.55557, Total Loss: 123.95410
Epoch[82/100], Step [390/391], Reconst Loss: 114.62827, KL Div: 11.19074, Total Loss: 125.81901
Epoch = 82
Training epoch time =  139.03256630897522
train total loss =  127.0135909765625
valid total loss =  128.38598028564454
Total epoch time =  257.25644850730896
Saving checkpoint...
Done!
Epoch[83/100], Step [10/391], Reconst Loss: 114.69060, KL Div: 11.73306, Total Loss: 126.42366
Epoch[83/100], Step [20/391], Reconst Loss: 121.55464, KL Div: 11.42597, Total Loss: 132.98061
Epoch[83/100], Step [30/391], Reconst Loss: 121.78792, KL Div: 11.97953, Total Loss: 133.76745
Epoch[83/100], Step [40/391], Reconst Loss: 120.59496, KL Div: 11.19214, Total Loss: 131.78709
Epoch[83/100], Step [50/391], Reconst Loss: 114.07286, KL Div: 11.59634, Total Loss: 125.66921
Epoch[83/100], Step [60/391], Reconst Loss: 113.09655, KL Div: 11.37957, Total Loss: 124.47612
Epoch[83/100], Step [70/391], Reconst Loss: 116.54897, KL Div: 11.26383, Total Loss: 127.81280
Epoch[83/100], Step [80/391], Reconst Loss: 113.90083, KL Div: 11.03380, Total Loss: 124.93463
Epoch[83/100], Step [90/391], Reconst Loss: 118.98174, KL Div: 11.28420, Total Loss: 130.26593
Epoch[83/100], Step [100/391], Reconst Loss: 111.90884, KL Div: 11.31146, Total Loss: 123.22030
Epoch[83/100], Step [110/391], Reconst Loss: 114.40104, KL Div: 11.27799, Total Loss: 125.67903
Epoch[83/100], Step [120/391], Reconst Loss: 114.24606, KL Div: 11.28949, Total Loss: 125.53555
Epoch[83/100], Step [130/391], Reconst Loss: 115.61023, KL Div: 11.56802, Total Loss: 127.17825
Epoch[83/100], Step [140/391], Reconst Loss: 116.55608, KL Div: 11.01338, Total Loss: 127.56945
Epoch[83/100], Step [150/391], Reconst Loss: 112.68857, KL Div: 10.56973, Total Loss: 123.25830
Epoch[83/100], Step [160/391], Reconst Loss: 113.68924, KL Div: 11.27121, Total Loss: 124.96045
Epoch[83/100], Step [170/391], Reconst Loss: 114.25499, KL Div: 11.18480, Total Loss: 125.43979
Epoch[83/100], Step [180/391], Reconst Loss: 112.07172, KL Div: 11.35941, Total Loss: 123.43113
Epoch[83/100], Step [190/391], Reconst Loss: 113.83566, KL Div: 11.54212, Total Loss: 125.37778
Epoch[83/100], Step [200/391], Reconst Loss: 113.76913, KL Div: 11.71767, Total Loss: 125.48680
Epoch[83/100], Step [210/391], Reconst Loss: 113.62871, KL Div: 11.06328, Total Loss: 124.69199
Epoch[83/100], Step [220/391], Reconst Loss: 114.18163, KL Div: 11.16653, Total Loss: 125.34817
Epoch[83/100], Step [230/391], Reconst Loss: 112.33019, KL Div: 11.46780, Total Loss: 123.79800
Epoch[83/100], Step [240/391], Reconst Loss: 112.17130, KL Div: 11.68632, Total Loss: 123.85762
Epoch[83/100], Step [250/391], Reconst Loss: 110.91302, KL Div: 11.55647, Total Loss: 122.46950
Epoch[83/100], Step [260/391], Reconst Loss: 120.15758, KL Div: 12.05782, Total Loss: 132.21540
Epoch[83/100], Step [270/391], Reconst Loss: 118.02990, KL Div: 11.60462, Total Loss: 129.63452
Epoch[83/100], Step [280/391], Reconst Loss: 113.88660, KL Div: 11.08890, Total Loss: 124.97550
Epoch[83/100], Step [290/391], Reconst Loss: 118.46030, KL Div: 11.30729, Total Loss: 129.76759
Epoch[83/100], Step [300/391], Reconst Loss: 116.19533, KL Div: 11.47565, Total Loss: 127.67098
Epoch[83/100], Step [310/391], Reconst Loss: 113.09070, KL Div: 11.34368, Total Loss: 124.43438
Epoch[83/100], Step [320/391], Reconst Loss: 121.35751, KL Div: 11.45978, Total Loss: 132.81729
Epoch[83/100], Step [330/391], Reconst Loss: 119.24265, KL Div: 11.03342, Total Loss: 130.27606
Epoch[83/100], Step [340/391], Reconst Loss: 117.64429, KL Div: 11.49156, Total Loss: 129.13586
Epoch[83/100], Step [350/391], Reconst Loss: 115.41534, KL Div: 11.15709, Total Loss: 126.57243
Epoch[83/100], Step [360/391], Reconst Loss: 112.50539, KL Div: 11.09983, Total Loss: 123.60523
Epoch[83/100], Step [370/391], Reconst Loss: 122.34632, KL Div: 11.24143, Total Loss: 133.58775
Epoch[83/100], Step [380/391], Reconst Loss: 121.19741, KL Div: 11.50250, Total Loss: 132.69991
Epoch[83/100], Step [390/391], Reconst Loss: 111.09151, KL Div: 11.17331, Total Loss: 122.26483
Epoch = 83
Training epoch time =  139.44869685173035
train total loss =  126.56025708984374
valid total loss =  128.1128274169922
Total epoch time =  257.8205282688141
Saving checkpoint...
Done!
Epoch[84/100], Step [10/391], Reconst Loss: 118.12148, KL Div: 11.61281, Total Loss: 129.73429
Epoch[84/100], Step [20/391], Reconst Loss: 120.83873, KL Div: 10.93560, Total Loss: 131.77433
Epoch[84/100], Step [30/391], Reconst Loss: 117.73526, KL Div: 11.33805, Total Loss: 129.07331
Epoch[84/100], Step [40/391], Reconst Loss: 112.83515, KL Div: 11.43830, Total Loss: 124.27345
Epoch[84/100], Step [50/391], Reconst Loss: 112.47528, KL Div: 11.14701, Total Loss: 123.62229
Epoch[84/100], Step [60/391], Reconst Loss: 118.67850, KL Div: 11.76912, Total Loss: 130.44762
Epoch[84/100], Step [70/391], Reconst Loss: 119.44078, KL Div: 11.24567, Total Loss: 130.68645
Epoch[84/100], Step [80/391], Reconst Loss: 119.58078, KL Div: 11.18971, Total Loss: 130.77049
Epoch[84/100], Step [90/391], Reconst Loss: 115.83245, KL Div: 11.29077, Total Loss: 127.12322
Epoch[84/100], Step [100/391], Reconst Loss: 114.83255, KL Div: 11.21055, Total Loss: 126.04310
Epoch[84/100], Step [110/391], Reconst Loss: 116.07525, KL Div: 11.50281, Total Loss: 127.57805
Epoch[84/100], Step [120/391], Reconst Loss: 114.93631, KL Div: 11.25905, Total Loss: 126.19536
Epoch[84/100], Step [130/391], Reconst Loss: 118.11185, KL Div: 11.59562, Total Loss: 129.70747
Epoch[84/100], Step [140/391], Reconst Loss: 113.63864, KL Div: 11.47034, Total Loss: 125.10898
Epoch[84/100], Step [150/391], Reconst Loss: 111.55327, KL Div: 11.05846, Total Loss: 122.61173
Epoch[84/100], Step [160/391], Reconst Loss: 113.48184, KL Div: 11.29809, Total Loss: 124.77994
Epoch[84/100], Step [170/391], Reconst Loss: 125.48952, KL Div: 11.49839, Total Loss: 136.98791
Epoch[84/100], Step [180/391], Reconst Loss: 120.87149, KL Div: 11.42073, Total Loss: 132.29222
Epoch[84/100], Step [190/391], Reconst Loss: 114.39640, KL Div: 11.45184, Total Loss: 125.84824
Epoch[84/100], Step [200/391], Reconst Loss: 118.23672, KL Div: 11.12514, Total Loss: 129.36187
Epoch[84/100], Step [210/391], Reconst Loss: 109.54398, KL Div: 11.17805, Total Loss: 120.72202
Epoch[84/100], Step [220/391], Reconst Loss: 116.27218, KL Div: 11.47495, Total Loss: 127.74713
Epoch[84/100], Step [230/391], Reconst Loss: 112.05836, KL Div: 11.32115, Total Loss: 123.37951
Epoch[84/100], Step [240/391], Reconst Loss: 115.57259, KL Div: 11.00719, Total Loss: 126.57978
Epoch[84/100], Step [250/391], Reconst Loss: 115.61388, KL Div: 11.32699, Total Loss: 126.94087
Epoch[84/100], Step [260/391], Reconst Loss: 118.56767, KL Div: 11.21466, Total Loss: 129.78233
Epoch[84/100], Step [270/391], Reconst Loss: 121.71420, KL Div: 11.26812, Total Loss: 132.98232
Epoch[84/100], Step [280/391], Reconst Loss: 117.82379, KL Div: 11.00634, Total Loss: 128.83013
Epoch[84/100], Step [290/391], Reconst Loss: 111.21620, KL Div: 11.39368, Total Loss: 122.60988
Epoch[84/100], Step [300/391], Reconst Loss: 112.98485, KL Div: 10.84970, Total Loss: 123.83455
Epoch[84/100], Step [310/391], Reconst Loss: 113.20222, KL Div: 11.42916, Total Loss: 124.63138
Epoch[84/100], Step [320/391], Reconst Loss: 120.24203, KL Div: 11.65347, Total Loss: 131.89551
Epoch[84/100], Step [330/391], Reconst Loss: 114.83444, KL Div: 11.16661, Total Loss: 126.00105
Epoch[84/100], Step [340/391], Reconst Loss: 116.77658, KL Div: 11.68337, Total Loss: 128.45995
Epoch[84/100], Step [350/391], Reconst Loss: 120.04393, KL Div: 11.02672, Total Loss: 131.07065
Epoch[84/100], Step [360/391], Reconst Loss: 117.52058, KL Div: 11.36903, Total Loss: 128.88961
Epoch[84/100], Step [370/391], Reconst Loss: 118.45511, KL Div: 11.13013, Total Loss: 129.58524
Epoch[84/100], Step [380/391], Reconst Loss: 120.15527, KL Div: 11.06143, Total Loss: 131.21671
Epoch[84/100], Step [390/391], Reconst Loss: 118.08049, KL Div: 11.54341, Total Loss: 129.62390
Epoch = 84
Training epoch time =  139.74303197860718
train total loss =  126.3610501953125
valid total loss =  127.96881295166015
Total epoch time =  257.94700503349304
Saving checkpoint...
Done!
Epoch[85/100], Step [10/391], Reconst Loss: 116.23628, KL Div: 11.39725, Total Loss: 127.63353
Epoch[85/100], Step [20/391], Reconst Loss: 117.21873, KL Div: 11.27553, Total Loss: 128.49427
Epoch[85/100], Step [30/391], Reconst Loss: 116.51846, KL Div: 11.42577, Total Loss: 127.94423
Epoch[85/100], Step [40/391], Reconst Loss: 109.78449, KL Div: 11.33962, Total Loss: 121.12411
Epoch[85/100], Step [50/391], Reconst Loss: 121.77316, KL Div: 11.45313, Total Loss: 133.22630
Epoch[85/100], Step [60/391], Reconst Loss: 114.00423, KL Div: 11.30857, Total Loss: 125.31280
Epoch[85/100], Step [70/391], Reconst Loss: 121.29454, KL Div: 11.12982, Total Loss: 132.42436
Epoch[85/100], Step [80/391], Reconst Loss: 118.87139, KL Div: 11.56976, Total Loss: 130.44115
Epoch[85/100], Step [90/391], Reconst Loss: 115.47845, KL Div: 11.30135, Total Loss: 126.77981
Epoch[85/100], Step [100/391], Reconst Loss: 116.43232, KL Div: 11.77187, Total Loss: 128.20419
Epoch[85/100], Step [110/391], Reconst Loss: 116.72798, KL Div: 11.70472, Total Loss: 128.43271
Epoch[85/100], Step [120/391], Reconst Loss: 116.67271, KL Div: 11.42064, Total Loss: 128.09334
Epoch[85/100], Step [130/391], Reconst Loss: 120.76484, KL Div: 11.72085, Total Loss: 132.48569
Epoch[85/100], Step [140/391], Reconst Loss: 119.23421, KL Div: 11.17043, Total Loss: 130.40463
Epoch[85/100], Step [150/391], Reconst Loss: 115.59727, KL Div: 11.59870, Total Loss: 127.19597
Epoch[85/100], Step [160/391], Reconst Loss: 112.32778, KL Div: 11.67857, Total Loss: 124.00635
Epoch[85/100], Step [170/391], Reconst Loss: 109.93168, KL Div: 11.58009, Total Loss: 121.51177
Epoch[85/100], Step [180/391], Reconst Loss: 115.09737, KL Div: 11.16795, Total Loss: 126.26531
Epoch[85/100], Step [190/391], Reconst Loss: 116.29225, KL Div: 11.93476, Total Loss: 128.22702
Epoch[85/100], Step [200/391], Reconst Loss: 121.61601, KL Div: 11.19104, Total Loss: 132.80705
Epoch[85/100], Step [210/391], Reconst Loss: 114.72084, KL Div: 11.13396, Total Loss: 125.85480
Epoch[85/100], Step [220/391], Reconst Loss: 115.89162, KL Div: 11.34446, Total Loss: 127.23609
Epoch[85/100], Step [230/391], Reconst Loss: 116.95876, KL Div: 11.23291, Total Loss: 128.19166
Epoch[85/100], Step [240/391], Reconst Loss: 113.38162, KL Div: 11.30538, Total Loss: 124.68700
Epoch[85/100], Step [250/391], Reconst Loss: 110.33326, KL Div: 11.72885, Total Loss: 122.06211
Epoch[85/100], Step [260/391], Reconst Loss: 115.38220, KL Div: 11.35901, Total Loss: 126.74121
Epoch[85/100], Step [270/391], Reconst Loss: 108.89340, KL Div: 11.97083, Total Loss: 120.86423
Epoch[85/100], Step [280/391], Reconst Loss: 117.89812, KL Div: 11.64421, Total Loss: 129.54234
Epoch[85/100], Step [290/391], Reconst Loss: 111.99129, KL Div: 11.48308, Total Loss: 123.47437
Epoch[85/100], Step [300/391], Reconst Loss: 113.89525, KL Div: 11.77500, Total Loss: 125.67025
Epoch[85/100], Step [310/391], Reconst Loss: 116.49812, KL Div: 11.17639, Total Loss: 127.67451
Epoch[85/100], Step [320/391], Reconst Loss: 110.80066, KL Div: 11.50812, Total Loss: 122.30878
Epoch[85/100], Step [330/391], Reconst Loss: 112.46964, KL Div: 11.55232, Total Loss: 124.02196
Epoch[85/100], Step [340/391], Reconst Loss: 120.27623, KL Div: 11.61590, Total Loss: 131.89213
Epoch[85/100], Step [350/391], Reconst Loss: 118.77205, KL Div: 11.10287, Total Loss: 129.87492
Epoch[85/100], Step [360/391], Reconst Loss: 112.03917, KL Div: 11.43453, Total Loss: 123.47370
Epoch[85/100], Step [370/391], Reconst Loss: 111.33966, KL Div: 11.82230, Total Loss: 123.16196
Epoch[85/100], Step [380/391], Reconst Loss: 117.60900, KL Div: 11.42700, Total Loss: 129.03600
Epoch[85/100], Step [390/391], Reconst Loss: 121.85309, KL Div: 11.31808, Total Loss: 133.17117
Epoch = 85
Training epoch time =  139.4163796901703
train total loss =  126.0977301953125
valid total loss =  127.72011837158203
Total epoch time =  257.5953006744385
Saving checkpoint...
Done!
Epoch[86/100], Step [10/391], Reconst Loss: 113.18314, KL Div: 11.15471, Total Loss: 124.33785
Epoch[86/100], Step [20/391], Reconst Loss: 116.18114, KL Div: 11.57144, Total Loss: 127.75258
Epoch[86/100], Step [30/391], Reconst Loss: 117.51521, KL Div: 11.43919, Total Loss: 128.95441
Epoch[86/100], Step [40/391], Reconst Loss: 117.33385, KL Div: 11.65473, Total Loss: 128.98858
Epoch[86/100], Step [50/391], Reconst Loss: 115.14796, KL Div: 11.34063, Total Loss: 126.48860
Epoch[86/100], Step [60/391], Reconst Loss: 114.13547, KL Div: 11.55711, Total Loss: 125.69258
Epoch[86/100], Step [70/391], Reconst Loss: 112.38297, KL Div: 11.64920, Total Loss: 124.03216
Epoch[86/100], Step [80/391], Reconst Loss: 119.84698, KL Div: 11.63320, Total Loss: 131.48018
Epoch[86/100], Step [90/391], Reconst Loss: 112.35527, KL Div: 11.37977, Total Loss: 123.73504
Epoch[86/100], Step [100/391], Reconst Loss: 119.36566, KL Div: 11.55649, Total Loss: 130.92215
Epoch[86/100], Step [110/391], Reconst Loss: 116.66237, KL Div: 11.23403, Total Loss: 127.89639
Epoch[86/100], Step [120/391], Reconst Loss: 114.22096, KL Div: 11.15760, Total Loss: 125.37856
Epoch[86/100], Step [130/391], Reconst Loss: 115.28167, KL Div: 11.14457, Total Loss: 126.42624
Epoch[86/100], Step [140/391], Reconst Loss: 113.89944, KL Div: 11.11615, Total Loss: 125.01559
Epoch[86/100], Step [150/391], Reconst Loss: 115.31686, KL Div: 11.55169, Total Loss: 126.86855
Epoch[86/100], Step [160/391], Reconst Loss: 115.58310, KL Div: 11.60334, Total Loss: 127.18644
Epoch[86/100], Step [170/391], Reconst Loss: 113.09551, KL Div: 11.53212, Total Loss: 124.62764
Epoch[86/100], Step [180/391], Reconst Loss: 109.68993, KL Div: 11.17594, Total Loss: 120.86586
Epoch[86/100], Step [190/391], Reconst Loss: 113.59068, KL Div: 11.78118, Total Loss: 125.37186
Epoch[86/100], Step [200/391], Reconst Loss: 118.91670, KL Div: 11.63748, Total Loss: 130.55419
Epoch[86/100], Step [210/391], Reconst Loss: 119.65831, KL Div: 11.22673, Total Loss: 130.88504
Epoch[86/100], Step [220/391], Reconst Loss: 118.14926, KL Div: 11.28567, Total Loss: 129.43493
Epoch[86/100], Step [230/391], Reconst Loss: 118.74009, KL Div: 11.63022, Total Loss: 130.37031
Epoch[86/100], Step [240/391], Reconst Loss: 117.03128, KL Div: 11.40046, Total Loss: 128.43174
Epoch[86/100], Step [250/391], Reconst Loss: 116.70732, KL Div: 11.22705, Total Loss: 127.93437
Epoch[86/100], Step [260/391], Reconst Loss: 127.27933, KL Div: 11.43757, Total Loss: 138.71689
Epoch[86/100], Step [270/391], Reconst Loss: 114.41289, KL Div: 11.44501, Total Loss: 125.85789
Epoch[86/100], Step [280/391], Reconst Loss: 116.28510, KL Div: 11.32955, Total Loss: 127.61465
Epoch[86/100], Step [290/391], Reconst Loss: 115.17496, KL Div: 11.57726, Total Loss: 126.75221
Epoch[86/100], Step [300/391], Reconst Loss: 111.58395, KL Div: 11.57689, Total Loss: 123.16084
Epoch[86/100], Step [310/391], Reconst Loss: 115.54581, KL Div: 11.34833, Total Loss: 126.89413
Epoch[86/100], Step [320/391], Reconst Loss: 119.76347, KL Div: 11.84105, Total Loss: 131.60453
Epoch[86/100], Step [330/391], Reconst Loss: 118.26968, KL Div: 11.49690, Total Loss: 129.76659
Epoch[86/100], Step [340/391], Reconst Loss: 117.31479, KL Div: 11.19403, Total Loss: 128.50882
Epoch[86/100], Step [350/391], Reconst Loss: 116.40512, KL Div: 11.66757, Total Loss: 128.07269
Epoch[86/100], Step [360/391], Reconst Loss: 114.97186, KL Div: 11.34735, Total Loss: 126.31920
Epoch[86/100], Step [370/391], Reconst Loss: 113.21483, KL Div: 11.14320, Total Loss: 124.35803
Epoch[86/100], Step [380/391], Reconst Loss: 118.94257, KL Div: 11.34300, Total Loss: 130.28556
Epoch[86/100], Step [390/391], Reconst Loss: 118.44057, KL Div: 11.24996, Total Loss: 129.69052
Epoch = 86
Training epoch time =  139.58590626716614
train total loss =  127.0701334765625
valid total loss =  128.6272280761719
Total epoch time =  257.50951409339905
Saving checkpoint...
Done!
Epoch[87/100], Step [10/391], Reconst Loss: 120.53149, KL Div: 11.17971, Total Loss: 131.71121
Epoch[87/100], Step [20/391], Reconst Loss: 123.96774, KL Div: 11.63338, Total Loss: 135.60113
Epoch[87/100], Step [30/391], Reconst Loss: 118.74178, KL Div: 11.39607, Total Loss: 130.13786
Epoch[87/100], Step [40/391], Reconst Loss: 115.51917, KL Div: 11.21328, Total Loss: 126.73245
Epoch[87/100], Step [50/391], Reconst Loss: 115.00114, KL Div: 11.34550, Total Loss: 126.34664
Epoch[87/100], Step [60/391], Reconst Loss: 120.06891, KL Div: 11.80441, Total Loss: 131.87332
Epoch[87/100], Step [70/391], Reconst Loss: 116.54933, KL Div: 11.59487, Total Loss: 128.14420
Epoch[87/100], Step [80/391], Reconst Loss: 114.24826, KL Div: 11.38991, Total Loss: 125.63817
Epoch[87/100], Step [90/391], Reconst Loss: 113.19107, KL Div: 11.19466, Total Loss: 124.38574
Epoch[87/100], Step [100/391], Reconst Loss: 111.90631, KL Div: 11.36907, Total Loss: 123.27538
Epoch[87/100], Step [110/391], Reconst Loss: 115.12498, KL Div: 11.23022, Total Loss: 126.35520
Epoch[87/100], Step [120/391], Reconst Loss: 117.69878, KL Div: 11.26385, Total Loss: 128.96263
Epoch[87/100], Step [130/391], Reconst Loss: 117.02139, KL Div: 11.47344, Total Loss: 128.49483
Epoch[87/100], Step [140/391], Reconst Loss: 118.16250, KL Div: 11.54758, Total Loss: 129.71008
Epoch[87/100], Step [150/391], Reconst Loss: 111.20133, KL Div: 11.26535, Total Loss: 122.46668
Epoch[87/100], Step [160/391], Reconst Loss: 117.17511, KL Div: 11.36686, Total Loss: 128.54197
Epoch[87/100], Step [170/391], Reconst Loss: 114.87418, KL Div: 11.44232, Total Loss: 126.31650
Epoch[87/100], Step [180/391], Reconst Loss: 122.62186, KL Div: 11.62104, Total Loss: 134.24289
Epoch[87/100], Step [190/391], Reconst Loss: 116.04544, KL Div: 11.49110, Total Loss: 127.53654
Epoch[87/100], Step [200/391], Reconst Loss: 109.07318, KL Div: 12.06688, Total Loss: 121.14007
Epoch[87/100], Step [210/391], Reconst Loss: 114.64635, KL Div: 11.43562, Total Loss: 126.08197
Epoch[87/100], Step [220/391], Reconst Loss: 113.81790, KL Div: 11.47184, Total Loss: 125.28974
Epoch[87/100], Step [230/391], Reconst Loss: 120.67207, KL Div: 11.36953, Total Loss: 132.04160
Epoch[87/100], Step [240/391], Reconst Loss: 114.69052, KL Div: 11.27787, Total Loss: 125.96839
Epoch[87/100], Step [250/391], Reconst Loss: 119.39668, KL Div: 11.90200, Total Loss: 131.29868
Epoch[87/100], Step [260/391], Reconst Loss: 110.42553, KL Div: 11.52591, Total Loss: 121.95144
Epoch[87/100], Step [270/391], Reconst Loss: 117.73064, KL Div: 11.57546, Total Loss: 129.30609
Epoch[87/100], Step [280/391], Reconst Loss: 114.95404, KL Div: 11.42761, Total Loss: 126.38165
Epoch[87/100], Step [290/391], Reconst Loss: 114.08318, KL Div: 11.05357, Total Loss: 125.13674
Epoch[87/100], Step [300/391], Reconst Loss: 115.49901, KL Div: 11.11563, Total Loss: 126.61464
Epoch[87/100], Step [310/391], Reconst Loss: 116.17915, KL Div: 11.01882, Total Loss: 127.19798
Epoch[87/100], Step [320/391], Reconst Loss: 120.52499, KL Div: 11.81412, Total Loss: 132.33912
Epoch[87/100], Step [330/391], Reconst Loss: 122.14100, KL Div: 11.78006, Total Loss: 133.92106
Epoch[87/100], Step [340/391], Reconst Loss: 116.85307, KL Div: 11.08524, Total Loss: 127.93830
Epoch[87/100], Step [350/391], Reconst Loss: 119.35933, KL Div: 11.60111, Total Loss: 130.96044
Epoch[87/100], Step [360/391], Reconst Loss: 115.66563, KL Div: 11.67297, Total Loss: 127.33860
Epoch[87/100], Step [370/391], Reconst Loss: 117.68053, KL Div: 11.36271, Total Loss: 129.04325
Epoch[87/100], Step [380/391], Reconst Loss: 122.14745, KL Div: 10.77762, Total Loss: 132.92507
Epoch[87/100], Step [390/391], Reconst Loss: 121.87079, KL Div: 11.75061, Total Loss: 133.62140
Epoch = 87
Training epoch time =  139.6785535812378
train total loss =  126.94200697265624
valid total loss =  128.39311049804687
Total epoch time =  257.92219042778015
Saving checkpoint...
Done!
Epoch[88/100], Step [10/391], Reconst Loss: 117.22186, KL Div: 11.75268, Total Loss: 128.97454
Epoch[88/100], Step [20/391], Reconst Loss: 123.16116, KL Div: 11.49178, Total Loss: 134.65295
Epoch[88/100], Step [30/391], Reconst Loss: 113.29549, KL Div: 11.63331, Total Loss: 124.92879
Epoch[88/100], Step [40/391], Reconst Loss: 120.66335, KL Div: 11.32490, Total Loss: 131.98824
Epoch[88/100], Step [50/391], Reconst Loss: 113.16447, KL Div: 11.10839, Total Loss: 124.27287
Epoch[88/100], Step [60/391], Reconst Loss: 115.21480, KL Div: 11.57100, Total Loss: 126.78580
Epoch[88/100], Step [70/391], Reconst Loss: 121.72350, KL Div: 11.57110, Total Loss: 133.29461
Epoch[88/100], Step [80/391], Reconst Loss: 118.83865, KL Div: 11.57553, Total Loss: 130.41419
Epoch[88/100], Step [90/391], Reconst Loss: 117.05536, KL Div: 11.69173, Total Loss: 128.74709
Epoch[88/100], Step [100/391], Reconst Loss: 119.98937, KL Div: 11.73321, Total Loss: 131.72259
Epoch[88/100], Step [110/391], Reconst Loss: 116.53076, KL Div: 11.20380, Total Loss: 127.73456
Epoch[88/100], Step [120/391], Reconst Loss: 114.63356, KL Div: 11.41337, Total Loss: 126.04693
Epoch[88/100], Step [130/391], Reconst Loss: 115.89618, KL Div: 11.36093, Total Loss: 127.25711
Epoch[88/100], Step [140/391], Reconst Loss: 115.22860, KL Div: 11.14957, Total Loss: 126.37817
Epoch[88/100], Step [150/391], Reconst Loss: 109.80446, KL Div: 11.33669, Total Loss: 121.14115
Epoch[88/100], Step [160/391], Reconst Loss: 119.01212, KL Div: 11.61622, Total Loss: 130.62834
Epoch[88/100], Step [170/391], Reconst Loss: 114.76827, KL Div: 11.50531, Total Loss: 126.27359
Epoch[88/100], Step [180/391], Reconst Loss: 114.41336, KL Div: 11.27808, Total Loss: 125.69144
Epoch[88/100], Step [190/391], Reconst Loss: 116.42618, KL Div: 11.22523, Total Loss: 127.65141
Epoch[88/100], Step [200/391], Reconst Loss: 118.04321, KL Div: 11.64128, Total Loss: 129.68448
Epoch[88/100], Step [210/391], Reconst Loss: 116.76830, KL Div: 11.29144, Total Loss: 128.05974
Epoch[88/100], Step [220/391], Reconst Loss: 124.59793, KL Div: 11.31957, Total Loss: 135.91750
Epoch[88/100], Step [230/391], Reconst Loss: 120.02045, KL Div: 11.35905, Total Loss: 131.37950
Epoch[88/100], Step [240/391], Reconst Loss: 116.17655, KL Div: 11.43002, Total Loss: 127.60657
Epoch[88/100], Step [250/391], Reconst Loss: 115.61034, KL Div: 11.65688, Total Loss: 127.26721
Epoch[88/100], Step [260/391], Reconst Loss: 111.18125, KL Div: 11.18793, Total Loss: 122.36918
Epoch[88/100], Step [270/391], Reconst Loss: 116.20888, KL Div: 10.87248, Total Loss: 127.08135
Epoch[88/100], Step [280/391], Reconst Loss: 116.49830, KL Div: 11.18367, Total Loss: 127.68197
Epoch[88/100], Step [290/391], Reconst Loss: 118.06668, KL Div: 11.42040, Total Loss: 129.48708
Epoch[88/100], Step [300/391], Reconst Loss: 112.47958, KL Div: 11.47962, Total Loss: 123.95920
Epoch[88/100], Step [310/391], Reconst Loss: 111.66343, KL Div: 11.79493, Total Loss: 123.45836
Epoch[88/100], Step [320/391], Reconst Loss: 117.13409, KL Div: 11.33795, Total Loss: 128.47205
Epoch[88/100], Step [330/391], Reconst Loss: 119.41809, KL Div: 11.48436, Total Loss: 130.90245
Epoch[88/100], Step [340/391], Reconst Loss: 118.99026, KL Div: 11.82385, Total Loss: 130.81412
Epoch[88/100], Step [350/391], Reconst Loss: 116.15187, KL Div: 11.40604, Total Loss: 127.55791
Epoch[88/100], Step [360/391], Reconst Loss: 112.94162, KL Div: 11.57675, Total Loss: 124.51837
Epoch[88/100], Step [370/391], Reconst Loss: 115.41576, KL Div: 11.40378, Total Loss: 126.81954
Epoch[88/100], Step [380/391], Reconst Loss: 111.48230, KL Div: 11.39171, Total Loss: 122.87401
Epoch[88/100], Step [390/391], Reconst Loss: 118.78362, KL Div: 11.25409, Total Loss: 130.03771
Epoch = 88
Training epoch time =  139.17417788505554
train total loss =  126.75561029296875
valid total loss =  128.02574411621094
Total epoch time =  257.0381395816803
Saving checkpoint...
Done!
Epoch[89/100], Step [10/391], Reconst Loss: 116.50813, KL Div: 11.20014, Total Loss: 127.70828
Epoch[89/100], Step [20/391], Reconst Loss: 117.81809, KL Div: 11.53447, Total Loss: 129.35256
Epoch[89/100], Step [30/391], Reconst Loss: 117.33275, KL Div: 11.23057, Total Loss: 128.56332
Epoch[89/100], Step [40/391], Reconst Loss: 120.57203, KL Div: 11.32308, Total Loss: 131.89511
Epoch[89/100], Step [50/391], Reconst Loss: 120.04887, KL Div: 11.32408, Total Loss: 131.37295
Epoch[89/100], Step [60/391], Reconst Loss: 116.19070, KL Div: 11.62727, Total Loss: 127.81798
Epoch[89/100], Step [70/391], Reconst Loss: 123.36642, KL Div: 11.16139, Total Loss: 134.52780
Epoch[89/100], Step [80/391], Reconst Loss: 113.98865, KL Div: 11.42163, Total Loss: 125.41028
Epoch[89/100], Step [90/391], Reconst Loss: 122.53481, KL Div: 11.35935, Total Loss: 133.89416
Epoch[89/100], Step [100/391], Reconst Loss: 120.85765, KL Div: 11.36378, Total Loss: 132.22143
Epoch[89/100], Step [110/391], Reconst Loss: 112.57669, KL Div: 11.16807, Total Loss: 123.74476
Epoch[89/100], Step [120/391], Reconst Loss: 116.04524, KL Div: 11.21242, Total Loss: 127.25766
Epoch[89/100], Step [130/391], Reconst Loss: 118.23289, KL Div: 11.24933, Total Loss: 129.48222
Epoch[89/100], Step [140/391], Reconst Loss: 116.97205, KL Div: 10.86004, Total Loss: 127.83209
Epoch[89/100], Step [150/391], Reconst Loss: 113.95571, KL Div: 11.42358, Total Loss: 125.37929
Epoch[89/100], Step [160/391], Reconst Loss: 116.44395, KL Div: 11.46167, Total Loss: 127.90563
Epoch[89/100], Step [170/391], Reconst Loss: 112.17983, KL Div: 11.54403, Total Loss: 123.72386
Epoch[89/100], Step [180/391], Reconst Loss: 123.61744, KL Div: 11.31940, Total Loss: 134.93684
Epoch[89/100], Step [190/391], Reconst Loss: 116.05050, KL Div: 11.33862, Total Loss: 127.38912
Epoch[89/100], Step [200/391], Reconst Loss: 111.55386, KL Div: 11.77776, Total Loss: 123.33162
Epoch[89/100], Step [210/391], Reconst Loss: 116.88521, KL Div: 11.28794, Total Loss: 128.17314
Epoch[89/100], Step [220/391], Reconst Loss: 109.59480, KL Div: 11.26557, Total Loss: 120.86037
Epoch[89/100], Step [230/391], Reconst Loss: 123.55580, KL Div: 11.25659, Total Loss: 134.81239
Epoch[89/100], Step [240/391], Reconst Loss: 114.95392, KL Div: 11.24258, Total Loss: 126.19650
Epoch[89/100], Step [250/391], Reconst Loss: 116.26225, KL Div: 11.43353, Total Loss: 127.69578
Epoch[89/100], Step [260/391], Reconst Loss: 115.76157, KL Div: 11.26594, Total Loss: 127.02750
Epoch[89/100], Step [270/391], Reconst Loss: 119.56474, KL Div: 11.49435, Total Loss: 131.05909
Epoch[89/100], Step [280/391], Reconst Loss: 111.20350, KL Div: 11.62016, Total Loss: 122.82366
Epoch[89/100], Step [290/391], Reconst Loss: 120.68915, KL Div: 11.44578, Total Loss: 132.13493
Epoch[89/100], Step [300/391], Reconst Loss: 116.44225, KL Div: 11.36948, Total Loss: 127.81172
Epoch[89/100], Step [310/391], Reconst Loss: 114.70628, KL Div: 10.91441, Total Loss: 125.62069
Epoch[89/100], Step [320/391], Reconst Loss: 114.07494, KL Div: 11.56982, Total Loss: 125.64476
Epoch[89/100], Step [330/391], Reconst Loss: 118.65830, KL Div: 11.39261, Total Loss: 130.05091
Epoch[89/100], Step [340/391], Reconst Loss: 111.50987, KL Div: 11.27414, Total Loss: 122.78401
Epoch[89/100], Step [350/391], Reconst Loss: 118.41309, KL Div: 11.31013, Total Loss: 129.72321
Epoch[89/100], Step [360/391], Reconst Loss: 116.37288, KL Div: 11.81431, Total Loss: 128.18719
Epoch[89/100], Step [370/391], Reconst Loss: 120.29726, KL Div: 11.74246, Total Loss: 132.03973
Epoch[89/100], Step [380/391], Reconst Loss: 121.50340, KL Div: 10.98498, Total Loss: 132.48839
Epoch[89/100], Step [390/391], Reconst Loss: 116.25187, KL Div: 11.23071, Total Loss: 127.48258
Epoch = 89
Training epoch time =  139.09827876091003
train total loss =  126.5393451171875
valid total loss =  127.91029067382813
Total epoch time =  257.2483513355255
Saving checkpoint...
Done!
Epoch[90/100], Step [10/391], Reconst Loss: 114.89919, KL Div: 11.26125, Total Loss: 126.16045
Epoch[90/100], Step [20/391], Reconst Loss: 116.70924, KL Div: 11.19899, Total Loss: 127.90823
Epoch[90/100], Step [30/391], Reconst Loss: 123.05990, KL Div: 10.99666, Total Loss: 134.05655
Epoch[90/100], Step [40/391], Reconst Loss: 117.19543, KL Div: 11.58872, Total Loss: 128.78415
Epoch[90/100], Step [50/391], Reconst Loss: 113.30717, KL Div: 11.14393, Total Loss: 124.45111
Epoch[90/100], Step [60/391], Reconst Loss: 114.94213, KL Div: 11.44988, Total Loss: 126.39202
Epoch[90/100], Step [70/391], Reconst Loss: 114.11664, KL Div: 11.33417, Total Loss: 125.45081
Epoch[90/100], Step [80/391], Reconst Loss: 123.66221, KL Div: 11.03335, Total Loss: 134.69556
Epoch[90/100], Step [90/391], Reconst Loss: 119.68397, KL Div: 11.45242, Total Loss: 131.13639
Epoch[90/100], Step [100/391], Reconst Loss: 110.20721, KL Div: 11.93705, Total Loss: 122.14426
Epoch[90/100], Step [110/391], Reconst Loss: 112.74049, KL Div: 11.28562, Total Loss: 124.02611
Epoch[90/100], Step [120/391], Reconst Loss: 113.68222, KL Div: 11.23948, Total Loss: 124.92170
Epoch[90/100], Step [130/391], Reconst Loss: 119.01265, KL Div: 11.26140, Total Loss: 130.27405
Epoch[90/100], Step [140/391], Reconst Loss: 110.98584, KL Div: 11.42532, Total Loss: 122.41116
Epoch[90/100], Step [150/391], Reconst Loss: 109.26091, KL Div: 11.33053, Total Loss: 120.59144
Epoch[90/100], Step [160/391], Reconst Loss: 109.77518, KL Div: 11.52458, Total Loss: 121.29976
Epoch[90/100], Step [170/391], Reconst Loss: 121.09576, KL Div: 11.38776, Total Loss: 132.48353
Epoch[90/100], Step [180/391], Reconst Loss: 115.90521, KL Div: 11.64669, Total Loss: 127.55190
Epoch[90/100], Step [190/391], Reconst Loss: 118.19652, KL Div: 11.50140, Total Loss: 129.69791
Epoch[90/100], Step [200/391], Reconst Loss: 122.07729, KL Div: 11.72671, Total Loss: 133.80400
Epoch[90/100], Step [210/391], Reconst Loss: 114.26816, KL Div: 11.28739, Total Loss: 125.55555
Epoch[90/100], Step [220/391], Reconst Loss: 112.46812, KL Div: 11.36611, Total Loss: 123.83422
Epoch[90/100], Step [230/391], Reconst Loss: 113.80097, KL Div: 11.67179, Total Loss: 125.47276
Epoch[90/100], Step [240/391], Reconst Loss: 116.18320, KL Div: 11.46089, Total Loss: 127.64409
Epoch[90/100], Step [250/391], Reconst Loss: 122.66656, KL Div: 11.25261, Total Loss: 133.91918
Epoch[90/100], Step [260/391], Reconst Loss: 117.20204, KL Div: 11.14899, Total Loss: 128.35103
Epoch[90/100], Step [270/391], Reconst Loss: 120.82701, KL Div: 11.65691, Total Loss: 132.48392
Epoch[90/100], Step [280/391], Reconst Loss: 114.22118, KL Div: 11.93131, Total Loss: 126.15249
Epoch[90/100], Step [290/391], Reconst Loss: 110.28026, KL Div: 10.82507, Total Loss: 121.10532
Epoch[90/100], Step [300/391], Reconst Loss: 116.44819, KL Div: 11.20108, Total Loss: 127.64927
Epoch[90/100], Step [310/391], Reconst Loss: 118.42102, KL Div: 11.80729, Total Loss: 130.22831
Epoch[90/100], Step [320/391], Reconst Loss: 117.65507, KL Div: 11.49026, Total Loss: 129.14533
Epoch[90/100], Step [330/391], Reconst Loss: 112.72131, KL Div: 11.77533, Total Loss: 124.49664
Epoch[90/100], Step [340/391], Reconst Loss: 121.15775, KL Div: 11.27430, Total Loss: 132.43205
Epoch[90/100], Step [350/391], Reconst Loss: 114.40144, KL Div: 11.43359, Total Loss: 125.83503
Epoch[90/100], Step [360/391], Reconst Loss: 113.29806, KL Div: 11.35291, Total Loss: 124.65097
Epoch[90/100], Step [370/391], Reconst Loss: 116.82024, KL Div: 11.77692, Total Loss: 128.59715
Epoch[90/100], Step [380/391], Reconst Loss: 113.89554, KL Div: 10.99048, Total Loss: 124.88602
Epoch[90/100], Step [390/391], Reconst Loss: 123.12305, KL Div: 11.45931, Total Loss: 134.58236
Epoch = 90
Training epoch time =  139.41668248176575
train total loss =  126.28679978515625
valid total loss =  127.62061517333984
Total epoch time =  257.15110039711
Saving checkpoint...
Done!
Epoch[91/100], Step [10/391], Reconst Loss: 116.64874, KL Div: 11.29464, Total Loss: 127.94338
Epoch[91/100], Step [20/391], Reconst Loss: 113.73677, KL Div: 11.59936, Total Loss: 125.33613
Epoch[91/100], Step [30/391], Reconst Loss: 118.41000, KL Div: 11.54843, Total Loss: 129.95843
Epoch[91/100], Step [40/391], Reconst Loss: 112.75941, KL Div: 11.32869, Total Loss: 124.08810
Epoch[91/100], Step [50/391], Reconst Loss: 120.29418, KL Div: 11.16790, Total Loss: 131.46208
Epoch[91/100], Step [60/391], Reconst Loss: 116.62697, KL Div: 11.44519, Total Loss: 128.07216
Epoch[91/100], Step [70/391], Reconst Loss: 116.23694, KL Div: 11.51111, Total Loss: 127.74805
Epoch[91/100], Step [80/391], Reconst Loss: 109.95087, KL Div: 11.07132, Total Loss: 121.02219
Epoch[91/100], Step [90/391], Reconst Loss: 114.34198, KL Div: 11.06727, Total Loss: 125.40925
Epoch[91/100], Step [100/391], Reconst Loss: 119.43307, KL Div: 11.54318, Total Loss: 130.97626
Epoch[91/100], Step [110/391], Reconst Loss: 111.85735, KL Div: 11.31037, Total Loss: 123.16772
Epoch[91/100], Step [120/391], Reconst Loss: 119.35165, KL Div: 10.68309, Total Loss: 130.03474
Epoch[91/100], Step [130/391], Reconst Loss: 110.42816, KL Div: 11.08741, Total Loss: 121.51557
Epoch[91/100], Step [140/391], Reconst Loss: 115.36850, KL Div: 11.23350, Total Loss: 126.60200
Epoch[91/100], Step [150/391], Reconst Loss: 119.16671, KL Div: 11.42510, Total Loss: 130.59181
Epoch[91/100], Step [160/391], Reconst Loss: 120.81319, KL Div: 11.14438, Total Loss: 131.95757
Epoch[91/100], Step [170/391], Reconst Loss: 118.52455, KL Div: 11.43766, Total Loss: 129.96221
Epoch[91/100], Step [180/391], Reconst Loss: 113.09073, KL Div: 11.30580, Total Loss: 124.39653
Epoch[91/100], Step [190/391], Reconst Loss: 114.11751, KL Div: 11.13801, Total Loss: 125.25552
Epoch[91/100], Step [200/391], Reconst Loss: 112.07576, KL Div: 11.70299, Total Loss: 123.77875
Epoch[91/100], Step [210/391], Reconst Loss: 112.71502, KL Div: 11.34758, Total Loss: 124.06260
Epoch[91/100], Step [220/391], Reconst Loss: 116.50490, KL Div: 11.09497, Total Loss: 127.59986
Epoch[91/100], Step [230/391], Reconst Loss: 116.89581, KL Div: 11.13658, Total Loss: 128.03238
Epoch[91/100], Step [240/391], Reconst Loss: 114.49103, KL Div: 11.23502, Total Loss: 125.72604
Epoch[91/100], Step [250/391], Reconst Loss: 115.21538, KL Div: 11.29824, Total Loss: 126.51362
Epoch[91/100], Step [260/391], Reconst Loss: 111.64905, KL Div: 11.65945, Total Loss: 123.30850
Epoch[91/100], Step [270/391], Reconst Loss: 114.59953, KL Div: 11.86716, Total Loss: 126.46669
Epoch[91/100], Step [280/391], Reconst Loss: 116.09360, KL Div: 11.11444, Total Loss: 127.20804
Epoch[91/100], Step [290/391], Reconst Loss: 112.02382, KL Div: 11.79223, Total Loss: 123.81605
Epoch[91/100], Step [300/391], Reconst Loss: 115.92246, KL Div: 11.44411, Total Loss: 127.36657
Epoch[91/100], Step [310/391], Reconst Loss: 116.69118, KL Div: 11.65126, Total Loss: 128.34245
Epoch[91/100], Step [320/391], Reconst Loss: 117.38523, KL Div: 11.61287, Total Loss: 128.99810
Epoch[91/100], Step [330/391], Reconst Loss: 124.39737, KL Div: 11.81616, Total Loss: 136.21353
Epoch[91/100], Step [340/391], Reconst Loss: 117.68660, KL Div: 11.30157, Total Loss: 128.98817
Epoch[91/100], Step [350/391], Reconst Loss: 119.07366, KL Div: 11.02110, Total Loss: 130.09476
Epoch[91/100], Step [360/391], Reconst Loss: 118.57948, KL Div: 11.67040, Total Loss: 130.24987
Epoch[91/100], Step [370/391], Reconst Loss: 114.78847, KL Div: 11.44875, Total Loss: 126.23722
Epoch[91/100], Step [380/391], Reconst Loss: 121.11821, KL Div: 11.42329, Total Loss: 132.54150
Epoch[91/100], Step [390/391], Reconst Loss: 118.17003, KL Div: 11.19006, Total Loss: 129.36009
Epoch = 91
Training epoch time =  139.35667753219604
train total loss =  126.58422505859374
valid total loss =  128.05414930419923
Total epoch time =  257.548344373703
Saving checkpoint...
Done!
Epoch[92/100], Step [10/391], Reconst Loss: 116.49451, KL Div: 11.55364, Total Loss: 128.04816
Epoch[92/100], Step [20/391], Reconst Loss: 121.01166, KL Div: 10.92746, Total Loss: 131.93911
Epoch[92/100], Step [30/391], Reconst Loss: 112.68085, KL Div: 11.69656, Total Loss: 124.37741
Epoch[92/100], Step [40/391], Reconst Loss: 120.13483, KL Div: 11.46579, Total Loss: 131.60062
Epoch[92/100], Step [50/391], Reconst Loss: 120.06158, KL Div: 11.30597, Total Loss: 131.36755
Epoch[92/100], Step [60/391], Reconst Loss: 115.61058, KL Div: 11.17609, Total Loss: 126.78668
Epoch[92/100], Step [70/391], Reconst Loss: 119.92628, KL Div: 11.15528, Total Loss: 131.08157
Epoch[92/100], Step [80/391], Reconst Loss: 108.33176, KL Div: 11.12674, Total Loss: 119.45850
Epoch[92/100], Step [90/391], Reconst Loss: 117.41772, KL Div: 11.10816, Total Loss: 128.52588
Epoch[92/100], Step [100/391], Reconst Loss: 117.06265, KL Div: 11.40100, Total Loss: 128.46366
Epoch[92/100], Step [110/391], Reconst Loss: 114.86775, KL Div: 11.53926, Total Loss: 126.40701
Epoch[92/100], Step [120/391], Reconst Loss: 115.18619, KL Div: 11.58806, Total Loss: 126.77424
Epoch[92/100], Step [130/391], Reconst Loss: 124.70988, KL Div: 11.09772, Total Loss: 135.80760
Epoch[92/100], Step [140/391], Reconst Loss: 117.72168, KL Div: 11.36575, Total Loss: 129.08743
Epoch[92/100], Step [150/391], Reconst Loss: 116.99764, KL Div: 11.71294, Total Loss: 128.71058
Epoch[92/100], Step [160/391], Reconst Loss: 109.74320, KL Div: 11.61907, Total Loss: 121.36227
Epoch[92/100], Step [170/391], Reconst Loss: 116.25024, KL Div: 11.75375, Total Loss: 128.00399
Epoch[92/100], Step [180/391], Reconst Loss: 116.21890, KL Div: 11.40099, Total Loss: 127.61989
Epoch[92/100], Step [190/391], Reconst Loss: 119.39670, KL Div: 11.42556, Total Loss: 130.82225
Epoch[92/100], Step [200/391], Reconst Loss: 121.92583, KL Div: 11.65983, Total Loss: 133.58567
Epoch[92/100], Step [210/391], Reconst Loss: 120.62299, KL Div: 11.49275, Total Loss: 132.11573
Epoch[92/100], Step [220/391], Reconst Loss: 116.17871, KL Div: 11.43228, Total Loss: 127.61099
Epoch[92/100], Step [230/391], Reconst Loss: 117.30794, KL Div: 11.77751, Total Loss: 129.08545
Epoch[92/100], Step [240/391], Reconst Loss: 111.62351, KL Div: 11.33486, Total Loss: 122.95837
Epoch[92/100], Step [250/391], Reconst Loss: 114.82123, KL Div: 11.50702, Total Loss: 126.32824
Epoch[92/100], Step [260/391], Reconst Loss: 115.45401, KL Div: 11.76199, Total Loss: 127.21600
Epoch[92/100], Step [270/391], Reconst Loss: 116.55773, KL Div: 11.16301, Total Loss: 127.72074
Epoch[92/100], Step [280/391], Reconst Loss: 111.32220, KL Div: 11.53547, Total Loss: 122.85767
Epoch[92/100], Step [290/391], Reconst Loss: 113.07998, KL Div: 11.52124, Total Loss: 124.60121
Epoch[92/100], Step [300/391], Reconst Loss: 114.49745, KL Div: 11.16055, Total Loss: 125.65800
Epoch[92/100], Step [310/391], Reconst Loss: 118.65273, KL Div: 11.67937, Total Loss: 130.33210
Epoch[92/100], Step [320/391], Reconst Loss: 114.73740, KL Div: 11.34126, Total Loss: 126.07866
Epoch[92/100], Step [330/391], Reconst Loss: 121.70282, KL Div: 11.50947, Total Loss: 133.21229
Epoch[92/100], Step [340/391], Reconst Loss: 117.30038, KL Div: 11.39888, Total Loss: 128.69927
Epoch[92/100], Step [350/391], Reconst Loss: 115.56322, KL Div: 11.21350, Total Loss: 126.77672
Epoch[92/100], Step [360/391], Reconst Loss: 120.13272, KL Div: 11.60900, Total Loss: 131.74172
Epoch[92/100], Step [370/391], Reconst Loss: 122.42567, KL Div: 11.07924, Total Loss: 133.50492
Epoch[92/100], Step [380/391], Reconst Loss: 116.87552, KL Div: 10.73119, Total Loss: 127.60671
Epoch[92/100], Step [390/391], Reconst Loss: 115.18964, KL Div: 11.12970, Total Loss: 126.31933
Epoch = 92
Training epoch time =  139.33204174041748
train total loss =  126.87326955078125
valid total loss =  128.4417015258789
Total epoch time =  257.4210731983185
Saving checkpoint...
Done!
Epoch[93/100], Step [10/391], Reconst Loss: 115.74165, KL Div: 11.05097, Total Loss: 126.79263
Epoch[93/100], Step [20/391], Reconst Loss: 119.52014, KL Div: 11.19681, Total Loss: 130.71695
Epoch[93/100], Step [30/391], Reconst Loss: 112.78805, KL Div: 11.26650, Total Loss: 124.05455
Epoch[93/100], Step [40/391], Reconst Loss: 123.50602, KL Div: 11.26346, Total Loss: 134.76948
Epoch[93/100], Step [50/391], Reconst Loss: 118.38625, KL Div: 11.41448, Total Loss: 129.80073
Epoch[93/100], Step [60/391], Reconst Loss: 117.39986, KL Div: 11.11954, Total Loss: 128.51940
Epoch[93/100], Step [70/391], Reconst Loss: 114.25647, KL Div: 11.24591, Total Loss: 125.50238
Epoch[93/100], Step [80/391], Reconst Loss: 113.54960, KL Div: 11.32421, Total Loss: 124.87381
Epoch[93/100], Step [90/391], Reconst Loss: 115.93282, KL Div: 10.85394, Total Loss: 126.78676
Epoch[93/100], Step [100/391], Reconst Loss: 116.71262, KL Div: 11.63440, Total Loss: 128.34702
Epoch[93/100], Step [110/391], Reconst Loss: 116.48978, KL Div: 11.40267, Total Loss: 127.89245
Epoch[93/100], Step [120/391], Reconst Loss: 116.41104, KL Div: 11.48736, Total Loss: 127.89840
Epoch[93/100], Step [130/391], Reconst Loss: 117.14796, KL Div: 11.05340, Total Loss: 128.20136
Epoch[93/100], Step [140/391], Reconst Loss: 117.95198, KL Div: 11.48538, Total Loss: 129.43736
Epoch[93/100], Step [150/391], Reconst Loss: 118.78838, KL Div: 11.39980, Total Loss: 130.18818
Epoch[93/100], Step [160/391], Reconst Loss: 117.52407, KL Div: 11.08497, Total Loss: 128.60905
Epoch[93/100], Step [170/391], Reconst Loss: 121.30824, KL Div: 11.35288, Total Loss: 132.66112
Epoch[93/100], Step [180/391], Reconst Loss: 114.45947, KL Div: 10.98924, Total Loss: 125.44871
Epoch[93/100], Step [190/391], Reconst Loss: 113.61775, KL Div: 11.07230, Total Loss: 124.69005
Epoch[93/100], Step [200/391], Reconst Loss: 115.41940, KL Div: 10.96231, Total Loss: 126.38171
Epoch[93/100], Step [210/391], Reconst Loss: 117.23449, KL Div: 11.16152, Total Loss: 128.39601
Epoch[93/100], Step [220/391], Reconst Loss: 114.00323, KL Div: 11.52698, Total Loss: 125.53020
Epoch[93/100], Step [230/391], Reconst Loss: 110.32569, KL Div: 10.95288, Total Loss: 121.27857
Epoch[93/100], Step [240/391], Reconst Loss: 112.49900, KL Div: 11.60294, Total Loss: 124.10194
Epoch[93/100], Step [250/391], Reconst Loss: 117.61163, KL Div: 11.39517, Total Loss: 129.00681
Epoch[93/100], Step [260/391], Reconst Loss: 118.32310, KL Div: 11.42287, Total Loss: 129.74597
Epoch[93/100], Step [270/391], Reconst Loss: 115.66331, KL Div: 11.53092, Total Loss: 127.19424
Epoch[93/100], Step [280/391], Reconst Loss: 115.19545, KL Div: 11.21857, Total Loss: 126.41402
Epoch[93/100], Step [290/391], Reconst Loss: 110.87808, KL Div: 11.30496, Total Loss: 122.18304
Epoch[93/100], Step [300/391], Reconst Loss: 118.06949, KL Div: 11.57232, Total Loss: 129.64181
Epoch[93/100], Step [310/391], Reconst Loss: 115.29321, KL Div: 11.21657, Total Loss: 126.50978
Epoch[93/100], Step [320/391], Reconst Loss: 116.46535, KL Div: 11.22853, Total Loss: 127.69388
Epoch[93/100], Step [330/391], Reconst Loss: 115.65944, KL Div: 11.32584, Total Loss: 126.98528
Epoch[93/100], Step [340/391], Reconst Loss: 121.71848, KL Div: 11.50803, Total Loss: 133.22651
Epoch[93/100], Step [350/391], Reconst Loss: 113.77519, KL Div: 11.17677, Total Loss: 124.95196
Epoch[93/100], Step [360/391], Reconst Loss: 117.22855, KL Div: 11.47728, Total Loss: 128.70583
Epoch[93/100], Step [370/391], Reconst Loss: 111.89632, KL Div: 11.15308, Total Loss: 123.04941
Epoch[93/100], Step [380/391], Reconst Loss: 114.82951, KL Div: 11.42067, Total Loss: 126.25018
Epoch[93/100], Step [390/391], Reconst Loss: 121.30010, KL Div: 11.38271, Total Loss: 132.68281
Epoch = 93
Training epoch time =  139.32435655593872
train total loss =  126.87733666015625
valid total loss =  128.29110059814454
Total epoch time =  257.38438844680786
Saving checkpoint...
Done!
Epoch[94/100], Step [10/391], Reconst Loss: 112.86739, KL Div: 11.47795, Total Loss: 124.34533
Epoch[94/100], Step [20/391], Reconst Loss: 113.65611, KL Div: 11.88186, Total Loss: 125.53796
Epoch[94/100], Step [30/391], Reconst Loss: 121.20529, KL Div: 11.39734, Total Loss: 132.60263
Epoch[94/100], Step [40/391], Reconst Loss: 116.50419, KL Div: 11.56866, Total Loss: 128.07285
Epoch[94/100], Step [50/391], Reconst Loss: 109.99771, KL Div: 11.21782, Total Loss: 121.21553
Epoch[94/100], Step [60/391], Reconst Loss: 119.81783, KL Div: 11.33046, Total Loss: 131.14829
Epoch[94/100], Step [70/391], Reconst Loss: 115.88484, KL Div: 11.69344, Total Loss: 127.57829
Epoch[94/100], Step [80/391], Reconst Loss: 119.86004, KL Div: 11.25923, Total Loss: 131.11927
Epoch[94/100], Step [90/391], Reconst Loss: 114.55489, KL Div: 11.24663, Total Loss: 125.80152
Epoch[94/100], Step [100/391], Reconst Loss: 113.69086, KL Div: 11.32867, Total Loss: 125.01953
Epoch[94/100], Step [110/391], Reconst Loss: 120.07268, KL Div: 11.60478, Total Loss: 131.67745
Epoch[94/100], Step [120/391], Reconst Loss: 116.33515, KL Div: 11.67992, Total Loss: 128.01507
Epoch[94/100], Step [130/391], Reconst Loss: 123.60557, KL Div: 11.56110, Total Loss: 135.16666
Epoch[94/100], Step [140/391], Reconst Loss: 116.04105, KL Div: 11.40900, Total Loss: 127.45005
Epoch[94/100], Step [150/391], Reconst Loss: 114.77147, KL Div: 11.52446, Total Loss: 126.29593
Epoch[94/100], Step [160/391], Reconst Loss: 109.83042, KL Div: 11.48173, Total Loss: 121.31216
Epoch[94/100], Step [170/391], Reconst Loss: 120.55938, KL Div: 11.47293, Total Loss: 132.03231
Epoch[94/100], Step [180/391], Reconst Loss: 114.13110, KL Div: 11.17566, Total Loss: 125.30676
Epoch[94/100], Step [190/391], Reconst Loss: 110.82848, KL Div: 11.07703, Total Loss: 121.90551
Epoch[94/100], Step [200/391], Reconst Loss: 116.01843, KL Div: 11.50397, Total Loss: 127.52240
Epoch[94/100], Step [210/391], Reconst Loss: 116.78121, KL Div: 11.30113, Total Loss: 128.08235
Epoch[94/100], Step [220/391], Reconst Loss: 113.13912, KL Div: 11.35580, Total Loss: 124.49492
Epoch[94/100], Step [230/391], Reconst Loss: 112.36120, KL Div: 11.25091, Total Loss: 123.61211
Epoch[94/100], Step [240/391], Reconst Loss: 111.22424, KL Div: 10.99750, Total Loss: 122.22175
Epoch[94/100], Step [250/391], Reconst Loss: 121.25240, KL Div: 11.82180, Total Loss: 133.07421
Epoch[94/100], Step [260/391], Reconst Loss: 113.55435, KL Div: 10.67482, Total Loss: 124.22917
Epoch[94/100], Step [270/391], Reconst Loss: 116.98030, KL Div: 11.40351, Total Loss: 128.38381
Epoch[94/100], Step [280/391], Reconst Loss: 112.40818, KL Div: 11.65382, Total Loss: 124.06200
Epoch[94/100], Step [290/391], Reconst Loss: 114.27013, KL Div: 11.31701, Total Loss: 125.58715
Epoch[94/100], Step [300/391], Reconst Loss: 114.37682, KL Div: 11.19052, Total Loss: 125.56733
Epoch[94/100], Step [310/391], Reconst Loss: 115.14191, KL Div: 11.41896, Total Loss: 126.56087
Epoch[94/100], Step [320/391], Reconst Loss: 115.52777, KL Div: 11.82962, Total Loss: 127.35739
Epoch[94/100], Step [330/391], Reconst Loss: 117.75409, KL Div: 11.42587, Total Loss: 129.17996
Epoch[94/100], Step [340/391], Reconst Loss: 114.17580, KL Div: 11.64900, Total Loss: 125.82480
Epoch[94/100], Step [350/391], Reconst Loss: 110.35358, KL Div: 11.18954, Total Loss: 121.54311
Epoch[94/100], Step [360/391], Reconst Loss: 111.72832, KL Div: 11.26671, Total Loss: 122.99502
Epoch[94/100], Step [370/391], Reconst Loss: 115.65857, KL Div: 11.56540, Total Loss: 127.22397
Epoch[94/100], Step [380/391], Reconst Loss: 111.84544, KL Div: 11.93562, Total Loss: 123.78105
Epoch[94/100], Step [390/391], Reconst Loss: 117.80495, KL Div: 11.32553, Total Loss: 129.13047
Epoch = 94
Training epoch time =  139.3546507358551
train total loss =  126.5226387890625
valid total loss =  127.9306552734375
Total epoch time =  257.5465943813324
Saving checkpoint...
Done!
Epoch[95/100], Step [10/391], Reconst Loss: 113.37405, KL Div: 11.75129, Total Loss: 125.12533
Epoch[95/100], Step [20/391], Reconst Loss: 121.28459, KL Div: 10.86285, Total Loss: 132.14744
Epoch[95/100], Step [30/391], Reconst Loss: 123.19910, KL Div: 11.53891, Total Loss: 134.73801
Epoch[95/100], Step [40/391], Reconst Loss: 120.02788, KL Div: 11.74471, Total Loss: 131.77259
Epoch[95/100], Step [50/391], Reconst Loss: 117.13286, KL Div: 11.39325, Total Loss: 128.52611
Epoch[95/100], Step [60/391], Reconst Loss: 112.54021, KL Div: 11.25884, Total Loss: 123.79905
Epoch[95/100], Step [70/391], Reconst Loss: 117.56554, KL Div: 11.89930, Total Loss: 129.46484
Epoch[95/100], Step [80/391], Reconst Loss: 111.93980, KL Div: 11.29722, Total Loss: 123.23703
Epoch[95/100], Step [90/391], Reconst Loss: 112.60927, KL Div: 11.45471, Total Loss: 124.06398
Epoch[95/100], Step [100/391], Reconst Loss: 112.55080, KL Div: 11.40789, Total Loss: 123.95868
Epoch[95/100], Step [110/391], Reconst Loss: 113.45920, KL Div: 11.63732, Total Loss: 125.09652
Epoch[95/100], Step [120/391], Reconst Loss: 118.92274, KL Div: 11.85293, Total Loss: 130.77567
Epoch[95/100], Step [130/391], Reconst Loss: 111.37538, KL Div: 11.81546, Total Loss: 123.19084
Epoch[95/100], Step [140/391], Reconst Loss: 117.42270, KL Div: 11.80274, Total Loss: 129.22544
Epoch[95/100], Step [150/391], Reconst Loss: 119.80638, KL Div: 11.99303, Total Loss: 131.79941
Epoch[95/100], Step [160/391], Reconst Loss: 114.80023, KL Div: 11.33413, Total Loss: 126.13436
Epoch[95/100], Step [170/391], Reconst Loss: 120.33638, KL Div: 11.18160, Total Loss: 131.51798
Epoch[95/100], Step [180/391], Reconst Loss: 113.17712, KL Div: 11.68196, Total Loss: 124.85908
Epoch[95/100], Step [190/391], Reconst Loss: 110.46375, KL Div: 11.47391, Total Loss: 121.93766
Epoch[95/100], Step [200/391], Reconst Loss: 114.21007, KL Div: 12.08787, Total Loss: 126.29794
Epoch[95/100], Step [210/391], Reconst Loss: 116.27692, KL Div: 11.21257, Total Loss: 127.48949
Epoch[95/100], Step [220/391], Reconst Loss: 115.82391, KL Div: 11.73344, Total Loss: 127.55735
Epoch[95/100], Step [230/391], Reconst Loss: 114.82236, KL Div: 11.23038, Total Loss: 126.05274
Epoch[95/100], Step [240/391], Reconst Loss: 113.39911, KL Div: 11.10735, Total Loss: 124.50646
Epoch[95/100], Step [250/391], Reconst Loss: 112.49781, KL Div: 11.74535, Total Loss: 124.24316
Epoch[95/100], Step [260/391], Reconst Loss: 116.63042, KL Div: 11.78951, Total Loss: 128.41993
Epoch[95/100], Step [270/391], Reconst Loss: 112.75522, KL Div: 11.48264, Total Loss: 124.23785
Epoch[95/100], Step [280/391], Reconst Loss: 123.40994, KL Div: 11.22935, Total Loss: 134.63929
Epoch[95/100], Step [290/391], Reconst Loss: 119.03961, KL Div: 11.47363, Total Loss: 130.51325
Epoch[95/100], Step [300/391], Reconst Loss: 116.93790, KL Div: 11.25128, Total Loss: 128.18919
Epoch[95/100], Step [310/391], Reconst Loss: 113.63915, KL Div: 11.05306, Total Loss: 124.69221
Epoch[95/100], Step [320/391], Reconst Loss: 112.91867, KL Div: 11.28493, Total Loss: 124.20360
Epoch[95/100], Step [330/391], Reconst Loss: 114.83652, KL Div: 11.64204, Total Loss: 126.47856
Epoch[95/100], Step [340/391], Reconst Loss: 117.82540, KL Div: 11.62948, Total Loss: 129.45488
Epoch[95/100], Step [350/391], Reconst Loss: 117.12540, KL Div: 11.72727, Total Loss: 128.85267
Epoch[95/100], Step [360/391], Reconst Loss: 117.50951, KL Div: 11.61026, Total Loss: 129.11976
Epoch[95/100], Step [370/391], Reconst Loss: 120.62738, KL Div: 11.86853, Total Loss: 132.49591
Epoch[95/100], Step [380/391], Reconst Loss: 109.78867, KL Div: 11.90826, Total Loss: 121.69692
Epoch[95/100], Step [390/391], Reconst Loss: 121.62259, KL Div: 11.35831, Total Loss: 132.98090
Epoch = 95
Training epoch time =  139.51280546188354
train total loss =  126.6242448828125
valid total loss =  128.0185490722656
Total epoch time =  257.40617299079895
Saving checkpoint...
Done!
Epoch[96/100], Step [10/391], Reconst Loss: 113.96117, KL Div: 11.44634, Total Loss: 125.40750
Epoch[96/100], Step [20/391], Reconst Loss: 123.46655, KL Div: 11.43869, Total Loss: 134.90524
Epoch[96/100], Step [30/391], Reconst Loss: 119.38881, KL Div: 11.62579, Total Loss: 131.01460
Epoch[96/100], Step [40/391], Reconst Loss: 111.32839, KL Div: 11.47944, Total Loss: 122.80783
Epoch[96/100], Step [50/391], Reconst Loss: 120.04649, KL Div: 11.46215, Total Loss: 131.50865
Epoch[96/100], Step [60/391], Reconst Loss: 118.94531, KL Div: 11.63374, Total Loss: 130.57905
Epoch[96/100], Step [70/391], Reconst Loss: 115.16974, KL Div: 11.75725, Total Loss: 126.92699
Epoch[96/100], Step [80/391], Reconst Loss: 121.16312, KL Div: 11.60065, Total Loss: 132.76376
Epoch[96/100], Step [90/391], Reconst Loss: 113.96427, KL Div: 11.40311, Total Loss: 125.36738
Epoch[96/100], Step [100/391], Reconst Loss: 116.39534, KL Div: 11.76255, Total Loss: 128.15789
Epoch[96/100], Step [110/391], Reconst Loss: 121.34048, KL Div: 11.87546, Total Loss: 133.21595
Epoch[96/100], Step [120/391], Reconst Loss: 115.47894, KL Div: 11.08163, Total Loss: 126.56058
Epoch[96/100], Step [130/391], Reconst Loss: 115.01665, KL Div: 11.23482, Total Loss: 126.25146
Epoch[96/100], Step [140/391], Reconst Loss: 112.97817, KL Div: 11.30526, Total Loss: 124.28343
Epoch[96/100], Step [150/391], Reconst Loss: 111.81432, KL Div: 11.01713, Total Loss: 122.83145
Epoch[96/100], Step [160/391], Reconst Loss: 117.98284, KL Div: 11.32662, Total Loss: 129.30946
Epoch[96/100], Step [170/391], Reconst Loss: 114.77148, KL Div: 11.09309, Total Loss: 125.86457
Epoch[96/100], Step [180/391], Reconst Loss: 115.32094, KL Div: 11.12176, Total Loss: 126.44270
Epoch[96/100], Step [190/391], Reconst Loss: 118.52919, KL Div: 11.12859, Total Loss: 129.65778
Epoch[96/100], Step [200/391], Reconst Loss: 112.61724, KL Div: 11.29571, Total Loss: 123.91296
Epoch[96/100], Step [210/391], Reconst Loss: 116.49818, KL Div: 11.01596, Total Loss: 127.51414
Epoch[96/100], Step [220/391], Reconst Loss: 120.94753, KL Div: 11.52980, Total Loss: 132.47732
Epoch[96/100], Step [230/391], Reconst Loss: 113.10670, KL Div: 11.26950, Total Loss: 124.37621
Epoch[96/100], Step [240/391], Reconst Loss: 121.27155, KL Div: 11.00526, Total Loss: 132.27680
Epoch[96/100], Step [250/391], Reconst Loss: 111.66689, KL Div: 11.60581, Total Loss: 123.27270
Epoch[96/100], Step [260/391], Reconst Loss: 121.46652, KL Div: 11.51101, Total Loss: 132.97754
Epoch[96/100], Step [270/391], Reconst Loss: 118.80627, KL Div: 11.13200, Total Loss: 129.93828
Epoch[96/100], Step [280/391], Reconst Loss: 118.72617, KL Div: 10.90808, Total Loss: 129.63426
Epoch[96/100], Step [290/391], Reconst Loss: 118.18727, KL Div: 11.61382, Total Loss: 129.80109
Epoch[96/100], Step [300/391], Reconst Loss: 114.32133, KL Div: 11.59417, Total Loss: 125.91550
Epoch[96/100], Step [310/391], Reconst Loss: 114.25891, KL Div: 11.71504, Total Loss: 125.97395
Epoch[96/100], Step [320/391], Reconst Loss: 119.46845, KL Div: 11.14212, Total Loss: 130.61057
Epoch[96/100], Step [330/391], Reconst Loss: 115.17092, KL Div: 11.34176, Total Loss: 126.51268
Epoch[96/100], Step [340/391], Reconst Loss: 115.96963, KL Div: 11.17229, Total Loss: 127.14192
Epoch[96/100], Step [350/391], Reconst Loss: 114.81834, KL Div: 11.13248, Total Loss: 125.95082
Epoch[96/100], Step [360/391], Reconst Loss: 114.94255, KL Div: 11.07755, Total Loss: 126.02010
Epoch[96/100], Step [370/391], Reconst Loss: 115.50658, KL Div: 10.96482, Total Loss: 126.47140
Epoch[96/100], Step [380/391], Reconst Loss: 119.37458, KL Div: 11.70826, Total Loss: 131.08284
Epoch[96/100], Step [390/391], Reconst Loss: 112.68819, KL Div: 11.40370, Total Loss: 124.09189
Epoch = 96
Training epoch time =  139.18701267242432
train total loss =  126.9709947265625
valid total loss =  128.38726282958984
Total epoch time =  257.4655432701111
Saving checkpoint...
Done!
Epoch[97/100], Step [10/391], Reconst Loss: 115.37577, KL Div: 11.24856, Total Loss: 126.62433
Epoch[97/100], Step [20/391], Reconst Loss: 114.89828, KL Div: 11.12084, Total Loss: 126.01913
Epoch[97/100], Step [30/391], Reconst Loss: 119.72999, KL Div: 11.36815, Total Loss: 131.09814
Epoch[97/100], Step [40/391], Reconst Loss: 114.22639, KL Div: 10.78479, Total Loss: 125.01119
Epoch[97/100], Step [50/391], Reconst Loss: 115.91238, KL Div: 11.12832, Total Loss: 127.04070
Epoch[97/100], Step [60/391], Reconst Loss: 121.89511, KL Div: 11.01892, Total Loss: 132.91403
Epoch[97/100], Step [70/391], Reconst Loss: 124.95421, KL Div: 11.14780, Total Loss: 136.10201
Epoch[97/100], Step [80/391], Reconst Loss: 118.88864, KL Div: 11.84530, Total Loss: 130.73394
Epoch[97/100], Step [90/391], Reconst Loss: 116.88707, KL Div: 11.03864, Total Loss: 127.92571
Epoch[97/100], Step [100/391], Reconst Loss: 123.27803, KL Div: 11.60916, Total Loss: 134.88719
Epoch[97/100], Step [110/391], Reconst Loss: 112.17262, KL Div: 11.08613, Total Loss: 123.25875
Epoch[97/100], Step [120/391], Reconst Loss: 123.07999, KL Div: 11.20822, Total Loss: 134.28822
Epoch[97/100], Step [130/391], Reconst Loss: 107.66535, KL Div: 10.88646, Total Loss: 118.55181
Epoch[97/100], Step [140/391], Reconst Loss: 116.10938, KL Div: 11.33054, Total Loss: 127.43991
Epoch[97/100], Step [150/391], Reconst Loss: 116.51024, KL Div: 11.48940, Total Loss: 127.99964
Epoch[97/100], Step [160/391], Reconst Loss: 116.83393, KL Div: 11.44613, Total Loss: 128.28006
Epoch[97/100], Step [170/391], Reconst Loss: 115.23310, KL Div: 11.69450, Total Loss: 126.92760
Epoch[97/100], Step [180/391], Reconst Loss: 115.14843, KL Div: 11.37369, Total Loss: 126.52212
Epoch[97/100], Step [190/391], Reconst Loss: 115.74657, KL Div: 11.49727, Total Loss: 127.24384
Epoch[97/100], Step [200/391], Reconst Loss: 116.56850, KL Div: 11.05941, Total Loss: 127.62791
Epoch[97/100], Step [210/391], Reconst Loss: 117.31261, KL Div: 11.28018, Total Loss: 128.59279
Epoch[97/100], Step [220/391], Reconst Loss: 115.40567, KL Div: 10.87920, Total Loss: 126.28487
Epoch[97/100], Step [230/391], Reconst Loss: 117.80458, KL Div: 11.11533, Total Loss: 128.91991
Epoch[97/100], Step [240/391], Reconst Loss: 118.53278, KL Div: 11.45892, Total Loss: 129.99169
Epoch[97/100], Step [250/391], Reconst Loss: 112.40618, KL Div: 11.69738, Total Loss: 124.10356
Epoch[97/100], Step [260/391], Reconst Loss: 117.38649, KL Div: 11.56509, Total Loss: 128.95158
Epoch[97/100], Step [270/391], Reconst Loss: 111.30011, KL Div: 11.36299, Total Loss: 122.66310
Epoch[97/100], Step [280/391], Reconst Loss: 113.50036, KL Div: 11.37790, Total Loss: 124.87826
Epoch[97/100], Step [290/391], Reconst Loss: 116.86040, KL Div: 11.49931, Total Loss: 128.35970
Epoch[97/100], Step [300/391], Reconst Loss: 112.88015, KL Div: 11.26678, Total Loss: 124.14693
Epoch[97/100], Step [310/391], Reconst Loss: 120.42987, KL Div: 11.18529, Total Loss: 131.61516
Epoch[97/100], Step [320/391], Reconst Loss: 114.07178, KL Div: 11.32424, Total Loss: 125.39601
Epoch[97/100], Step [330/391], Reconst Loss: 115.54730, KL Div: 11.58812, Total Loss: 127.13542
Epoch[97/100], Step [340/391], Reconst Loss: 121.61552, KL Div: 10.90350, Total Loss: 132.51903
Epoch[97/100], Step [350/391], Reconst Loss: 115.45277, KL Div: 11.58168, Total Loss: 127.03446
Epoch[97/100], Step [360/391], Reconst Loss: 110.07172, KL Div: 11.08440, Total Loss: 121.15611
Epoch[97/100], Step [370/391], Reconst Loss: 116.88608, KL Div: 11.61551, Total Loss: 128.50159
Epoch[97/100], Step [380/391], Reconst Loss: 117.12525, KL Div: 11.29484, Total Loss: 128.42010
Epoch[97/100], Step [390/391], Reconst Loss: 113.68526, KL Div: 11.62111, Total Loss: 125.30636
Epoch = 97
Training epoch time =  139.36135601997375
train total loss =  126.7758844140625
valid total loss =  128.17140673828126
Total epoch time =  257.12788105010986
Saving checkpoint...
Done!
Epoch[98/100], Step [10/391], Reconst Loss: 120.30457, KL Div: 11.37310, Total Loss: 131.67767
Epoch[98/100], Step [20/391], Reconst Loss: 115.83160, KL Div: 11.08207, Total Loss: 126.91367
Epoch[98/100], Step [30/391], Reconst Loss: 113.90305, KL Div: 11.33368, Total Loss: 125.23673
Epoch[98/100], Step [40/391], Reconst Loss: 116.40477, KL Div: 11.37210, Total Loss: 127.77687
Epoch[98/100], Step [50/391], Reconst Loss: 121.80711, KL Div: 11.34098, Total Loss: 133.14809
Epoch[98/100], Step [60/391], Reconst Loss: 111.00034, KL Div: 11.18834, Total Loss: 122.18868
Epoch[98/100], Step [70/391], Reconst Loss: 110.04115, KL Div: 11.57251, Total Loss: 121.61366
Epoch[98/100], Step [80/391], Reconst Loss: 117.28286, KL Div: 11.57251, Total Loss: 128.85537
Epoch[98/100], Step [90/391], Reconst Loss: 118.10892, KL Div: 10.98704, Total Loss: 129.09596
Epoch[98/100], Step [100/391], Reconst Loss: 123.52457, KL Div: 10.84831, Total Loss: 134.37289
Epoch[98/100], Step [110/391], Reconst Loss: 115.13867, KL Div: 11.43558, Total Loss: 126.57425
Epoch[98/100], Step [120/391], Reconst Loss: 120.98201, KL Div: 11.10647, Total Loss: 132.08848
Epoch[98/100], Step [130/391], Reconst Loss: 120.62309, KL Div: 10.98115, Total Loss: 131.60424
Epoch[98/100], Step [140/391], Reconst Loss: 113.34651, KL Div: 11.23402, Total Loss: 124.58053
Epoch[98/100], Step [150/391], Reconst Loss: 121.05866, KL Div: 11.38616, Total Loss: 132.44482
Epoch[98/100], Step [160/391], Reconst Loss: 122.11031, KL Div: 11.19915, Total Loss: 133.30946
Epoch[98/100], Step [170/391], Reconst Loss: 117.91355, KL Div: 11.08650, Total Loss: 129.00005
Epoch[98/100], Step [180/391], Reconst Loss: 118.28006, KL Div: 10.86741, Total Loss: 129.14747
Epoch[98/100], Step [190/391], Reconst Loss: 116.49262, KL Div: 11.88716, Total Loss: 128.37978
Epoch[98/100], Step [200/391], Reconst Loss: 116.62865, KL Div: 11.32477, Total Loss: 127.95342
Epoch[98/100], Step [210/391], Reconst Loss: 113.10611, KL Div: 11.06583, Total Loss: 124.17194
Epoch[98/100], Step [220/391], Reconst Loss: 115.64321, KL Div: 10.96900, Total Loss: 126.61221
Epoch[98/100], Step [230/391], Reconst Loss: 115.60314, KL Div: 10.73867, Total Loss: 126.34181
Epoch[98/100], Step [240/391], Reconst Loss: 117.07162, KL Div: 11.71302, Total Loss: 128.78464
Epoch[98/100], Step [250/391], Reconst Loss: 114.62123, KL Div: 11.22158, Total Loss: 125.84282
Epoch[98/100], Step [260/391], Reconst Loss: 122.40351, KL Div: 10.83649, Total Loss: 133.24000
Epoch[98/100], Step [270/391], Reconst Loss: 116.71280, KL Div: 11.62840, Total Loss: 128.34120
Epoch[98/100], Step [280/391], Reconst Loss: 115.66846, KL Div: 11.47959, Total Loss: 127.14805
Epoch[98/100], Step [290/391], Reconst Loss: 117.39450, KL Div: 11.75642, Total Loss: 129.15092
Epoch[98/100], Step [300/391], Reconst Loss: 116.08453, KL Div: 11.62128, Total Loss: 127.70581
Epoch[98/100], Step [310/391], Reconst Loss: 111.54751, KL Div: 10.89099, Total Loss: 122.43850
Epoch[98/100], Step [320/391], Reconst Loss: 115.51667, KL Div: 10.97718, Total Loss: 126.49385
Epoch[98/100], Step [330/391], Reconst Loss: 116.09198, KL Div: 11.32318, Total Loss: 127.41516
Epoch[98/100], Step [340/391], Reconst Loss: 115.47119, KL Div: 11.76461, Total Loss: 127.23580
Epoch[98/100], Step [350/391], Reconst Loss: 121.65056, KL Div: 11.10400, Total Loss: 132.75456
Epoch[98/100], Step [360/391], Reconst Loss: 114.50635, KL Div: 11.14550, Total Loss: 125.65184
Epoch[98/100], Step [370/391], Reconst Loss: 116.55443, KL Div: 11.41014, Total Loss: 127.96456
Epoch[98/100], Step [380/391], Reconst Loss: 116.32049, KL Div: 11.34373, Total Loss: 127.66422
Epoch[98/100], Step [390/391], Reconst Loss: 116.87013, KL Div: 10.63321, Total Loss: 127.50334
Epoch = 98
Training epoch time =  139.39123249053955
train total loss =  127.06248802734375
valid total loss =  128.54189304199218
Total epoch time =  257.96371126174927
Saving checkpoint...
Done!
Epoch[99/100], Step [10/391], Reconst Loss: 122.70711, KL Div: 10.93822, Total Loss: 133.64533
Epoch[99/100], Step [20/391], Reconst Loss: 114.71313, KL Div: 11.34336, Total Loss: 126.05649
Epoch[99/100], Step [30/391], Reconst Loss: 118.05194, KL Div: 11.19395, Total Loss: 129.24589
Epoch[99/100], Step [40/391], Reconst Loss: 118.51714, KL Div: 11.18230, Total Loss: 129.69944
Epoch[99/100], Step [50/391], Reconst Loss: 114.90983, KL Div: 11.44676, Total Loss: 126.35659
Epoch[99/100], Step [60/391], Reconst Loss: 113.35825, KL Div: 11.02124, Total Loss: 124.37948
Epoch[99/100], Step [70/391], Reconst Loss: 112.70753, KL Div: 11.37374, Total Loss: 124.08126
Epoch[99/100], Step [80/391], Reconst Loss: 112.58511, KL Div: 10.89793, Total Loss: 123.48304
Epoch[99/100], Step [90/391], Reconst Loss: 118.70943, KL Div: 11.43794, Total Loss: 130.14737
Epoch[99/100], Step [100/391], Reconst Loss: 114.67772, KL Div: 10.97073, Total Loss: 125.64845
Epoch[99/100], Step [110/391], Reconst Loss: 110.87593, KL Div: 11.32049, Total Loss: 122.19642
Epoch[99/100], Step [120/391], Reconst Loss: 116.69498, KL Div: 11.57357, Total Loss: 128.26855
Epoch[99/100], Step [130/391], Reconst Loss: 117.77779, KL Div: 11.47866, Total Loss: 129.25645
Epoch[99/100], Step [140/391], Reconst Loss: 118.86826, KL Div: 10.98308, Total Loss: 129.85133
Epoch[99/100], Step [150/391], Reconst Loss: 116.58736, KL Div: 11.29040, Total Loss: 127.87777
Epoch[99/100], Step [160/391], Reconst Loss: 115.43738, KL Div: 11.29531, Total Loss: 126.73269
Epoch[99/100], Step [170/391], Reconst Loss: 118.94990, KL Div: 10.90219, Total Loss: 129.85209
Epoch[99/100], Step [180/391], Reconst Loss: 122.44446, KL Div: 11.23103, Total Loss: 133.67548
Epoch[99/100], Step [190/391], Reconst Loss: 116.98200, KL Div: 11.27856, Total Loss: 128.26057
Epoch[99/100], Step [200/391], Reconst Loss: 116.70055, KL Div: 11.39413, Total Loss: 128.09468
Epoch[99/100], Step [210/391], Reconst Loss: 113.41622, KL Div: 11.44591, Total Loss: 124.86213
Epoch[99/100], Step [220/391], Reconst Loss: 114.20311, KL Div: 11.67118, Total Loss: 125.87429
Epoch[99/100], Step [230/391], Reconst Loss: 117.42184, KL Div: 11.61449, Total Loss: 129.03633
Epoch[99/100], Step [240/391], Reconst Loss: 112.51968, KL Div: 11.22401, Total Loss: 123.74369
Epoch[99/100], Step [250/391], Reconst Loss: 116.07896, KL Div: 10.99974, Total Loss: 127.07870
Epoch[99/100], Step [260/391], Reconst Loss: 116.90907, KL Div: 11.23817, Total Loss: 128.14724
Epoch[99/100], Step [270/391], Reconst Loss: 114.12939, KL Div: 11.63955, Total Loss: 125.76894
Epoch[99/100], Step [280/391], Reconst Loss: 118.39948, KL Div: 11.39495, Total Loss: 129.79444
Epoch[99/100], Step [290/391], Reconst Loss: 116.62431, KL Div: 11.38596, Total Loss: 128.01027
Epoch[99/100], Step [300/391], Reconst Loss: 117.00731, KL Div: 11.32775, Total Loss: 128.33506
Epoch[99/100], Step [310/391], Reconst Loss: 119.34982, KL Div: 11.26567, Total Loss: 130.61550
Epoch[99/100], Step [320/391], Reconst Loss: 115.49872, KL Div: 10.60916, Total Loss: 126.10788
Epoch[99/100], Step [330/391], Reconst Loss: 118.25353, KL Div: 11.50182, Total Loss: 129.75535
Epoch[99/100], Step [340/391], Reconst Loss: 115.27827, KL Div: 11.15572, Total Loss: 126.43399
Epoch[99/100], Step [350/391], Reconst Loss: 110.63751, KL Div: 11.41985, Total Loss: 122.05736
Epoch[99/100], Step [360/391], Reconst Loss: 113.48866, KL Div: 10.78095, Total Loss: 124.26961
Epoch[99/100], Step [370/391], Reconst Loss: 116.12453, KL Div: 11.39060, Total Loss: 127.51512
Epoch[99/100], Step [380/391], Reconst Loss: 118.11748, KL Div: 11.48455, Total Loss: 129.60203
Epoch[99/100], Step [390/391], Reconst Loss: 120.66155, KL Div: 11.39989, Total Loss: 132.06145
Epoch = 99
Training epoch time =  139.86993074417114
train total loss =  126.0942378515625
valid total loss =  127.61402193603516
Total epoch time =  257.92286491394043
Saving checkpoint...
Done!
Epoch[100/100], Step [10/391], Reconst Loss: 110.30222, KL Div: 10.91812, Total Loss: 121.22033
Epoch[100/100], Step [20/391], Reconst Loss: 112.34839, KL Div: 11.23871, Total Loss: 123.58709
Epoch[100/100], Step [30/391], Reconst Loss: 113.65065, KL Div: 11.11344, Total Loss: 124.76409
Epoch[100/100], Step [40/391], Reconst Loss: 122.23732, KL Div: 11.73845, Total Loss: 133.97577
Epoch[100/100], Step [50/391], Reconst Loss: 118.43271, KL Div: 10.94145, Total Loss: 129.37416
Epoch[100/100], Step [60/391], Reconst Loss: 113.22067, KL Div: 11.35086, Total Loss: 124.57153
Epoch[100/100], Step [70/391], Reconst Loss: 113.92559, KL Div: 11.48382, Total Loss: 125.40941
Epoch[100/100], Step [80/391], Reconst Loss: 112.07584, KL Div: 11.11923, Total Loss: 123.19507
Epoch[100/100], Step [90/391], Reconst Loss: 119.62916, KL Div: 10.68152, Total Loss: 130.31067
Epoch[100/100], Step [100/391], Reconst Loss: 112.87088, KL Div: 10.96348, Total Loss: 123.83436
Epoch[100/100], Step [110/391], Reconst Loss: 118.58145, KL Div: 11.27208, Total Loss: 129.85353
Epoch[100/100], Step [120/391], Reconst Loss: 124.08376, KL Div: 10.84882, Total Loss: 134.93257
Epoch[100/100], Step [130/391], Reconst Loss: 119.63653, KL Div: 11.02791, Total Loss: 130.66443
Epoch[100/100], Step [140/391], Reconst Loss: 115.98660, KL Div: 11.75517, Total Loss: 127.74177
Epoch[100/100], Step [150/391], Reconst Loss: 117.14194, KL Div: 11.25426, Total Loss: 128.39619
Epoch[100/100], Step [160/391], Reconst Loss: 114.80679, KL Div: 11.71241, Total Loss: 126.51920
Epoch[100/100], Step [170/391], Reconst Loss: 118.99078, KL Div: 11.86109, Total Loss: 130.85187
Epoch[100/100], Step [180/391], Reconst Loss: 111.27576, KL Div: 11.07075, Total Loss: 122.34651
Epoch[100/100], Step [190/391], Reconst Loss: 118.97229, KL Div: 11.53520, Total Loss: 130.50749
Epoch[100/100], Step [200/391], Reconst Loss: 115.16086, KL Div: 11.58671, Total Loss: 126.74757
Epoch[100/100], Step [210/391], Reconst Loss: 119.42575, KL Div: 11.24769, Total Loss: 130.67344
Epoch[100/100], Step [220/391], Reconst Loss: 119.11211, KL Div: 11.30598, Total Loss: 130.41809
Epoch[100/100], Step [230/391], Reconst Loss: 119.33644, KL Div: 11.39093, Total Loss: 130.72737
Epoch[100/100], Step [240/391], Reconst Loss: 122.97552, KL Div: 11.27573, Total Loss: 134.25125
Epoch[100/100], Step [250/391], Reconst Loss: 119.58942, KL Div: 11.18233, Total Loss: 130.77175
Epoch[100/100], Step [260/391], Reconst Loss: 121.24740, KL Div: 11.83970, Total Loss: 133.08710
Epoch[100/100], Step [270/391], Reconst Loss: 115.97701, KL Div: 11.20526, Total Loss: 127.18226
Epoch[100/100], Step [280/391], Reconst Loss: 112.98822, KL Div: 11.11497, Total Loss: 124.10319
Epoch[100/100], Step [290/391], Reconst Loss: 119.10087, KL Div: 10.92484, Total Loss: 130.02571
Epoch[100/100], Step [300/391], Reconst Loss: 115.45914, KL Div: 11.17325, Total Loss: 126.63239
Epoch[100/100], Step [310/391], Reconst Loss: 119.42995, KL Div: 11.59330, Total Loss: 131.02324
Epoch[100/100], Step [320/391], Reconst Loss: 114.77875, KL Div: 11.50161, Total Loss: 126.28035
Epoch[100/100], Step [330/391], Reconst Loss: 115.52476, KL Div: 11.42332, Total Loss: 126.94808
Epoch[100/100], Step [340/391], Reconst Loss: 110.56834, KL Div: 10.94991, Total Loss: 121.51825
Epoch[100/100], Step [350/391], Reconst Loss: 116.44566, KL Div: 11.31977, Total Loss: 127.76542
Epoch[100/100], Step [360/391], Reconst Loss: 113.91524, KL Div: 11.20860, Total Loss: 125.12383
Epoch[100/100], Step [370/391], Reconst Loss: 110.71915, KL Div: 11.05332, Total Loss: 121.77247
Epoch[100/100], Step [380/391], Reconst Loss: 109.06909, KL Div: 11.23823, Total Loss: 120.30732
Epoch[100/100], Step [390/391], Reconst Loss: 109.83287, KL Div: 11.41182, Total Loss: 121.24470
Epoch = 100
Training epoch time =  139.74390196800232
train total loss =  125.98346296875
valid total loss =  127.32379970703126
Total epoch time =  257.86579275131226
Saving checkpoint...
Done!
Total loss on test data: 126.52100057373048
Generation:
z = 
 tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
         0., 1.],
        [0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
         1., 1.],
        [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         1., 1.],
        [0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
         0., 1.],
        [1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
         0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
         1., 1.],
        [0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
         1., 1.],
        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
         0., 0.],
        [0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
         0., 0.],
        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,
         0., 0.]])
Generation:
z = 
 tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
         0., 0.],
        [0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
         1., 1.],
        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
         0., 0.],
        [0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,
         0., 1.],
        [0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
         1., 0.],
        [0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
         1., 0.],
        [1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,
         1., 1.],
        [0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
         1., 1.],
        [0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
         1., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
         0., 0.]])
Generation:
z = 
 tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
         0., 1.],
        [1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
         1., 0.],
        [0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,
         0., 1.],
        [1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
         0., 1.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,
         0., 0.],
        [0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.,
         0., 0.],
        [0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
         0., 0.],
        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
         0., 1.],
        [1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,
         0., 1.],
        [1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
         0., 1.]])
Generation:
z = 
 tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
         1., 1.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,
         1., 0.],
        [0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
         1., 1.],
        [0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
         0., 0.],
        [0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
         1., 0.],
        [0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
         0., 0.],
        [1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,
         0., 1.],
        [0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
         0., 1.],
        [0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
         0., 0.],
        [0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,
         0., 0.]])
Generation:
z = 
 tensor([[1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
         1., 0.],
        [0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
         0., 1.],
        [1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
         1., 0.],
        [0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
         0., 0.],
        [1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
         0., 1.],
        [0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,
         0., 0.],
        [1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
         1., 0.],
        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,
         1., 0.],
        [0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
         1., 1.],
        [0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
         1., 1.]])
